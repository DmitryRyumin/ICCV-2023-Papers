[
  {
    "title": "TMR: Text-to-Motion Retrieval using Contrastive 3D Human Motion Synthesis",
    "base_url": null,
    "title_page": null,
    "repo": "Mathux/TMR",
    "web_page": null,
    "github_page": "https://mathis.petrovich.fr/tmr/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/Mathux/TMR",
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Petrovich_TMR_Text-to-Motion_Retrieval_Using_Contrastive_3D_Human_Motion_Synthesis_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2305.00976",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "FK0RukgDEtM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Sequential Texts Driven Cohesive Motions Synthesis with Natural Transitions",
    "base_url": null,
    "title_page": null,
    "repo": "Druthrie/ST2M",
    "web_page": null,
    "github_page": "https://druthrie.github.io/sequential-texts-to-motion/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Sequential_Texts_Driven_Cohesive_Motions_Synthesis_with_Natural_Transitions_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Auxiliary Tasks Benefit 3D Skeleton-based Human Motion Prediction",
    "base_url": null,
    "title_page": null,
    "repo": "MediaBrain-SJTU/AuxFormer",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Auxiliary_Tasks_Benefit_3D_Skeleton-based_Human_Motion_Prediction_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.08942",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Explicit Motion Disentangling for Efficient Optical Flow Estimation",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Explicit_Motion_Disentangling_for_Efficient_Optical_Flow_Estimation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "TrackFlow: Multi-Object tracking with Normalizing Flows",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Mancusi_TrackFlow_Multi-Object_tracking_with_Normalizing_Flows_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.11513",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "HumanMAC: Masked Motion Completion for Human Motion Prediction",
    "base_url": null,
    "title_page": null,
    "repo": "LinghaoChan/HumanMAC",
    "web_page": "https://lhchen.top/Human-MAC/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_HumanMAC_Masked_Motion_Completion_for_Human_Motion_Prediction_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2302.03665",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "vfde9GdUHBs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Geometrized Transformer for Self-Supervised Homography Estimation",
    "base_url": null,
    "title_page": null,
    "repo": "ruc-aimc-lab/GeoFormer",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Geometrized_Transformer_for_Self-Supervised_Homography_Estimation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "SemARFlow: Injecting Semantics into Unsupervised Optical Flow Estimation for Autonomous Driving",
    "base_url": null,
    "title_page": null,
    "repo": "duke-vision/semantic-unsup-flow-release",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_SemARFlow_Injecting_Semantics_into_Unsupervised_Optical_Flow_Estimation_for_Autonomous_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.06209",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "XYBTolH2S8A",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "NeSS-ST: Detecting Good and Stable Keypoints with a Neural Stability Score and the Shi-Tomasi Detector",
    "base_url": null,
    "title_page": null,
    "repo": "KonstantinPakulev/NeSS-ST",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pakulev_NeSS-ST_Detecting_Good_and_Stable_Keypoints_with_a_Neural_Stability_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Robust Object Modeling for Visual Tracking",
    "base_url": null,
    "title_page": null,
    "repo": "dawnyc/ROMTrack",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Robust_Object_Modeling_for_Visual_Tracking_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.05140",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Social Diffusion: Long-Term Multiple Human Motion Anticipation",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tanke_Social_Diffusion_Long-term_Multiple_Human_Motion_Anticipation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Exploring Lightweight Hierarchical Vision Transformers for Efficient Visual Tracking",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_Exploring_Lightweight_Hierarchical_Vision_Transformers_for_Efficient_Visual_Tracking_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.06904",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "HMD-NeMo: Online 3D Avatar Motion Generation from Sparse Observations",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Aliakbarian_HMD-NeMo_Online_3D_Avatar_Motion_Generation_From_Sparse_Observations_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.11261",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Learning Fine-Grained Features for Pixel-Wise Video Correspondences",
    "base_url": null,
    "title_page": null,
    "repo": "qianduoduolr/Spa-then-Temp",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Learning_Fine-Grained_Features_for_Pixel-Wise_Video_Correspondences_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.03040",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "2ZCVUoiyM0U",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "GAFlow: Incorporating Gaussian Attention into Optical Flow",
    "base_url": null,
    "title_page": null,
    "repo": "LA30/GAFlow",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_GAFlow_Incorporating_Gaussian_Attention_into_Optical_Flow_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Occ<sup>2</sup>Net: Robust Image Matching based on 3D Occupancy Estimation for Occluded Regions",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Occ2Net_Robust_Image_Matching_Based_on_3D_Occupancy_Estimation_for_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.16160",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Locomotion-Action-Manipulation: Synthesizing Human-Scene Interactions in Complex 3D Environments",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": "https://jiyewise.github.io/projects/LAMA/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Locomotion-Action-Manipulation_Synthesizing_Human-Scene_Interactions_in_Complex_3D_Environments_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2301.02667",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Trajectory Unified Transformer for Pedestrian Trajectory Prediction",
    "base_url": null,
    "title_page": null,
    "repo": "lssiair/TUTR",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Trajectory_Unified_Transformer_for_Pedestrian_Trajectory_Prediction_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "TMA: Temporal Motion Aggregation for Event-based Optical Flow",
    "base_url": null,
    "title_page": null,
    "repo": "ispc-lab/TMA",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_TMA_Temporal_Motion_Aggregation_for_Event-based_Optical_Flow_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.11629",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Taming Contrast Maximization for Learning Sequential, Low-Latency, Event-based Optical Flow",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": "https://mavlab.tudelft.nl/taming_event_flow/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Paredes-Valles_Taming_Contrast_Maximization_for_Learning_Sequential_Low-latency_Event-based_Optical_Flow_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "vkYimENc494",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "GlueStick: Robust Image Matching by Sticking Points and Lines Together",
    "base_url": null,
    "title_page": null,
    "repo": "cvg/GlueStick",
    "web_page": "https://iago-suarez.com/gluestick/",
    "github_page": null,
    "colab": "https://colab.research.google.com/github/cvg/GlueStick/blob/main/gluestick_matching_demo.ipynb",
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pautrat_GlueStick_Robust_Image_Matching_by_Sticking_Points_and_Lines_Together_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.02008",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "JmpddJ5pfz8",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "DARTH: Holistic Test-Time Adaptation for Multiple Object Tracking",
    "base_url": null,
    "title_page": null,
    "repo": "mattiasegu/darth",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Segu_DARTH_Holistic_Test-time_Adaptation_for_Multiple_Object_Tracking_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "S-TREK: Sequential Translation and Rotation Equivariant Keypoints for Local Feature Extraction",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Santellani_S-TREK_Sequential_Translation_and_Rotation_Equivariant_Keypoints_for_Local_Feature_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.14598",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Integrating Boxes and Masks: A Multi-Object Framework for Unified Visual Tracking and Segmentation",
    "base_url": null,
    "title_page": null,
    "repo": "yoxu515/MITS",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Integrating_Boxes_and_Masks_A_Multi-Object_Framework_for_Unified_Visual_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.13266",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Robust Frame-to-Frame Camera Rotation Estimation in Crowded Scenes",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": "https://fabiendelattre.com/robust-rotation-estimation/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Delattre_Robust_Frame-to-Frame_Camera_Rotation_Estimation_in_Crowded_Scenes_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2309.08588",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "SL4QBedLu9Q",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Sparse Instance Conditioned Multimodal Trajectory Prediction",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Sparse_Instance_Conditioned_Multimodal_Trajectory_Prediction_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "PoseDiffusion: Solving Pose Estimation via Diffusion-aided Bundle Adjustment",
    "base_url": null,
    "title_page": null,
    "repo": "facebookresearch/PoseDiffusion",
    "web_page": null,
    "github_page": "https://posediffusion.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_PoseDiffusion_Solving_Pose_Estimation_via_Diffusion-aided_Bundle_Adjustment_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2306.15667",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "3DMOTFormer: Graph Transformer for Online 3D Multi-Object Tracking",
    "base_url": null,
    "title_page": null,
    "repo": "dsx0511/3DMOTFormer",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_3DMOTFormer_Graph_Transformer_for_Online_3D_Multi-Object_Tracking_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.06635",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Fast Inference and Update of Probabilistic Density Estimation on Trajectory Prediction",
    "base_url": null,
    "title_page": null,
    "repo": "meaten/FlowChain-ICCV2023",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Maeda_Fast_Inference_and_Update_of_Probabilistic_Density_Estimation_on_Trajectory_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.08824",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Supervised Homography Learning with Realistic Dataset Generation",
    "base_url": null,
    "title_page": null,
    "repo": "JianghaiSCU/RealSH",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Supervised_Homography_Learning_with_Realistic_Dataset_Generation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.15353",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Joint-Relation Transformer for Multi-Person Motion Prediction",
    "base_url": null,
    "title_page": null,
    "repo": "MediaBrain-SJTU/JRTransformer",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Joint-Relation_Transformer_for_Multi-Person_Motion_Prediction_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.04808",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Event-based Temporally Dense Optical Flow Estimation with Sequential Learning",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ponghiran_Event-based_Temporally_Dense_Optical_Flow_Estimation_with_Sequential_Learning_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2210.01244",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "3D Motion Magnification: Visualizing Subtle Motions from Time-Varying Radiance Fields",
    "base_url": null,
    "title_page": null,
    "repo": "3d-motion-magnification/3d-motion-mag",
    "web_page": null,
    "github_page": "https://3d-motion-magnification.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_3D_Motion_Magnification_Visualizing_Subtle_Motions_from_Time-Varying_Radiance_Fields_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.03757",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ljar4GAFkUk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Learning Optical Flow from Event Camera with Rendered Dataset",
    "base_url": null,
    "title_page": null,
    "repo": "boomluo02/ADMFlow",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Learning_Optical_Flow_from_Event_Camera_with_Rendered_Dataset_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.11011",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Persistent-Transient Duality: A Multi-Mechanism Approach for Modeling Human-Object Interaction",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tran_Persistent-Transient_Duality_A_Multi-Mechanism_Approach_for_Modeling_Human-Object_Interaction_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.12729",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "nVOQdI8g7AY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Deep Homography Mixture for Single Image Rolling Shutter Correction",
    "base_url": null,
    "title_page": null,
    "repo": "DavidYan2001/Deep_RS-HM",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Deep_Homography_Mixture_for_Single_Image_Rolling_Shutter_Correction_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Fast Neural Scene Flow",
    "base_url": null,
    "title_page": null,
    "repo": "Lilac-Lee/FastNSF",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Fast_Neural_Scene_Flow_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.09121",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "RLSAC: Reinforcement Learning Enhanced Sample Consensus for End-to-End Robust Estimation",
    "base_url": null,
    "title_page": null,
    "repo": "IRMVLab/RLSAC",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Nie_RLSAC_Reinforcement_Learning_Enhanced_Sample_Consensus_for_End-to-End_Robust_Estimation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.05318",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "MeMOTR: Long-Term Memory-Augmented Transformer for Multi-Object Tracking",
    "base_url": null,
    "title_page": null,
    "repo": "MCG-NJU/MeMOTR",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_MeMOTR_Long-Term_Memory-Augmented_Transformer_for_Multi-Object_Tracking_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.15700",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "MBPTrack: Improving 3D Point Cloud Tracking with Memory Networks and Box Priors",
    "base_url": null,
    "title_page": null,
    "repo": "slothfulxtx/MBPTrack3D",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_MBPTrack_Improving_3D_Point_Cloud_Tracking_with_Memory_Networks_and_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2303.05071",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Zl_4LnoX_Ak",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "SportsMOT: A Large Multi-Object Tracking Dataset in Multiple Sports Scenes",
    "base_url": null,
    "title_page": null,
    "repo": "MCG-NJU/SportsMOT",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_SportsMOT_A_Large_Multi-Object_Tracking_Dataset_in_Multiple_Sports_Scenes_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.05170",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Heterogeneous Diversity Driven Active Learning for Multi-Object Tracking",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Heterogeneous_Diversity_Driven_Active_Learning_for_Multi-Object_Tracking_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "TM2D: Bimodality Driven 3D Dance Generation via Music-Text Integration",
    "base_url": null,
    "title_page": null,
    "repo": "Garfield-kh/TM2D",
    "web_page": null,
    "github_page": "https://garfield-kh.github.io/TM2D/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gong_TM2D_Bimodality_Driven_3D_Dance_Generation_via_Music-Text_Integration_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.02419",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "6QQFXG4s7iQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Synchronize Feature Extracting and Matching: A Single Branch Framework for 3D Object Tracking",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Synchronize_Feature_Extracting_and_Matching_A_Single_Branch_Framework_for_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.12549",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Collaborative Tracking Learning for Frame-Rate-Insensitive Multi-Object Tracking",
    "base_url": null,
    "title_page": null,
    "repo": "yolomax/ColTrack",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Collaborative_Tracking_Learning_for_Frame-Rate-Insensitive_Multi-Object_Tracking_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.05911",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "CiteTracker: Correlating Image and Text for Visual Tracking",
    "base_url": null,
    "title_page": null,
    "repo": "NorahGreen/CiteTracker",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CiteTracker_Correlating_Image_and_Text_for_Visual_Tracking_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.11322",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "SINC: Spatial Composition of 3D Human Motions for Simultaneous Action Generation",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": "https://sinc.is.tue.mpg.de/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Athanasiou_SINC_Spatial_Composition_of_3D_Human_Motions_for_Simultaneous_Action_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2304.10417",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "uwUriDnKTLI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Uncertainty-Aware Unsupervised Multi-Object Tracking",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Uncertainty-aware_Unsupervised_Multi-Object_Tracking_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.15409",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "PVT++: A Simple End-to-End Latency-Aware Visual Tracking Framework",
    "base_url": null,
    "title_page": null,
    "repo": "Jaraxxus-Me/PVT_pp",
    "web_page": null,
    "github_page": "https://jaraxxus-me.github.io/ICCV2023_PVTpp/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_PVT_A_Simple_End-to-End_Latency-Aware_Visual_Tracking_Framework_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "EigenTrajectory: Low-Rank Descriptors for Multi-Modal Trajectory Forecasting",
    "base_url": null,
    "title_page": null,
    "repo": "inhwanbae/EigenTrajectory",
    "web_page": null,
    "github_page": "https://ihbae.com/publication/eigentrajectory/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Bae_EigenTrajectory_Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2307.09306",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "RPEFlow: Multimodal Fusion of RGB-PointCloud-Event for Joint Optical Flow and Scene Flow Estimation",
    "base_url": null,
    "title_page": null,
    "repo": "danqu130/RPEFlow",
    "web_page": null,
    "github_page": "https://npucvr.github.io/RPEFlow/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wan_RPEFlow_Multimodal_Fusion_of_RGB-PointCloud-Event_for_Joint_Optical_Flow_and_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2309.15082",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Multi-Scale Bidirectional Recurrent Network with Hybrid Correlation for Point Cloud based Scene Flow Estimation",
    "base_url": null,
    "title_page": null,
    "repo": "cwc1260/MSBRN",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Multi-Scale_Bidirectional_Recurrent_Network_with_Hybrid_Correlation_for_Point_Cloud_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "ReST: A Reconfigurable Spatial-Temporal Graph Model for Multi-Camera Multi-Object Tracking",
    "base_url": null,
    "title_page": null,
    "repo": "chengche6230/ReST",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_ReST_A_Reconfigurable_Spatial-Temporal_Graph_Model_for_Multi-Camera_Multi-Object_Tracking_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.13229",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "TAPIR: Tracking any Point with Per-Frame Initialization and Temporal Refinement",
    "base_url": null,
    "title_page": null,
    "repo": "google-deepmind/tapnet",
    "web_page": null,
    "github_page": "https://deepmind-tapir.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Doersch_TAPIR_Tracking_Any_Point_with_Per-Frame_Initialization_and_Temporal_Refinement_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2306.08637",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "I1DQJH3v7Nk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "IHNet: Iterative Hierarchical Network Guided by High-Resolution Estimated Information for Scene Flow Estimation",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_IHNet_Iterative_Hierarchical_Network_Guided_by_High-Resolution_Estimated_Information_for_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Can Language Models Learn to Listen?",
    "base_url": null,
    "title_page": null,
    "repo": "sanjayss34/lm-listener",
    "web_page": "https://people.eecs.berkeley.edu/~evonne_ng/projects/text2listen/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ng_Can_Language_Models_Learn_to_Listen_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2308.10897",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "djpSOhdIU8M",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "XVO: Generalized Visual Odometry via Cross-Modal Self-Training",
    "base_url": null,
    "title_page": null,
    "repo": "h2xlab/XVO",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lai_XVO_Generalized_Visual_Odometry_via_Cross-Modal_Self-Training_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Distracting Downpour: Adversarial Weather Attacks for Motion Estimation",
    "base_url": null,
    "title_page": null,
    "repo": "cv-stuttgart/DistractingDownpour",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Schmalfuss_Distracting_Downpour_Adversarial_Weather_Attacks_for_Motion_Estimation_ICCV_2023_paper.pdf",
    "paper_arxiv_id": "2305.06716",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  },
  {
    "title": "Foreground-Background Distribution Modeling Transformer for Visual Object Tracking",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Foreground-Background_Distribution_Modeling_Transformer_for_Visual_Object_Tracking_ICCV_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Motion Estimation, Matching and Tracking"
  }
]