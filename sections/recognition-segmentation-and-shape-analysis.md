# ICCV-2023-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/vision-and-audio.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/generative-ai.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" />
    </a>
</div>

## Recognition, Segmentation, and Shape Analysis

![Section Papers](https://img.shields.io/badge/Section%20Papers-12-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-10-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-10-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-1-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Segment Anything | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://segment-anything.com/) <br /> [![GitHub](https://img.shields.io/github/stars/facebookresearch/segment-anything?style=flat)](https://github.com/facebookresearch/segment-anything) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kirillov_Segment_Anything_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.02643-b31b1b.svg)](https://arxiv.org/abs/2304.02643) | :heavy_minus_sign: |
| Shape Analysis of Euclidean Curves under Frenet-Serret Framework | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chassat_Shape_Analysis_of_Euclidean_Curves_under_Frenet-Serret_Framework_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Unmasking Anomalies in Road-Scene Segmentation | [![GitHub](https://img.shields.io/github/stars/shyam671/Mask2Anomaly-Unmasking-Anomalies-in-Road-Scene-Segmentation?style=flat)](https://github.com/shyam671/Mask2Anomaly-Unmasking-Anomalies-in-Road-Scene-Segmentation) <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1iMF5lWj3J8zlIJFkekXC3ipQo2semJfL?usp=sharing) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Nandan_Unmasking_Anomalies_in_Road-Scene_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.13316-b31b1b.svg)](https://arxiv.org/abs/2307.13316) | :heavy_minus_sign: |
| High Quality Entity Segmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](http://luqi.info/entityv2.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/qqlu/Entity?style=flat)](https://github.com/qqlu/Entity) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Qi_High_Quality_Entity_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.05776-b31b1b.svg)](https://arxiv.org/abs/2211.05776) | :heavy_minus_sign: |
| Towards Open-Vocabulary Video Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/haochenheheda/LVVIS?style=flat)](https://github.com/haochenheheda/LVVIS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Towards_Open-Vocabulary_Video_Instance_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.01715-b31b1b.svg)](https://arxiv.org/abs/2304.01715) | :heavy_minus_sign: |
| Beyond One-to-One: Rethinking the Referring Image Segmentation | [![GitHub](https://img.shields.io/github/stars/toggle1995/RIS-DMMI?style=flat)](https://github.com/toggle1995/RIS-DMMI) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Beyond_One-to-One_Rethinking_the_Referring_Image_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.13853-b31b1b.svg)](https://arxiv.org/abs/2308.13853) | :heavy_minus_sign: |
| Multiple Instance Learning Framework with Masked Hard Instance Mining for whole Slide Image Classification | [![GitHub](https://img.shields.io/github/stars/DearCaat/MHIM-MIL?style=flat)](https://github.com/DearCaat/MHIM-MIL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Multiple_Instance_Learning_Framework_with_Masked_Hard_Instance_Mining_for_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.15254-b31b1b.svg)](https://arxiv.org/abs/2307.15254) | :heavy_minus_sign: |
| Scale-MAE: A Scale-Aware Masked Autoencoder for Multiscale Geospatial Representation Learning | [![GitHub](https://img.shields.io/github/stars/bair-climate-initiative/scale-mae?style=flat)](https://github.com/bair-climate-initiative/scale-mae) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Reed_Scale-MAE_A_Scale-Aware_Masked_Autoencoder_for_Multiscale_Geospatial_Representation_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.14532-b31b1b.svg)](https://arxiv.org/abs/2212.14532) | :heavy_minus_sign: |
| Progressive Spatio-Temporal Prototype Matching for Text-Video Retrieval | [![GitHub](https://img.shields.io/github/stars/IMCCretrieval/ProST?style=flat)](https://github.com/IMCCretrieval/ProST) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Progressive_Spatio-Temporal_Prototype_Matching_for_Text-Video_Retrieval_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Towards Deeply Unified Depth-Aware Panoptic Segmentation with Bi-Directional Guidance Learning | [![GitHub](https://img.shields.io/github/stars/jwh97nn/DeepDPS?style=flat)](https://github.com/jwh97nn/DeepDPS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/He_Towards_Deeply_Unified_Depth-aware_Panoptic_Segmentation_with_Bi-directional_Guidance_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.14786-b31b1b.svg)](https://arxiv.org/abs/2307.14786) | :heavy_minus_sign: |
| LogicSeg: Parsing Visual Semantics with Neural Logic Learning and Reasoning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_LogicSeg_Parsing_Visual_Semantics_with_Neural_Logic_Learning_and_Reasoning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.13556-b31b1b.svg)](https://arxiv.org/abs/2309.13556) | :heavy_minus_sign: |
| ASIC: Aligning Sparse in-the-Wild Image Collections | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://kampta.github.io/asic/) <br /> [![GitHub](https://img.shields.io/github/stars/kampta/asic?style=flat)](https://github.com/kampta/asic) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Gupta_ASIC_Aligning_Sparse_in-the-wild_Image_Collections_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16201-b31b1b.svg)](https://arxiv.org/abs/2303.16201) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=fLjkkMriuoY) |
