# ICCV-2023-Papers

## Image and Video Synthesis

![Section Papers](https://img.shields.io/badge/Section%20Papers-71-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-58-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-44-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-10-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Text-Driven Generative Domain Adaptation with Spectral Consistency Regularization | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MosaiQ: Quantum Generative Adversarial Networks for Image Generation on NISQ Computers | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.11096-b31b1b.svg)](https://arxiv.org/abs/2308.11096) | :heavy_minus_sign: |
| Controllable Visual-Tactile Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://visual-tactile-synthesis.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/RuihanGao/visual-tactile-synthesis)](https://github.com/RuihanGao/visual-tactile-synthesis) | [![arXiv](https://img.shields.io/badge/arXiv-2305.03051-b31b1b.svg)](https://arxiv.org/abs/2305.03051) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=TdwPfwsGX3I) |
| Editing Implicit Assumptions in Text-to-Image Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://time-diffusion.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/bahjat-kawar/time-diffusion)](https://github.com/bahjat-kawar/time-diffusion) | [![arXiv](https://img.shields.io/badge/arXiv-2303.08084-b31b1b.svg)](https://arxiv.org/abs/2303.08084) | :heavy_minus_sign: |
| DINAR: Diffusion Inpainting of Neural Textures for One-Shot Human Avatars | [![GitHub](https://img.shields.io/github/stars/SamsungLabs/DINAR)](https://github.com/SamsungLabs/DINAR) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09375-b31b1b.svg)](https://arxiv.org/abs/2303.09375) | :heavy_minus_sign: |
| Smoothness Similarity Regularization for Few-Shot GAN Adaptation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.09717-b31b1b.svg)](https://arxiv.org/abs/2308.09717) | :heavy_minus_sign: |
| HSR-Diff: Hyperspectral Image Super-Resolution via Conditional Diffusion Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.12085-b31b1b.svg)](https://arxiv.org/abs/2306.12085) | :heavy_minus_sign: |
| Long-Term Photometric Consistent Novel View Synthesis with Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yorkucvil.github.io/Photoconsistent-NVS/) | [![arXiv](https://img.shields.io/badge/arXiv-2304.10700-b31b1b.svg)](https://arxiv.org/abs/2304.10700) | :heavy_minus_sign: |
| AutoDiffusion: Training-Free Optimization of Time Steps and Architectures for Automated Diffusion Model Acceleration | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2309.10438-b31b1b.svg)](https://arxiv.org/abs/2309.10438) | :heavy_minus_sign: |
| GaFET: Learning Geometry-Aware Facial Expression Translation from in-the-Wild Images | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.03413-b31b1b.svg)](https://arxiv.org/abs/2308.03413) | :heavy_minus_sign: |
| Collecting the Puzzle Pieces: Disentangled Self-Driven Human Pose Transfer by Permuting Textures | [![GitHub](https://img.shields.io/github/stars/NannanLi999/pt_square)](https://github.com/NannanLi999/pt_square) | [![arXiv](https://img.shields.io/badge/arXiv-2210.01887-b31b1b.svg)](https://arxiv.org/abs/2210.01887) | :heavy_minus_sign: |
| Multi-Directional Subspace Editing in Style-Space | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chennaveh.github.io/MDSE/) <br /> [![GitHub](https://img.shields.io/github/stars/chennaveh/MDSE)](https://github.com/chennaveh/MDSE) | [![arXiv](https://img.shields.io/badge/arXiv-2211.11825-b31b1b.svg)](https://arxiv.org/abs/2211.11825) | :heavy_minus_sign: |
| HyperReenact: One-Shot Reenactment via Jointly Learning to Refine and Retarget Faces | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://stelabou.github.io/hyperreenact.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/StelaBou/HyperReenact)](https://github.com/StelaBou/HyperReenact) | [![arXiv](https://img.shields.io/badge/arXiv-2307.10797-b31b1b.svg)](https://arxiv.org/abs/2307.10797) | :heavy_minus_sign: |
| Generating Realistic Images from in-the-Wild Sounds | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2309.02405-b31b1b.svg)](https://arxiv.org/abs/2309.02405) | :heavy_minus_sign: |
| CC3D: Layout-Conditioned Generation of Compositional 3D Scenes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sherwinbahmani.github.io/cc3d/) <br /> [![GitHub](https://img.shields.io/github/stars/sherwinbahmani/cc3d)](https://github.com/sherwinbahmani/cc3d) | [![arXiv](https://img.shields.io/badge/arXiv-2303.12074-b31b1b.svg)](https://arxiv.org/abs/2303.12074) | :heavy_minus_sign: |
| UMFuse: Unified Multi View Fusion for Human Editing Applications | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2211.10157-b31b1b.svg)](https://arxiv.org/abs/2211.10157) | :heavy_minus_sign: |
| Evaluating Data Attribution for Text-to-Image Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://peterwang512.github.io/GenDataAttribution/) <br /> [![GitHub](https://img.shields.io/github/stars/PeterWang512/GenDataAttribution)](https://github.com/PeterWang512/GenDataAttribution) | [![arXiv](https://img.shields.io/badge/arXiv-2306.09345-b31b1b.svg)](https://arxiv.org/abs/2306.09345) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=iO6fiSyyv40) |
| Neural Characteristic Function Learning for Conditional Image Generation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| WaveIPT: Joint Attention and Flow Alignment in the Wavelet Domain for Pose Transfer | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| LayoutDiffusion: Improving Graphic Layout Generation by Discrete Diffusion Probabilistic Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://github.com/microsoft/LayoutGeneration/tree/main/LayoutDiffusion) <br /> [![GitHub](https://img.shields.io/github/stars/microsoft/LayoutGeneration)](https://github.com/microsoft/LayoutGeneration) | [![arXiv](https://img.shields.io/badge/arXiv-2303.11589-b31b1b.svg)](https://arxiv.org/abs/2303.11589) | :heavy_minus_sign: |
| Human-Inspired Facial Sketch Synthesis with Dynamic Adaptation | [![GitHub](https://img.shields.io/github/stars/AiArt-HDU/HIDA)](https://github.com/AiArt-HDU/HIDA) | [![arXiv](https://img.shields.io/badge/arXiv-2309.00216-b31b1b.svg)](https://arxiv.org/abs/2309.00216) | :heavy_minus_sign: |
| Conceptual and Hierarchical Latent Space Decomposition for Face Editing | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Improving Diversity in Zero-Shot GAN Adaptation with Semantic Variations | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.10554-b31b1b.svg)](https://arxiv.org/abs/2308.10554) | :heavy_minus_sign: |
| BallGAN: 3D-Aware Image Synthesis with a Spherical Background | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://minjung-s.github.io/ballgan) <br /> [![GitHub](https://img.shields.io/github/stars/minjung-s/BallGAN)](https://github.com/minjung-s/BallGAN) | [![arXiv](https://img.shields.io/badge/arXiv-2301.09091-b31b1b.svg)](https://arxiv.org/abs/2301.09091) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=RUIWWMiomuY) |
| End-to-End Diffusion Latent Optimization Improves Classifier Guidance | [![GitHub](https://img.shields.io/github/stars/salesforce/DOODL)](https://github.com/salesforce/DOODL) | [![arXiv](https://img.shields.io/badge/arXiv-2303.13703-b31b1b.svg)](https://arxiv.org/abs/2303.13703) | :heavy_minus_sign: |
| Deep Geometrized Cartoon Line Inbetweening | [![GitHub](https://img.shields.io/github/stars/lisiyao21/AnimeInbet)](https://github.com/lisiyao21/AnimeInbet) | :heavy_minus_sign: | :heavy_minus_sign: |
| UnitedHuman: Harnessing Multi-Source Data for High-Resolution Human Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://unitedhuman.github.io/) | :heavy_minus_sign: | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=pdsfUYFDLSw) |
| Towards Authentic Face Restoration with Iterative Diffusion Models and Beyond | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.08996-b31b1b.svg)](https://arxiv.org/abs/2307.08996) | :heavy_minus_sign: |
| SVDiff: Compact Parameter Space for Diffusion Fine-Tuning | [![GitHub](https://img.shields.io/github/stars/mkshing/svdiff-pytorch)](https://github.com/mkshing/svdiff-pytorch) | [![arXiv](https://img.shields.io/badge/arXiv-2303.11305-b31b1b.svg)](https://arxiv.org/abs/2303.11305) | :heavy_minus_sign: |
| MI-GAN: A Simple Baseline for Image Inpainting on Mobile Devices | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Structure and Content-Guided Video Synthesis with Diffusion Models | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://research.runwayml.com/gen1) | [![arXiv](https://img.shields.io/badge/arXiv-2302.03011-b31b1b.svg)](https://arxiv.org/abs/2302.03011) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Y2_JmgzTeeo) |
| Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yuxinn-j.github.io/projects/Scenimefy.html) <br /> [![GitHub](https://img.shields.io/github/stars/Yuxinn-J/Scenimefy)](https://github.com/Yuxinn-J/Scenimefy) <br /> [![Hugging Face](https://img.shields.io/badge/ðŸ¤—-Demo-FFD21F.svg)](https://huggingface.co/spaces/YuxinJ/Scenimefy) | [![arXiv](https://img.shields.io/badge/arXiv-2308.12968-b31b1b.svg)](https://arxiv.org/abs/2308.12968) | :heavy_minus_sign: |
| Efficient-VQGAN: Towards High-Resolution Image Generation with Efficient Vision Transformers | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| A Latent Space of Stochastic Diffusion Models for Zero-Shot Image Editing and Guidance | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Generative Multiplane Neural Radiance for 3D-Aware Image Generation | [![GitHub](https://img.shields.io/github/stars/VIROBO-15/GMNR)](https://github.com/VIROBO-15/GMNR) | [![arXiv](https://img.shields.io/badge/arXiv-2304.01172-b31b1b.svg)](https://arxiv.org/abs/2304.01172) | :heavy_minus_sign: |
| Parallax-Tolerant Unsupervised Deep Image Stitching | [![GitHub](https://img.shields.io/github/stars/nie-lang/UDIS2)](https://github.com/nie-lang/UDIS2) | [![arXiv](https://img.shields.io/badge/arXiv-2302.08207-b31b1b.svg)](https://arxiv.org/abs/2302.08207) | :heavy_minus_sign: |
| GAIT: Generating Aesthetic Indoor Tours with Deep Reinforcement Learning | [![GitHub](https://img.shields.io/github/stars/desaixie/gait)](https://github.com/desaixie/gait) | :heavy_minus_sign: | :heavy_minus_sign: |
| EverLight: Indoor-Outdoor Editable HDR Lighting Estimation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lvsn.github.io/everlight/) | [![arXiv](https://img.shields.io/badge/arXiv-2304.13207-b31b1b.svg)](https://arxiv.org/abs/2304.13207) | :heavy_minus_sign: |
| Prompt Tuning Inversion for Text-Driven Image Editing using Diffusion Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2305.04441-b31b1b.svg)](https://arxiv.org/abs/2305.04441) | :heavy_minus_sign: |
| Efficient Diffusion Training via Min-SNR Weighting Strategy | [![GitHub](https://img.shields.io/github/stars/TiankaiHang/Min-SNR-Diffusion-Training)](https://github.com/TiankaiHang/Min-SNR-Diffusion-Training) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09556-b31b1b.svg)](https://arxiv.org/abs/2303.09556) | :heavy_minus_sign: |
| BoxDiff: Text-to-Image Synthesis with Training-Free Box-Constrained Diffusion | [![GitHub](https://img.shields.io/github/stars/showlab/BoxDiff)](https://github.com/showlab/BoxDiff) | [![arXiv](https://img.shields.io/badge/arXiv-2307.10816-b31b1b.svg)](https://arxiv.org/abs/2307.10816) | :heavy_minus_sign: |
| Improving Sample Quality of Diffusion Models using Self-Attention Guidance | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ku-cvlab.github.io/Self-Attention-Guidance/) <br /> [![GitHub](https://img.shields.io/github/stars/KU-CVLAB/Self-Attention-Guidance)](https://github.com/KU-CVLAB/Self-Attention-Guidance) | [![arXiv](https://img.shields.io/badge/arXiv-2210.00939-b31b1b.svg)](https://arxiv.org/abs/2210.00939) | :heavy_minus_sign: |
| Not All Steps are Created Equal: Selective Diffusion Distillation for Image Manipulation | [![GitHub](https://img.shields.io/github/stars/EnVision-Research/Selective-Diffusion-Distillation)](https://github.com/EnVision-Research/Selective-Diffusion-Distillation) | [![arXiv](https://img.shields.io/badge/arXiv-2307.08448-b31b1b.svg)](https://arxiv.org/abs/2307.08448) | :heavy_minus_sign: |
| Deep Image Harmonization with Learnable Augmentation | [![GitHub](https://img.shields.io/github/stars/bcmi/SycoNet-Adaptive-Image-Harmonization)](https://github.com/bcmi/SycoNet-Adaptive-Image-Harmonization) | [![arXiv](https://img.shields.io/badge/arXiv-2308.00376-b31b1b.svg)](https://arxiv.org/abs/2308.00376) | :heavy_minus_sign: |
| Out-of-Domain GAN Inversion via Invertibility Decomposition for Photo-Realistic Human Face Manipulation | [![GitHub](https://img.shields.io/github/stars/AbnerVictor/OOD-GAN-inversion)](https://github.com/AbnerVictor/OOD-GAN-inversion) | [![arXiv](https://img.shields.io/badge/arXiv-2212.09262-b31b1b.svg)](https://arxiv.org/abs/2212.09262) | :heavy_minus_sign: |
| Bidirectionally Deformable Motion Modulation for Video-based Human Pose Transfer | [![GitHub](https://img.shields.io/github/stars/rocketappslab/bdmm)](https://github.com/rocketappslab/bdmm) | [![arXiv](https://img.shields.io/badge/arXiv-2307.07754-b31b1b.svg)](https://arxiv.org/abs/2307.07754) | :heavy_minus_sign: |
| Size does Matter: Size-Aware Virtual Try-On via Clothing-Oriented Transformation Try-On Network | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| VidStyleODE: Disentangled Video Editing via StyleGAN and NeuralODEs | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://cyberiada.github.io/VidStyleODE/) <br /> [![GitHub](https://img.shields.io/github/stars/MoayedHajiAli/VidStyleODE-official)](https://github.com/MoayedHajiAli/VidStyleODE-official) | [![arXiv](https://img.shields.io/badge/arXiv-2304.06020-b31b1b.svg)](https://arxiv.org/abs/2304.06020) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Cfh-mgr1isc) |
| Learning Global-Aware Kernel for Image Harmonization | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2305.11676-b31b1b.svg)](https://arxiv.org/abs/2305.11676) | :heavy_minus_sign: |
| Expressive Text-to-Image Generation with Rich Text | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rich-text-to-image.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/SongweiGe/rich-text-to-image)](https://github.com/SongweiGe/rich-text-to-image) <br /> [![Hugging Face](https://img.shields.io/badge/ðŸ¤—-Demo-FFD21F.svg)](https://huggingface.co/spaces/songweig/rich-text-to-image) | [![arXiv](https://img.shields.io/badge/arXiv-2304.06720-b31b1b.svg)](https://arxiv.org/abs/2304.06720) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ihDbAUh0LXk) |
| A Large-Scale Outdoor Multi-Modal Dataset and Benchmark for Novel View Synthesis and Implicit Scene Reconstruction | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://ommo.luchongshan.com/) <br /> [![GitHub](https://img.shields.io/github/stars/luchongshan/OMMO)](https://github.com/luchongshan/OMMO) | [![arXiv](https://img.shields.io/badge/arXiv-2301.06782-b31b1b.svg)](https://arxiv.org/abs/2301.06782) | [![Loom](https://a11ybadges.com/badge?logo=loom)](https://www.loom.com/share/7b9ed35bfb3649eda051398d3a51cda7) |
| Efficient Region-Aware Neural Radiance Fields for High-Fidelity Talking Portrait Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://fictionarry.github.io/ER-NeRF/) <br /> [![GitHub](https://img.shields.io/github/stars/Fictionarry/ER-NeRF)](https://github.com/Fictionarry/ER-NeRF) | [![arXiv](https://img.shields.io/badge/arXiv-2307.09323-b31b1b.svg)](https://arxiv.org/abs/2307.09323) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Gc2d3Z8MMuI) |
| Perceptual Artifacts Localization for Image Synthesis Tasks | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://owenzlz.github.io/PAL4VST/) <br /> [![GitHub](https://img.shields.io/github/stars/owenzlz/PAL4VST)](https://github.com/owenzlz/PAL4VST) | :heavy_minus_sign: | :heavy_minus_sign: |
| Learning to Generate Semantic Layouts for Higher Text-Image Correspondence in Text-to-Image Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://pmh9960.github.io/research/GCDP/) <br /> [![GitHub](https://img.shields.io/github/stars/pmh9960/GCDP)](https://github.com/pmh9960/GCDP) | [![arXiv](https://img.shields.io/badge/arXiv-2308.08157-b31b1b.svg)](https://arxiv.org/abs/2308.08157) | :heavy_minus_sign: |
| StylerDALLE: Language-Guided Style Transfer using a Vector-Quantized Tokenizer of a Large-Scale Generative Model | [![GitHub](https://img.shields.io/github/stars/zipengxuc/StylerDALLE)](https://github.com/zipengxuc/StylerDALLE) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09268-b31b1b.svg)](https://arxiv.org/abs/2303.09268) | :heavy_minus_sign: |
| Shortcut-V2V: Compression Framework for Video-to-Video Translation based on Temporal Redundancy Reduction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://shortcut-v2v.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2308.08011-b31b1b.svg)](https://arxiv.org/abs/2308.08011) | :heavy_minus_sign: |
| Tune-a-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://tuneavideo.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/showlab/Tune-A-Video)](https://github.com/showlab/Tune-A-Video) <br /> [![Hugging Face](https://img.shields.io/badge/ðŸ¤—-Demo-FFD21F.svg)](https://huggingface.co/spaces/Tune-A-Video-library/Tune-A-Video-Training-UI) | [![arXiv](https://img.shields.io/badge/arXiv-2212.11565-b31b1b.svg)](https://arxiv.org/abs/2212.11565) | :heavy_minus_sign: |
| BlendFace: Re-Designing Identity Encoders for Face-Swapping | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://mapooon.github.io/BlendFacePage/) <br /> [![GitHub](https://img.shields.io/github/stars/mapooon/BlendFace)](https://github.com/mapooon/BlendFace) | [![arXiv](https://img.shields.io/badge/arXiv-2307.10854-b31b1b.svg)](https://arxiv.org/abs/2307.10854) | :heavy_minus_sign: |
| Talking Head Generation with Probabilistic Audio-to-Visual Diffusion Priors | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zxyin.github.io/TH-PAD/) | [![arXiv](https://img.shields.io/badge/arXiv-2212.04248-b31b1b.svg)](https://arxiv.org/abs/2212.04248) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CrLXg7Cq8w8) |
| LinkGAN: Linking GAN Latents to Pixels for Controllable Image Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zhujiapeng.github.io/linkgan/) <br /> [![GitHub](https://img.shields.io/github/stars/zhujiapeng/linkgan)](https://github.com/zhujiapeng/linkgan) | [![arXiv](https://img.shields.io/badge/arXiv-2301.04604-b31b1b.svg)](https://arxiv.org/abs/2301.04604) | :heavy_minus_sign: |
| Open-Vocabulary Object Segmentation with Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lipurple.github.io/Grounded_Diffusion/) <br /> [![GitHub](https://img.shields.io/github/stars/Lipurple/Grounded-Diffusion)](https://github.com/Lipurple/Grounded-Diffusion) | [![arXiv](https://img.shields.io/badge/arXiv-2301.05221-b31b1b.svg)](https://arxiv.org/abs/2301.05221) | :heavy_minus_sign: |
| StyleDiffusion: Controllable Disentangled Style Transfer via Diffusion Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.07863-b31b1b.svg)](https://arxiv.org/abs/2308.07863) | :heavy_minus_sign: |
| ToonTalker: Cross-Domain Face Reenactment | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://opentalker.github.io/ToonTalker/) <br /> [![GitHub](https://img.shields.io/github/stars/OpenTalker/ToonTalker)](https://github.com/OpenTalker/ToonTalker) | [![arXiv](https://img.shields.io/badge/arXiv-2308.12866-b31b1b.svg)](https://arxiv.org/abs/2308.12866) | :heavy_minus_sign: |
| Dense Text-to-Image Generation with Attention Modulation | [![GitHub](https://img.shields.io/github/stars/naver-ai/DenseDiffusion)](https://github.com/naver-ai/DenseDiffusion) | [![arXiv](https://img.shields.io/badge/arXiv-2308.12964-b31b1b.svg)](https://arxiv.org/abs/2308.12964) | :heavy_minus_sign: |
| Householder Projector for Unsupervised Latent Semantics Discovery | [![GitHub](https://img.shields.io/github/stars/KingJamesSong/HouseholderGAN)](https://github.com/KingJamesSong/HouseholderGAN) | [![arXiv](https://img.shields.io/badge/arXiv-2307.08012-b31b1b.svg)](https://arxiv.org/abs/2307.08012) | :heavy_minus_sign: |
| Deep Image Harmonization with Globally Guided Feature Transformation and Relation Distillation | [![GitHub](https://img.shields.io/github/stars/bcmi/Image-Harmonization-Dataset-ccHarmony)](https://github.com/bcmi/Image-Harmonization-Dataset-ccHarmony) | [![arXiv](https://img.shields.io/badge/arXiv-2308.00356-b31b1b.svg)](https://arxiv.org/abs/2308.00356) | :heavy_minus_sign: |
| One-Shot Generative Domain Adaptation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://genforce.github.io/genda/) <br /> [![GitHub](https://img.shields.io/github/stars/genforce/genda)](https://github.com/genforce/genda) | [![arXiv](https://img.shields.io/badge/arXiv-2111.09876-b31b1b.svg)](https://arxiv.org/abs/2111.09876) | :heavy_minus_sign: |
| Hashing Neural Video Decomposition with Multiplicative Residuals in Space-Time | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lightbulb12294.github.io/hashing-nvd/) | :heavy_minus_sign: | :heavy_minus_sign: |
| Versatile Diffusion: Text, Images and Variations All in One Diffusion Model | [![GitHub](https://img.shields.io/github/stars/SHI-Labs/Versatile-Diffusion)](https://github.com/SHI-Labs/Versatile-Diffusion) <br /> [![Hugging Face](https://img.shields.io/badge/ðŸ¤—-Demo-FFD21F.svg)](https://huggingface.co/spaces/shi-labs/Versatile-Diffusion) | [![arXiv](https://img.shields.io/badge/arXiv-2211.08332-b31b1b.svg)](https://arxiv.org/abs/2211.08332) | :heavy_minus_sign: |
| Harnessing the Spatial-Temporal Attention of Diffusion Models for High-Fidelity Text-to-Image Synthesis | [![GitHub](https://img.shields.io/github/stars/UCSB-NLP-Chang/Diffusion-SpaceTime-Attn)](https://github.com/UCSB-NLP-Chang/Diffusion-SpaceTime-Attn) | [![arXiv](https://img.shields.io/badge/arXiv-2304.03869-b31b1b.svg)](https://arxiv.org/abs/2304.03869) | :heavy_minus_sign: |
| FreeDoM: Training-Free Energy-Guided Conditional Diffusion Model | [![GitHub](https://img.shields.io/github/stars/vvictoryuki/FreeDoM)](https://github.com/vvictoryuki/FreeDoM) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09833-b31b1b.svg)](https://arxiv.org/abs/2303.09833) | :heavy_minus_sign: |
