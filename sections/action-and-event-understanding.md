# ICCV-2023-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/motion-estimation-matching-and-tracking.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/computational-imaging.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" />
    </a>
</div>

## Action and Event Understanding

![Section Papers](https://img.shields.io/badge/Section%20Papers-30-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-22-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-19-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-1-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Weakly-Supervised Action Segmentation and Unseen Error Detection in Anomalous Instructional Videos | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ghoddoosian_Weakly-Supervised_Action_Segmentation_and_Unseen_Error_Detection_in_Anomalous_Instructional_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Diffusion Action Segmentation | [![GitHub](https://img.shields.io/github/stars/Finspire13/DiffAct)](https://github.com/Finspire13/DiffAct) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Diffusion_Action_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17959-b31b1b.svg)](https://arxiv.org/abs/2303.17959) | :heavy_minus_sign: |
| Audio-Visual Glance Network for Efficient Video Recognition | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Nugroho_Audio-Visual_Glance_Network_for_Efficient_Video_Recognition_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09322-b31b1b.svg)](https://arxiv.org/abs/2308.09322) | :heavy_minus_sign: |
| Learning from Noisy Pseudo Labels for Semi-Supervised Temporal Action Localization | [![GitHub](https://img.shields.io/github/stars/kunnxia/NPL)](https://github.com/kunnxia/NPL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Learning_from_Noisy_Pseudo_Labels_for_Semi-Supervised_Temporal_Action_Localization_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Video Action Recognition with Attentive Semantic Units | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Video_Action_Recognition_with_Attentive_Semantic_Units_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09756-b31b1b.svg)](https://arxiv.org/abs/2303.09756) | :heavy_minus_sign: |
| Masked Motion Predictors are Strong 3D Action Representation Learners | [![GitHub](https://img.shields.io/github/stars/maoyunyao/MAMP)](https://github.com/maoyunyao/MAMP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Mao_Masked_Motion_Predictors_are_Strong_3D_Action_Representation_Learners_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.07092-b31b1b.svg)](https://arxiv.org/abs/2308.07092) | :heavy_minus_sign: |
| Boosting Positive Segments for Weakly-Supervised Audio-Visual Video Parsing | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Rachavarapu_Boosting_Positive_Segments_for_Weakly-Supervised_Audio-Visual_Video_Parsing_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Weakly-Supervised Action Localization by Hierarchically-Structured Latent Attention Modeling | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Weakly-Supervised_Action_Localization_by_Hierarchically-Structured_Latent_Attention_Modeling_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09946-b31b1b.svg)](https://arxiv.org/abs/2308.09946) | :heavy_minus_sign: |
| Few-Shot Common Action Localization via Cross-Attentional Fusion of Context and Temporal Dynamics | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Few-Shot_Common_Action_Localization_via_Cross-Attentional_Fusion_of_Context_and_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Interaction-Aware Joint Attention Estimation using People Attributes | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.toyota-ti.ac.jp/Lab/Denshi/iim/ukita/selection/ICCV2023-PJAE.html) <br /> [![GitHub](https://img.shields.io/github/stars/chihina/PJAE)](https://github.com/chihina/PJAE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Nakatani_Interaction-aware_Joint_Attention_Estimation_Using_People_Attributes_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.05382-b31b1b.svg)](https://arxiv.org/abs/2308.05382) | :heavy_minus_sign: |
| FineDance: A Fine-Grained Choreography Dataset for 3D Full Body Dance Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://li-ronghui.github.io/finedance) <br /> [![GitHub](https://img.shields.io/github/stars/li-ronghui/FineDance)](https://github.com/li-ronghui/FineDance) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_FineDance_A_Fine-grained_Choreography_Dataset_for_3D_Full_Body_Dance_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.03741-b31b1b.svg)](https://arxiv.org/abs/2212.03741) | :heavy_minus_sign: |
| SOAR: Scene-Debiasing Open-Set Action Recognition | [![GitHub](https://img.shields.io/github/stars/yhZhai/SOAR)](https://github.com/yhZhai/SOAR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_SOAR_Scene-debiasing_Open-set_Action_Recognition_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.01265-b31b1b.svg)](https://arxiv.org/abs/2309.01265) | :heavy_minus_sign: |
| Leveraging Spatio-Temporal Dependency for Skeleton-based Action Recognition | [![GitHub](https://img.shields.io/github/stars/Jho-Yonsei/STC-Net)](https://github.com/Jho-Yonsei/STC-Net) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Leveraging_Spatio-Temporal_Dependency_for_Skeleton-Based_Action_Recognition_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.04761-b31b1b.svg)](https://arxiv.org/abs/2212.04761) | :heavy_minus_sign: |
| Cross-Modal Learning with 3D Deformable Attention for Action Recognition | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Cross-Modal_Learning_with_3D_Deformable_Attention_for_Action_Recognition_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.05638-b31b1b.svg)](https://arxiv.org/abs/2212.05638) | :heavy_minus_sign: |
| Generative Action Description Prompts for Skeleton-based Action Recognition | [![GitHub](https://img.shields.io/github/stars/MartinXM/GAP)](https://github.com/MartinXM/GAP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Generative_Action_Description_Prompts_for_Skeleton-based_Action_Recognition_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2208.05318-b31b1b.svg)](https://arxiv.org/abs/2208.05318) | :heavy_minus_sign: |
| Self-Feedback DETR for Temporal Action Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Self-Feedback_DETR_for_Temporal_Action_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10570-b31b1b.svg)](https://arxiv.org/abs/2308.10570) | :heavy_minus_sign: |
| Skip-Plan: Procedure Planning in Instructional Videos via Condensed Action Space Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Skip-Plan_Procedure_Planning_in_Instructional_Videos_via_Condensed_Action_Space_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| The Unreasonable Effectiveness of Large Language-Vision Models for Source-Free Video Domain Adaptation | [![GitHub](https://img.shields.io/github/stars/giaczara/dallv)](https://github.com/giaczara/dallv) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zara_The_Unreasonable_Effectiveness_of_Large_Language-Vision_Models_for_Source-Free_Video_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09139-b31b1b.svg)](https://arxiv.org/abs/2308.09139) | :heavy_minus_sign: |
| Multimodal Motion Conditioned Diffusion Model for Skeleton-based Video Anomaly Detection | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.pinlab.org/mocodad) <br /> [![GitHub](https://img.shields.io/github/stars/aleflabo/MoCoDAD)](https://github.com/aleflabo/MoCoDAD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Flaborea_Multimodal_Motion_Conditioned_Diffusion_Model_for_Skeleton-based_Video_Anomaly_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.07205-b31b1b.svg)](https://arxiv.org/abs/2307.07205) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=IuDzVez--9U) |
| Video Anomaly Detection via Sequentially Learning Multiple Pretext Tasks | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Video_Anomaly_Detection_via_Sequentially_Learning_Multiple_Pretext_Tasks_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| MiniROAD: Minimal RNN Framework for Online Action Detection | [![GitHub](https://img.shields.io/github/stars/jbistanbul/MiniROAD)](https://github.com/jbistanbul/MiniROAD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/An_MiniROAD_Minimal_RNN_Framework_for_Online_Action_Detection_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| How much Temporal Long-Term Context is Needed for Action Segmentation? | [![GitHub](https://img.shields.io/github/stars/LTContext/LTContext)](https://github.com/LTContext/LTContext) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Bahrami_How_Much_Temporal_Long-Term_Context_is_Needed_for_Action_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11358-b31b1b.svg)](https://arxiv.org/abs/2308.11358) | :heavy_minus_sign: |
| DiffTAD: Temporal Action Detection with Proposal Denoising Diffusion | [![GitHub](https://img.shields.io/github/stars/sauradip/DiffusionTAD)](https://github.com/sauradip/DiffusionTAD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Nag_DiffTAD_Temporal_Action_Detection_with_Proposal_Denoising_Diffusion_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14863-b31b1b.svg)](https://arxiv.org/abs/2303.14863) | :heavy_minus_sign: |
| STEPs: Self-Supervised Key Step Extraction and Localization from Unlabeled Procedural Videos | [![GitHub](https://img.shields.io/github/stars/anshulbshah/STEPs)](https://github.com/anshulbshah/STEPs) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Shah_STEPs_Self-Supervised_Key_Step_Extraction_and_Localization_from_Unlabeled_Procedural_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.00794-b31b1b.svg)](https://arxiv.org/abs/2301.00794) | :heavy_minus_sign: |
| Efficient Video Action Detection with Token Dropout and Context Refinement | [![GitHub](https://img.shields.io/github/stars/MCG-NJU/EVAD)](https://github.com/MCG-NJU/EVAD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Efficient_Video_Action_Detection_with_Token_Dropout_and_Context_Refinement_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.08451-b31b1b.svg)](https://arxiv.org/abs/2304.08451) | :heavy_minus_sign: |
| FSAR: Federated Skeleton-based Action Recognition with Adaptive Topology Structure and Knowledge Distillation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_FSAR_Federated_Skeleton-based_Action_Recognition_with_Adaptive_Topology_Structure_and_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.11046-b31b1b.svg)](https://arxiv.org/abs/2306.11046) | :heavy_minus_sign: |
| Exploring Predicate Visual Context in Detecting of Human-Object Interactions | [![GitHub](https://img.shields.io/github/stars/fredzzhang/pvic)](https://github.com/fredzzhang/pvic) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Exploring_Predicate_Visual_Context_in_Detecting_of_Human-Object_Interactions_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.06202-b31b1b.svg)](https://arxiv.org/abs/2308.06202) | :heavy_minus_sign: |
| E2E-LOAD: End-to-End Long-Form Online Action Detection | [![GitHub](https://img.shields.io/github/stars/sqiangcao99/E2E-LOAD)](https://github.com/sqiangcao99/E2E-LOAD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_E2E-LOAD_End-to-End_Long-form_Online_Action_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.07703-b31b1b.svg)](https://arxiv.org/abs/2306.07703) | :heavy_minus_sign: |
| Revisiting Foreground and Background Separation in Weakly-Supervised Temporal Action Localization: A Clustering-based Approach | [![GitHub](https://img.shields.io/github/stars/Qinying-Liu/CASE)](https://github.com/Qinying-Liu/CASE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Revisiting_Foreground_and_Background_Separation_in_Weakly-supervised_Temporal_Action_Localization_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Hierarchically Decomposed Graph Convolutional Networks for Skeleton-based Action Recognition | [![GitHub](https://img.shields.io/github/stars/Jho-Yonsei/HD-GCN)](https://github.com/Jho-Yonsei/HD-GCN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Hierarchically_Decomposed_Graph_Convolutional_Networks_for_Skeleton-Based_Action_Recognition_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2208.10741-b31b1b.svg)](https://arxiv.org/abs/2208.10741) | :heavy_minus_sign: |
