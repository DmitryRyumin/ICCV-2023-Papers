# ICCV-2023-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/vision-graphics-and-robotics.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/fairness-privacy-ethics-social-good-transparency-accountability-in-vision.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" />
    </a>
</div>

## Privacy, Security, Fairness, and Explainability

![Section Papers](https://img.shields.io/badge/Section%20Papers-8-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-8-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-7-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Zolly: Zoom Focal Length Correctly for Perspective-Distorted Human Mesh Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://wenjiawang0312.github.io/projects/zolly/) <br /> [![GitHub](https://img.shields.io/github/stars/WenjiaWang0312/Zolly?style=flat)](https://github.com/WenjiaWang0312/Zolly) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Zolly_Zoom_Focal_Length_Correctly_for_Perspective-Distorted_Human_Mesh_Reconstruction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13796-b31b1b.svg)](https://arxiv.org/abs/2303.13796) | :heavy_minus_sign: |
| ACLS: Adaptive and Conditional Label Smoothing for Network Calibration | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://cvlab.yonsei.ac.kr/projects/ACLS/) <br /> [![GitHub](https://img.shields.io/github/stars/cvlab-yonsei/ACLS?style=flat)](https://github.com/cvlab-yonsei/ACLS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Park_ACLS_Adaptive_and_Conditional_Label_Smoothing_for_Network_Calibration_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11911-b31b1b.svg)](https://arxiv.org/abs/2308.11911) | :heavy_minus_sign: |
| PGFed: Personalize Each Client's Global Objective for Federated Learning | [![GitHub](https://img.shields.io/github/stars/ljaiverson/pgfed?style=flat)](https://github.com/ljaiverson/pgfed) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_PGFed_Personalize_Each_Clients_Global_Objective_for_Federated_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.01448-b31b1b.svg)](https://arxiv.org/abs/2212.01448) | :heavy_minus_sign: |
| Overwriting Pretrained Bias with Finetuning Data | [![GitHub](https://img.shields.io/github/stars/princetonvisualai/overcoming-pretraining-bias?style=flat)](https://github.com/princetonvisualai/overcoming-pretraining-bias) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Overwriting_Pretrained_Bias_with_Finetuning_Data_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06167-b31b1b.svg)](https://arxiv.org/abs/2303.06167) <br /> [![ResearchGate](https://img.shields.io/badge/Research-Gate-D7E7F5.svg)](https://www.researchgate.net/publication/369199104_Overcoming_Bias_in_Pretrained_Models_by_Manipulating_the_Finetuning_Dataset) | :heavy_minus_sign: |
| ITI-GEN: Inclusive Text-to-Image Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://czhang0528.github.io/iti-gen) <br /> [![GitHub](https://img.shields.io/github/stars/humansensinglab/ITI-GEN?style=flat)](https://github.com/humansensinglab/ITI-GEN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ITI-GEN_Inclusive_Text-to-Image_Generation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.05569-b31b1b.svg)](https://arxiv.org/abs/2309.05569) | :heavy_minus_sign: |
| FunnyBirds: A Synthetic Vision Dataset for a Part-based Analysis of Explainable AI Methods | [![GitHub](https://img.shields.io/github/stars/visinf/funnybirds?style=flat)](https://github.com/visinf/funnybirds) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hesse_FunnyBirds_A_Synthetic_Vision_Dataset_for_a_Part-Based_Analysis_of_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.06248-b31b1b.svg)](https://arxiv.org/abs/2308.06248) | :heavy_minus_sign: |
| X-VoE: Measuring eXplanatory Violation of Expectation in Physical Events | [![GitHub](https://img.shields.io/github/stars/daibopku/X-VoE?style=flat)](https://github.com/daibopku/X-VoE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Dai_X-VoE_Measuring_eXplanatory_Violation_of_Expectation_in_Physical_Events_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10441-b31b1b.svg)](https://arxiv.org/abs/2308.10441) | :heavy_minus_sign: |
| Adaptive Testing of Computer Vision Models | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Adaptive_Testing_of_Computer_Vision_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.02774-b31b1b.svg)](https://arxiv.org/abs/2212.02774) | :heavy_minus_sign: |
