# ICCV-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/vision-applications-and-systems.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/2023/main/w-scene-graphs-and-graph-representation-learning.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Machine Learning and Dataset

![Section Papers](https://img.shields.io/badge/Section%20Papers-12-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-10-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-10-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-3-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| DiffusionDet: Diffusion Model for Object Detection | [![GitHub](https://img.shields.io/github/stars/ShoufaChen/DiffusionDet?style=flat)](https://github.com/ShoufaChen/DiffusionDet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_DiffusionDet_Diffusion_Model_for_Object_Detection_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.09788-b31b1b.svg)](https://arxiv.org/abs/2211.09788) | :heavy_minus_sign: |
| V3Det: Vast Vocabulary Visual Detection Dataset | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://v3det.openxlab.org.cn/) <br /> [![GitHub](https://img.shields.io/github/stars/V3Det/V3Det?style=flat)](https://github.com/V3Det/V3Det) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_V3Det_Vast_Vocabulary_Visual_Detection_Dataset_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.03752-b31b1b.svg)](https://arxiv.org/abs/2304.03752) | :heavy_minus_sign: |
| PointOdyssey: A Large-Scale Synthetic Dataset for Long-Term Point Tracking | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://pointodyssey.com/) <br /> [![GitHub](https://img.shields.io/github/stars/aharley/pips2?style=flat)](https://github.com/aharley/pips2) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_PointOdyssey_A_Large-Scale_Synthetic_Dataset_for_Long-Term_Point_Tracking_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.15055-b31b1b.svg)](https://arxiv.org/abs/2307.15055) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=BL-1nbA4G0M) |
| Label-Free Event-based Object Recognition via Joint Learning with Image Reconstruction from Events | [![GitHub](https://img.shields.io/github/stars/Chohoonhee/Ev-LaFOR?style=flat)](https://github.com/Chohoonhee/Ev-LaFOR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Label-Free_Event-based_Object_Recognition_via_Joint_Learning_with_Image_Reconstruction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09383-b31b1b.svg)](https://arxiv.org/abs/2308.09383) | :heavy_minus_sign: |
| Vision HGNN: An Image is more than a Graph of Nodes | [![GitHub](https://img.shields.io/github/stars/VITA-Group/ViHGNN?style=flat)](https://github.com/VITA-Group/ViHGNN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Vision_HGNN_An_Image_is_More_than_a_Graph_of_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Revisiting Vision Transformer from the View of Path Ensemble | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_Revisiting_Vision_Transformer_from_the_View_of_Path_Ensemble_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.06548-b31b1b.svg)](https://arxiv.org/abs/2308.06548) | :heavy_minus_sign: |
| All in Tokens: Unifying Output Space of Visual Tasks via Soft Token | [![GitHub](https://img.shields.io/github/stars/SwinTransformer/AiT?style=flat)](https://github.com/SwinTransformer/AiT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ning_All_in_Tokens_Unifying_Output_Space_of_Visual_Tasks_via_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.02229-b31b1b.svg)](https://arxiv.org/abs/2301.02229) | :heavy_minus_sign: |
| Mitigating and Evaluating Static Bias of Action Representations in the Background and the Foreground | [![GitHub](https://img.shields.io/github/stars/lihaoxin05/StillMix?style=flat)](https://github.com/lihaoxin05/StillMix) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Mitigating_and_Evaluating_Static_Bias_of_Action_Representations_in_the_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12883-b31b1b.svg)](https://arxiv.org/abs/2211.12883) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=tlYqLpLGVbU) |
| Deep Multitask Learning with Progressive Parameter Sharing | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Deep_Multitask_Learning_with_Progressive_Parameter_Sharing_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Implicit Temporal Modeling with Learnable Alignment for Video Recognition | [![GitHub](https://img.shields.io/github/stars/Francis-Rings/ILA?style=flat)](https://github.com/Francis-Rings/ILA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_Implicit_Temporal_Modeling_with_Learnable_Alignment_for_Video_Recognition_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.10465-b31b1b.svg)](https://arxiv.org/abs/2304.10465) | :heavy_minus_sign: |
| Unmasked Teacher: Towards Training-Efficient Video Foundation Models | [![GitHub](https://img.shields.io/github/stars/OpenGVLab/unmasked_teacher?style=flat)](https://github.com/OpenGVLab/unmasked_teacher) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Unmasked_Teacher_Towards_Training-Efficient_Video_Foundation_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16058-b31b1b.svg)](https://arxiv.org/abs/2303.16058) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=pkTwHS36BmY) |
| Large-Scale Person Detection and Localization using Overhead Fisheye Cameras | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://loafisheye.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/BUPT-PRIV/LOAF?style=flat)](https://github.com/BUPT-PRIV/LOAF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Large-Scale_Person_Detection_and_Localization_Using_Overhead_Fisheye_Cameras_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.08252-b31b1b.svg)](https://arxiv.org/abs/2307.08252) | :heavy_minus_sign: |
