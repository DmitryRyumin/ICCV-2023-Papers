# ICCV-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/3d-from-multi-view-and-sensors.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/vision-and-robotics.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Adversarial Attack and Defense

![Section Papers](https://img.shields.io/badge/Section%20Papers-53-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-41-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-36-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-2-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Robust Mixture-of-Expert Training for Convolutional Neural Networks | [![GitHub](https://img.shields.io/github/stars/OPTML-Group/Robust-MoE-CNN?style=flat)](https://github.com/OPTML-Group/Robust-MoE-CNN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Robust_Mixture-of-Expert_Training_for_Convolutional_Neural_Networks_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10110-b31b1b.svg)](https://arxiv.org/abs/2308.10110) | :heavy_minus_sign: |
| Set-Level Guidance Attack: Boosting Adversarial Transferability of Vision-Language Pre-Training Models | [![GitHub](https://img.shields.io/github/stars/Zoky-2020/SGA?style=flat)](https://github.com/Zoky-2020/SGA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Set-level_Guidance_Attack_Boosting_Adversarial_Transferability_of_Vision-Language_Pre-training_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.14061-b31b1b.svg)](https://arxiv.org/abs/2307.14061) | :heavy_minus_sign: |
| CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive Learning | [![GitHub](https://img.shields.io/github/stars/nishadsinghi/CleanCLIP?style=flat)](https://github.com/nishadsinghi/CleanCLIP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Bansal_CleanCLIP_Mitigating_Data_Poisoning_Attacks_in_Multimodal_Contrastive_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.03323-b31b1b.svg)](https://arxiv.org/abs/2303.03323) | :heavy_minus_sign: |
| CGBA: Curvature-Aware Geometric Black-Box Attack | [![GitHub](https://img.shields.io/github/stars/Farhamdur/CGBA?style=flat)](https://github.com/Farhamdur/CGBA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Reza_CGBA_Curvature-aware_Geometric_Black-box_Attack_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.03163-b31b1b.svg)](https://arxiv.org/abs/2308.03163) | :heavy_minus_sign: |
| Robust Evaluation of Diffusion-based Adversarial Purification | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Robust_Evaluation_of_Diffusion-Based_Adversarial_Purification_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09051-b31b1b.svg)](https://arxiv.org/abs/2303.09051) | :heavy_minus_sign: |
| Advancing Example Exploitation can Alleviate Critical Challenges in Adversarial Training | [![GitHub](https://img.shields.io/github/stars/geyao1995/advancing-example-exploitation-in-adversarial-training?style=flat)](https://github.com/geyao1995/advancing-example-exploitation-in-adversarial-training) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Advancing_Example_Exploitation_Can_Alleviate_Critical_Challenges_in_Adversarial_Training_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| The Victim and the Beneficiary: Exploiting a Poisoned Model to Train a Clean Model on Poisoned Data | [![GitHub](https://img.shields.io/github/stars/Zixuan-Zhu/VaB?style=flat)](https://github.com/Zixuan-Zhu/VaB) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_The_Victim_and_The_Beneficiary_Exploiting_a_Poisoned_Model_to_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| TIJO: Trigger Inversion with Joint Optimization for Defending Multimodal Backdoored Models | [![GitHub](https://img.shields.io/github/stars/SRI-CSL/TIJO?style=flat)](https://github.com/SRI-CSL/TIJO) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Sur_TIJO_Trigger_Inversion_with_Joint_Optimization_for_Defending_Multimodal_Backdoored_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.03906-b31b1b.svg)](https://arxiv.org/abs/2308.03906) | :heavy_minus_sign: |
| SAGA: Spectral Adversarial Geometric Attack on 3D Meshes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://stoliktomer.github.io/SAGA/) <br /> [![GitHub](https://img.shields.io/github/stars/StolikTomer/SAGA?style=flat)](https://github.com/StolikTomer/SAGA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Stolik_SAGA_Spectral_Adversarial_Geometric_Attack_on_3D_Meshes_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.13775-b31b1b.svg)](https://arxiv.org/abs/2211.13775) | :heavy_minus_sign: |
| Benchmarking and Analyzing Robust Point Cloud Recognition: Bag of Tricks for Defending Adversarial Examples | [![GitHub](https://img.shields.io/github/stars/qiufan319/benchmark_pc_attack?style=flat)](https://github.com/qiufan319/benchmark_pc_attack) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Benchmarking_and_Analyzing_Robust_Point_Cloud_Recognition_Bag_of_Tricks_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.16361-b31b1b.svg)](https://arxiv.org/abs/2307.16361) | :heavy_minus_sign: |
| ACTIVE: Towards Highly Transferable 3D Physical Camouflage for Universal and Robust Vehicle Evasion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://islab-ai.github.io/active-iccv2023/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Suryanto_ACTIVE_Towards_Highly_Transferable_3D_Physical_Camouflage_for_Universal_and_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.07009-b31b1b.svg)](https://arxiv.org/abs/2308.07009) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=m6m90kX0O3w) |
| Frequency-Aware GAN for Adversarial Manipulation Generation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Frequency-aware_GAN_for_Adversarial_Manipulation_Generation_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Breaking Temporal Consistency: Generating Video Universal Adversarial Perturbations using Image Models | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Breaking_Temporal_Consistency_Generating_Video_Universal_Adversarial_Perturbations_Using_Image_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Tracing the Origin of Adversarial Attack for Forensic Investigation and Deterrence | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Tracing_the_Origin_of_Adversarial_Attack_for_Forensic_Investigation_and_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.01218-b31b1b.svg)](https://arxiv.org/abs/2301.01218) | :heavy_minus_sign: |
| Downstream-Agnostic Adversarial Examples | [![GitHub](https://img.shields.io/github/stars/CGCL-codes/AdvEncoder?style=flat)](https://github.com/CGCL-codes/AdvEncoder) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Downstream-agnostic_Adversarial_Examples_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.12280-b31b1b.svg)](https://arxiv.org/abs/2307.12280) | :heavy_minus_sign: |
| Hiding Visual Information via Obfuscating Adversarial Perturbations | [![GitHub](https://img.shields.io/github/stars/suzhigangssz/AVIH?style=flat)](https://github.com/suzhigangssz/AVIH) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Su_Hiding_Visual_Information_via_Obfuscating_Adversarial_Perturbations_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2209.15304-b31b1b.svg)](https://arxiv.org/abs/2209.15304) | :heavy_minus_sign: |
| An Embarrassingly Simple Backdoor Attack on Self-Supervised Learning | [![GitHub](https://img.shields.io/github/stars/meet-cjli/CTRL?style=flat)](https://github.com/meet-cjli/CTRL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_An_Embarrassingly_Simple_Backdoor_Attack_on_Self-supervised_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2210.07346-b31b1b.svg)](https://arxiv.org/abs/2210.07346) | :heavy_minus_sign: |
| Efficient Decision-based Black-Box Patch Attacks on Video Recognition | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Efficient_Decision-based_Black-box_Patch_Attacks_on_Video_Recognition_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11917-b31b1b.svg)](https://arxiv.org/abs/2303.11917) | :heavy_minus_sign: |
| Adversarial Finetuning with Latent Representation Constraint to Mitigate Accuracy-Robustness Tradeoff | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Suzuki_Adversarial_Finetuning_with_Latent_Representation_Constraint_to_Mitigate_Accuracy-Robustness_Tradeoff_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.16454-b31b1b.svg)](https://arxiv.org/abs/2308.16454) | :heavy_minus_sign: |
| Towards Building more Robust Models with Frequency Bias | [![GitHub](https://img.shields.io/github/stars/retsuh-bqw/ICCV23-Towards-Building-More-Robust-Models-with-Frequency-Bias?style=flat)](https://github.com/retsuh-bqw/ICCV23-Towards-Building-More-Robust-Models-with-Frequency-Bias) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Bu_Towards_Building_More_Robust_Models_with_Frequency_Bias_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.09763-b31b1b.svg)](https://arxiv.org/abs/2307.09763) | :heavy_minus_sign: |
| Does Physical Adversarial Example Really Matter to Autonomous Driving? Towards System-Level Effect of Adversarial Object Evasion Attack | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://sites.google.com/view/cav-sec/sysadv) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Does_Physical_Adversarial_Example_Really_Matter_to_Autonomous_Driving_Towards_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11894-b31b1b.svg)](https://arxiv.org/abs/2308.11894) | :heavy_minus_sign: |
| Improving Generalization of Adversarial Training via Robust Critical Fine-Tuning | [![GitHub](https://img.shields.io/github/stars/microsoft/robustlearn?style=flat)](https://github.com/microsoft/robustlearn) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Improving_Generalization_of_Adversarial_Training_via_Robust_Critical_Fine-Tuning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.02533-b31b1b.svg)](https://arxiv.org/abs/2308.02533) | :heavy_minus_sign: |
| Enhancing Generalization of Universal Adversarial Perturbation through Gradient Aggregation | [![GitHub](https://img.shields.io/github/stars/liuxuannan/Stochastic-Gradient-Aggregation?style=flat)](https://github.com/liuxuannan/Stochastic-Gradient-Aggregation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Enhancing_Generalization_of_Universal_Adversarial_Perturbation_through_Gradient_Aggregation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.06015-b31b1b.svg)](https://arxiv.org/abs/2308.06015) | :heavy_minus_sign: |
| Unified Adversarial Patch for Cross-Modal Attacks in the Physical World | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Unified_Adversarial_Patch_for_Cross-Modal_Attacks_in_the_Physical_World_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.07859-b31b1b.svg)](https://arxiv.org/abs/2307.07859) | :heavy_minus_sign: |
| RFLA: A Stealthy Reflected Light Adversarial Attack in the Physical World | [![GitHub](https://img.shields.io/github/stars/winterwindwang/RFLA?style=flat)](https://github.com/winterwindwang/RFLA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_RFLA_A_Stealthy_Reflected_Light_Adversarial_Attack_in_the_Physical_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.07653-b31b1b.svg)](https://arxiv.org/abs/2307.07653) | :heavy_minus_sign: |
| Enhancing Fine-Tuning based Backdoor Defense with Sharpness-Aware Minimization | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Enhancing_Fine-Tuning_Based_Backdoor_Defense_with_Sharpness-Aware_Minimization_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.11823-b31b1b.svg)](https://arxiv.org/abs/2304.11823) | :heavy_minus_sign: |
| Conditional 360-Degree Image Synthesis for Immersive Indoor Scene Decoration | [![GitHub](https://img.shields.io/github/stars/kcshum/neural_360_decoration?style=flat)](https://github.com/kcshum/neural_360_decoration) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Shum_Conditional_360-degree_Image_Synthesis_for_Immersive_Indoor_Scene_Decoration_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.09621-b31b1b.svg)](https://arxiv.org/abs/2307.09621) | :heavy_minus_sign: |
| An Adaptive Model Ensemble Adversarial Attack for Boosting Adversarial Transferability | [![GitHub](https://img.shields.io/github/stars/CHENBIN99/AdaEA?style=flat)](https://github.com/CHENBIN99/AdaEA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_An_Adaptive_Model_Ensemble_Adversarial_Attack_for_Boosting_Adversarial_Transferability_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.02897-b31b1b.svg)](https://arxiv.org/abs/2308.02897) | :heavy_minus_sign: |
| Mitigating Adversarial Vulnerability through Causal Parameter Estimation by Adversarial Double Machine Learning | [![GitHub](https://img.shields.io/github/stars/ByungKwanLee/Double-Debiased-Adversary?style=flat)](https://github.com/ByungKwanLee/Double-Debiased-Adversary) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Mitigating_Adversarial_Vulnerability_through_Causal_Parameter_Estimation_by_Adversarial_Double_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.07250-b31b1b.svg)](https://arxiv.org/abs/2307.07250) | :heavy_minus_sign: |
| LEA<sup>2</sup>: A Lightweight Ensemble Adversarial Attack via Non-Overlapping Vulnerable Frequency Regions | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_LEA2_A_Lightweight_Ensemble_Adversarial_Attack_via_Non-overlapping_Vulnerable_Frequency_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Explaining Adversarial Robustness of Neural Networks from Clustering Effect Perspective | [![GitHub](https://img.shields.io/github/stars/clustering-effect/SAT?style=flat)](https://github.com/clustering-effect/SAT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Explaining_Adversarial_Robustness_of_Neural_Networks_from_Clustering_Effect_Perspective_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| VertexSerum: Poisoning Graph Neural Networks for Link Inference | [![GitHub](https://img.shields.io/github/stars/RollinDing/VertexSerum?style=flat)](https://github.com/RollinDing/VertexSerum) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_VertexSerum_Poisoning_Graph_Neural_Networks_for_Link_Inference_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.01469-b31b1b.svg)](https://arxiv.org/abs/2308.01469) | :heavy_minus_sign: |
| How to Choose Your Best Allies for a Transferable Attack? | [![GitHub](https://img.shields.io/github/stars/t-maho/transferability_measure_fit?style=flat)](https://github.com/t-maho/transferability_measure_fit) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Maho_How_to_Choose_your_Best_Allies_for_a_Transferable_Attack_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.02312-b31b1b.svg)](https://arxiv.org/abs/2304.02312) | :heavy_minus_sign: |
| Enhancing Adversarial Robustness in Low-Label Regime via Adaptively Weighted Regularization and Knowledge Distillation | [![GitHub](https://img.shields.io/github/stars/dyoony/SRST_AWR?style=flat)](https://github.com/dyoony/SRST_AWR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Enhancing_Adversarial_Robustness_in_Low-Label_Regime_via_Adaptively_Weighted_Regularization_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.04061-b31b1b.svg)](https://arxiv.org/abs/2308.04061) | :heavy_minus_sign: |
| AdvDiffuser: Natural Adversarial Example Synthesis with Diffusion Models | [![GitHub](https://img.shields.io/github/stars/lafeat/advdiffuser?style=flat)](https://github.com/lafeat/advdiffuser) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AdvDiffuser_Natural_Adversarial_Example_Synthesis_with_Diffusion_Models_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| F&F Attack: Adversarial Attack against Multiple Object Trackers by Inducing
False Negatives and False Positives | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://infzhou.github.io/FnFAttack/index.html) <br /> [![GitHub](https://img.shields.io/github/stars/infZhou/FnF_Attack?style=flat)](https://github.com/infZhou/FnF_Attack) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_FF_Attack_Adversarial_Attack_against_Multiple_Object_Trackers_by_Inducing_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Rickrolling the Artist: Injecting Backdoors into Text Encoders for Text-to-Image Synthesis | [![GitHub](https://img.shields.io/github/stars/LukasStruppek/Rickrolling-the-Artist?style=flat)](https://github.com/LukasStruppek/Rickrolling-the-Artist) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Struppek_Rickrolling_the_Artist_Injecting_Backdoors_into_Text_Encoders_for_Text-to-Image_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.02408-b31b1b.svg)](https://arxiv.org/abs/2211.02408) | :heavy_minus_sign: |
| Hard No-Box Adversarial Attack on Skeleton-based Human Action Recognition with Skeleton-Motion-Informed Gradient | [![GitHub](https://img.shields.io/github/stars/luyg45/HardNoBoxAttack?style=flat)](https://github.com/luyg45/HardNoBoxAttack) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Hard_No-Box_Adversarial_Attack_on_Skeleton-Based_Human_Action_Recognition_with_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.05681-b31b1b.svg)](https://arxiv.org/abs/2308.05681) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=hvniybZIiqA) |
| Structure Invariant Transformation for Better Adversarial Transferability | [![GitHub](https://img.shields.io/github/stars/xiaosen-wang/SIT?style=flat)](https://github.com/xiaosen-wang/SIT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Structure_Invariant_Transformation_for_better_Adversarial_Transferability_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Beating Backdoor Attack at its Own Game | [![GitHub](https://img.shields.io/github/stars/damianliumin/non-adversarial_backdoor?style=flat)](https://github.com/damianliumin/non-adversarial_backdoor) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Beating_Backdoor_Attack_at_Its_Own_Game_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.15539-b31b1b.svg)](https://arxiv.org/abs/2307.15539) | :heavy_minus_sign: |
| Transferable Adversarial Attack for Both Vision Transformers and Convolutional Networks via Momentum Integrated Gradients | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Transferable_Adversarial_Attack_for_Both_Vision_Transformers_and_Convolutional_Networks_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| REAP: A Large-Scale Realistic Adversarial Patch Benchmark | [![GitHub](https://img.shields.io/github/stars/wagner-group/reap-benchmark?style=flat)](https://github.com/wagner-group/reap-benchmark) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hingun_REAP_A_Large-Scale_Realistic_Adversarial_Patch_Benchmark_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.05680-b31b1b.svg)](https://arxiv.org/abs/2212.05680) | :heavy_minus_sign: |
| Multi-Metrics Adaptively Identifies Backdoors in Federated Learning | [![GitHub](https://img.shields.io/github/stars/siquanhuang/Multi-metrics_against_backdoors_in_FL?style=flat)](https://github.com/siquanhuang/Multi-metrics_against_backdoors_in_FL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Multi-Metrics_Adaptively_Identifies_Backdoors_in_Federated_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06601-b31b1b.svg)](https://arxiv.org/abs/2303.06601) | :heavy_minus_sign: |
| Backpropagation Path Search on Adversarial Transferability | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Backpropagation_Path_Search_On_Adversarial_Transferability_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.07625-b31b1b.svg)](https://arxiv.org/abs/2308.07625) | :heavy_minus_sign: |
| Rapid Network Adaptation: Learning to Adapt Neural Networks using Test-Time Feedback | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://rapid-network-adaptation.epfl.ch/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yeo_Rapid_Network_Adaptation_Learning_to_Adapt_Neural_Networks_Using_Test-Time_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.15762-b31b1b.svg)](https://arxiv.org/abs/2309.15762) | :heavy_minus_sign: |
| One-Bit Flip is All You Need: When Bit-Flip Attack Meets Model Training | [![GitHub](https://img.shields.io/github/stars/jianshuod/TBA?style=flat)](https://github.com/jianshuod/TBA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_One-bit_Flip_is_All_You_Need_When_Bit-flip_Attack_Meets_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.07934-b31b1b.svg)](https://arxiv.org/abs/2308.07934) | :heavy_minus_sign: |
| PolicyCleanse: Backdoor Detection and Mitigation for Competitive Reinforcement Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_PolicyCleanse_Backdoor_Detection_and_Mitigation_for_Competitive_Reinforcement_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2202.03609-b31b1b.svg)](https://arxiv.org/abs/2202.03609) | :heavy_minus_sign: |
| Towards Viewpoint-Invariant Visual Recognition via Adversarial Training | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ruan_Towards_Viewpoint-Invariant_Visual_Recognition_via_Adversarial_Training_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.10235-b31b1b.svg)](https://arxiv.org/abs/2307.10235) | :heavy_minus_sign: |
| Fast Adversarial Training with Smooth Convergence | [![GitHub](https://img.shields.io/github/stars/FAT-CS/ConvergeSmooth?style=flat)](https://github.com/FAT-CS/ConvergeSmooth) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Fast_Adversarial_Training_with_Smooth_Convergence_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.12857-b31b1b.svg)](https://arxiv.org/abs/2308.12857) | :heavy_minus_sign: |
| The Perils of Learning from Unlabeled Data: Backdoor Attacks on Semi-Supervised Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Shejwalkar_The_Perils_of_Learning_From_Unlabeled_Data_Backdoor_Attacks_on_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.00453-b31b1b.svg)](https://arxiv.org/abs/2211.00453) | :heavy_minus_sign: |
| Boosting Adversarial Transferability via Gradient Relevance Attack | [![GitHub](https://img.shields.io/github/stars/RYC-98/GRA?style=flat)](https://github.com/RYC-98/GRA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Boosting_Adversarial_Transferability_via_Gradient_Relevance_Attack_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Towards Robust Model Watermark via Reducing Parametric Vulnerability | [![GitHub](https://img.shields.io/github/stars/GuanhaoGan/robust-model-watermarking?style=flat)](https://github.com/GuanhaoGan/robust-model-watermarking) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Gan_Towards_Robust_Model_Watermark_via_Reducing_Parametric_Vulnerability_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.04777-b31b1b.svg)](https://arxiv.org/abs/2309.04777) | :heavy_minus_sign: |
| TRM-UAP: Enhancing the Transferability of Data-Free Universal Adversarial Perturbation via Truncated Ratio Maximization | [![GitHub](https://img.shields.io/github/stars/RandolphCarter0/TRMUAP?style=flat)](https://github.com/RandolphCarter0/TRMUAP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_TRM-UAP_Enhancing_the_Transferability_of_Data-Free_Universal_Adversarial_Perturbation_via_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
