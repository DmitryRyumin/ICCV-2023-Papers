# ICCV-2023-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/recognition-segmentation-and-shape-analysis.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/humans-3d-modeling-and-driving.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" />
    </a>
</div>

## Generative AI

![Section Papers](https://img.shields.io/badge/Section%20Papers-24-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-23-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-17-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-6-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| CLIPascene: Scene Sketching with Different Types and Levels of Abstraction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://clipascene.github.io/CLIPascene/) <br /> [![GitHub](https://img.shields.io/github/stars/yael-vinker/SceneSketch)](https://github.com/yael-vinker/SceneSketch) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Vinker_CLIPascene_Scene_Sketching_with_Different_Types_and_Levels_of_Abstraction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.17256-b31b1b.svg)](https://arxiv.org/abs/2211.17256) | :heavy_minus_sign: |
| LD-ZNet: A Latent Diffusion Approach for Text-based Image Segmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://koutilya-pnvr.github.io/LD-ZNet/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/PNVR_LD-ZNet_A_Latent_Diffusion_Approach_for_Text-Based_Image_Segmentation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12343-b31b1b.svg)](https://arxiv.org/abs/2303.12343) | :heavy_minus_sign: |
| TexFusion: Synthesizing 3D Textures with Text-Guided Image Diffusion Models | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://research.nvidia.com/labs/toronto-ai/texfusion/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_TexFusion_Synthesizing_3D_Textures_with_Text-Guided_Image_Diffusion_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.13772-b31b1b.svg)](https://arxiv.org/abs/2310.13772) | :heavy_minus_sign: |
| NeuRBF: A Neural Fields Representation with Adaptive Radial Basis Functions | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://oppo-us-research.github.io/NeuRBF-website/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_NeuRBF_A_Neural_Fields_Representation_with_Adaptive_Radial_Basis_Functions_ICCV_2023_paper.pdf) <br /> [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://cse.buffalo.edu/~jsyuan/papers/2023/ICCV2023_zhang.pdf) | :heavy_minus_sign: |
| Scalable Diffusion Models with Transformers | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.wpeebles.com/DiT) <br /> [![GitHub](https://img.shields.io/github/stars/facebookresearch/DiT)](https://github.com/facebookresearch/DiT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Peebles_Scalable_Diffusion_Models_with_Transformers_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.09748-b31b1b.svg)](https://arxiv.org/abs/2212.09748) | :heavy_minus_sign: |
| Texture Generation on 3D Meshes with Point-UV Diffusion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://cvmi-lab.github.io/Point-UV-Diffusion/) <br /> [![GitHub](https://img.shields.io/github/stars/CVMI-Lab/Point-UV-Diffusion)](https://github.com/CVMI-Lab/Point-UV-Diffusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Texture_Generation_on_3D_Meshes_with_Point-UV_Diffusion_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10490-b31b1b.svg)](https://arxiv.org/abs/2308.10490) | :heavy_minus_sign: |
| Generative Novel View Synthesis with 3D-Aware Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://nvlabs.github.io/genvs/) <br /> [![GitHub](https://img.shields.io/github/stars/NVlabs/genvs)](https://github.com/NVlabs/genvs) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_Generative_Novel_View_Synthesis_with_3D-Aware_Diffusion_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.02602-b31b1b.svg)](https://arxiv.org/abs/2304.02602) | :heavy_minus_sign: |
| DiffFit: Unlocking Transferability of Large Diffusion Models via Simple Parameter-Efficient Fine-Tuning | [![GitHub](https://img.shields.io/github/stars/mkshing/DiffFit-pytorch)](https://github.com/mkshing/DiffFit-pytorch) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_DiffFit_Unlocking_Transferability_of_Large_Diffusion_Models_via_Simple_Parameter-efficient_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06648-b31b1b.svg)](https://arxiv.org/abs/2304.06648) | :heavy_minus_sign: |
| VQ3D: Learning a 3D-Aware Generative Model on ImageNet | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://kylesargent.github.io/vq3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Sargent_VQ3D_Learning_a_3D-Aware_Generative_Model_on_ImageNet_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.06833-b31b1b.svg)](https://arxiv.org/abs/2302.06833) | :heavy_minus_sign: |
| Ref-NeuS: Ambiguity-Reduced Neural Implicit Surface Learning for Multi-View Reconstruction with Reflection | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://g3956.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/EnVision-Research/Ref-NeuS)](https://github.com/EnVision-Research/Ref-NeuS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Ref-NeuS_Ambiguity-Reduced_Neural_Implicit_Surface_Learning_for_Multi-View_Reconstruction_with_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.10840-b31b1b.svg)](https://arxiv.org/abs/2303.10840) | :heavy_minus_sign: |
| A Complete Recipe for Diffusion Generative Models | [![GitHub](https://img.shields.io/github/stars/mandt-lab/PSLD)](https://github.com/mandt-lab/PSLD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Pandey_A_Complete_Recipe_for_Diffusion_Generative_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.01748-b31b1b.svg)](https://arxiv.org/abs/2303.01748) | :heavy_minus_sign: |
| MMVP: Motion-Matrix-based Video Prediction | [![GitHub](https://img.shields.io/github/stars/Kay1794/MMVP-motion-matrix-based-video-prediction)](https://github.com/Kay1794/MMVP-motion-matrix-based-video-prediction) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_MMVP_Motion-Matrix-Based_Video_Prediction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.16154-b31b1b.svg)](https://arxiv.org/abs/2308.16154) | :heavy_minus_sign: |
| Cross-Ray Neural Radiance Fields for Novel-View Synthesis from Unconstrained Image Collections | [![GitHub](https://img.shields.io/github/stars/YifYang993/CR-NeRF-PyTorch)](https://github.com/YifYang993/CR-NeRF-PyTorch) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Cross-Ray_Neural_Radiance_Fields_for_Novel-View_Synthesis_from_Unconstrained_Image_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.08093-b31b1b.svg)](https://arxiv.org/abs/2307.08093) | :heavy_minus_sign: |
| Effective Real Image Editing with Accelerated Iterative Diffusion Inversion | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.04907-b31b1b.svg)](https://arxiv.org/abs/2309.04907) | :heavy_minus_sign: |
| Simulating Fluids in Real-World Still Images | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://slr-sfs.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/simon3dv/SLR-SFS)](https://github.com/simon3dv/SLR-SFS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Simulating_Fluids_in_Real-World_Still_Images_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2204.11335-b31b1b.svg)](https://arxiv.org/abs/2204.11335) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Aatrl16t-V8) |
| FateZero: Fusing Attentions for Zero-Shot Text-based Video Editing | [![GitHub](https://img.shields.io/github/stars/ChenyangQiQi/FateZero)](https://github.com/ChenyangQiQi/FateZero) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/QI_FateZero_Fusing_Attentions_for_Zero-shot_Text-based_Video_Editing_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09535-b31b1b.svg)](https://arxiv.org/abs/2303.09535) | :heavy_minus_sign: |
| ELITE: Encoding Visual Concepts into Textual Embeddings for Customized Text-to-Image Generation | [![GitHub](https://img.shields.io/github/stars/csyxwei/ELITE)](https://github.com/csyxwei/ELITE) <br /> [![Hugging Face](https://img.shields.io/badge/ðŸ¤—-Demo-FFD21F.svg)](https://huggingface.co/spaces/ELITE-library/ELITE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_ELITE_Encoding_Visual_Concepts_into_Textual_Embeddings_for_Customized_Text-to-Image_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.13848-b31b1b.svg)](https://arxiv.org/abs/2302.13848) | :heavy_minus_sign: |
| Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://text2video-zero.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/Picsart-AI-Research/Text2Video-Zero)](https://github.com/Picsart-AI-Research/Text2Video-Zero) <br /> [![Hugging Face](https://img.shields.io/badge/ðŸ¤—-Demo-FFD21F.svg)](https://huggingface.co/spaces/PAIR/Text2Video-Zero) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Khachatryan_Text2Video-Zero_Text-to-Image_Diffusion_Models_are_Zero-Shot_Video_Generators_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13439-b31b1b.svg)](https://arxiv.org/abs/2303.13439) | [![Dropbox](https://img.shields.io/badge/Dropbox-%233B4D98.svg?style=for-the-badge&logo=Dropbox&logoColor=white)](https://www.dropbox.com/s/uv90mi2z598olsq/Text2Video-Zero.MP4?dl=0) |
| Chupa: Carving 3D Clothed Humans from Skinned Shape Priors using 2D Diffusion Probabilistic Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://snuvclab.github.io/chupa/) <br /> [![GitHub](https://img.shields.io/github/stars/snuvclab/chupa)](https://github.com/snuvclab/chupa) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Chupa_Carving_3D_Clothed_Humans_from_Skinned_Shape_Priors_using_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.11870-b31b1b.svg)](https://arxiv.org/abs/2305.11870) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ZHwtbQSsQjw) |
| DiffPose: Multi-Hypothesis Human Pose Estimation using Diffusion Models | [![GitHub](https://img.shields.io/github/stars/bastianwandt/DiffPose)](https://github.com/bastianwandt/DiffPose) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Holmquist_DiffPose_Multi-hypothesis_Human_Pose_Estimation_using_Diffusion_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.16487-b31b1b.svg)](https://arxiv.org/abs/2211.16487) | :heavy_minus_sign: |
| HumanSD: A Native Skeleton-Guided Diffusion Model for Human Image Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://idea-research.github.io/HumanSD/) <br /> [![GitHub](https://img.shields.io/github/stars/IDEA-Research/HumanSD)](https://github.com/IDEA-Research/HumanSD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Ju_HumanSD_A_Native_Skeleton-Guided_Diffusion_Model_for_Human_Image_Generation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.04269-b31b1b.svg)](https://arxiv.org/abs/2304.04269) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=rVy8eWCWRmg) |
| Role-Aware Interaction Generation from Textual Description | [![GitHub](https://img.shields.io/github/stars/line/Human-Interaction-Generation)](https://github.com/line/Human-Interaction-Generation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Tanaka_Role-Aware_Interaction_Generation_from_Textual_Description_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| PhysDiff: Physics-Guided Human Motion Diffusion Model | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://nvlabs.github.io/PhysDiff/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_PhysDiff_Physics-Guided_Human_Motion_Diffusion_Model_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.02500-b31b1b.svg)](https://arxiv.org/abs/2212.02500) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=y8Tdcvzjfjg) |
| Forward Flow for Novel View Synthesis of Dynamic Scenes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://npucvr.github.io/ForwardFlowDNeRF/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Forward_Flow_for_Novel_View_Synthesis_of_Dynamic_Scenes_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.17390-b31b1b.svg)](https://arxiv.org/abs/2309.17390) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AiUogciQlW8) |
