# ICCV-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/recognition-categorization.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/neural-generative-models.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Explainable AI for CV

![Section Papers](https://img.shields.io/badge/Section%20Papers-21-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-17-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-15-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-1-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Towards Improved Input Masking for Convolutional Neural Networks | [![GitHub](https://img.shields.io/github/stars/SriramB-98/layer_masking?style=flat)](https://github.com/SriramB-98/layer_masking) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Balasubramanian_Towards_Improved_Input_Masking_for_Convolutional_Neural_Networks_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.14646-b31b1b.svg)](https://arxiv.org/abs/2211.14646) | :heavy_minus_sign: |
| PDiscoNet: Semantically Consistent Part Discovery for Fine-Grained Recognition | [![GitHub](https://img.shields.io/github/stars/robertdvdk/part_detection?style=flat)](https://github.com/robertdvdk/part_detection) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/van_der_Klis_PDiscoNet_Semantically_consistent_part_discovery_for_fine-grained_recognition_ICCV_2023_paper.pdf) <br /> [![HAL Science](https://img.shields.io/badge/hal-science-040060.svg)](https://hal.inrae.fr/hal-04183747) | :heavy_minus_sign: |
| Corrupting Neuron Explanations of Deep Visual Features | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Srivastava_Corrupting_Neuron_Explanations_of_Deep_Visual_Features_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.16332-b31b1b.svg)](https://arxiv.org/abs/2310.16332) | :heavy_minus_sign: |
| ICICLE: Interpretable Class Incremental Continual Learning | [![GitHub](https://img.shields.io/github/stars/gmum/ICICLE?style=flat)](https://github.com/gmum/ICICLE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Rymarczyk_ICICLE_Interpretable_Class_Incremental_Continual_Learning_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07811-b31b1b.svg)](https://arxiv.org/abs/2303.07811) | :heavy_minus_sign: |
| ProbVLM: Probabilistic Adapter for Frozen Vison-Language Models | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.eml-unitue.de/publication/ProbVLM) <br /> [![GitHub](https://img.shields.io/github/stars/ExplainableML/ProbVLM?style=flat)](https://github.com/ExplainableML/ProbVLM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Upadhyay_ProbVLM_Probabilistic_Adapter_for_Frozen_Vison-Language_Models_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.00398-b31b1b.svg)](https://arxiv.org/abs/2307.00398) | :heavy_minus_sign: |
| Out-of-Distribution Detection for Monocular Depth Estimation | [![GitHub](https://img.shields.io/github/stars/jhornauer/mde_ood?style=flat)](https://github.com/jhornauer/mde_ood) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Hornauer_Out-of-Distribution_Detection_for_Monocular_Depth_Estimation_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.06072-b31b1b.svg)](https://arxiv.org/abs/2308.06072) | :heavy_minus_sign: |
| Studying how to Efficiently and Effectively Guide Models with Explanations | [![GitHub](https://img.shields.io/github/stars/sukrutrao/Model-Guidance?style=flat)](https://github.com/sukrutrao/Model-Guidance) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Rao_Studying_How_to_Efficiently_and_Effectively_Guide_Models_with_Explanations_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11932-b31b1b.svg)](https://arxiv.org/abs/2303.11932) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=g9tKVe3fEcQ) |
| Rosetta Neurons: Mining the Common Units in a Model Zoo | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yossigandelsman.github.io/rosetta_neurons/) <br /> [![GitHub](https://img.shields.io/github/stars/yossigandelsman/rosetta_neurons?style=flat)](https://github.com/yossigandelsman/rosetta_neurons) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Dravid_Rosetta_Neurons_Mining_the_Common_Units_in_a_Model_Zoo_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.09346-b31b1b.svg)](https://arxiv.org/abs/2306.09346) | :heavy_minus_sign: |
| Prototype-based Dataset Comparison | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://nanne.github.io/ProtoSim/) <br /> [![GitHub](https://img.shields.io/github/stars/Nanne/ProtoSim?style=flat)](https://github.com/Nanne/ProtoSim) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/van_Noord_Protoype-based_Dataset_Comparison_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.02401-b31b1b.svg)](https://arxiv.org/abs/2309.02401) | :heavy_minus_sign: |
| Learning to Identify Critical States for Reinforcement Learning from Videos | [![GitHub](https://img.shields.io/github/stars/AI-Initiative-KAUST/VideoRLCS?style=flat)](https://github.com/AI-Initiative-KAUST/VideoRLCS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_to_Identify_Critical_States_for_Reinforcement_Learning_from_Videos_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.07795-b31b1b.svg)](https://arxiv.org/abs/2308.07795) | :heavy_minus_sign: |
| Leaping Into Memories: Space-Time Deep Feature Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://alexandrosstergiou.github.io/project_pages/LEAPS/index.html) <br /> [![GitHub](https://img.shields.io/github/stars/alexandrosstergiou/Leaping-Into-Memories?style=flat)](https://github.com/alexandrosstergiou/Leaping-Into-Memories) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Stergiou_Leaping_Into_Memories_Space-Time_Deep_Feature_Synthesis_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09941-b31b1b.svg)](https://arxiv.org/abs/2303.09941) | :heavy_minus_sign: |
| MAGI: Multi-Annotated Explanation-Guided Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_MAGI_Multi-Annotated_Explanation-Guided_Learning_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| SAFARI: Versatile and Efficient Evaluations for Robustness of Interpretability | [![GitHub](https://img.shields.io/github/stars/havelhuang/Eval_XAI_Robustness?style=flat)](https://github.com/havelhuang/Eval_XAI_Robustness) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_SAFARI_Versatile_and_Efficient_Evaluations_for_Robustness_of_Interpretability_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2208.09418-b31b1b.svg)](https://arxiv.org/abs/2208.09418) | :heavy_minus_sign: |
| Do DALL-E and Flamingo Understand Each Other? | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dalleflamingo.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Do_DALL-E_and_Flamingo_Understand_Each_Other_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.12249-b31b1b.svg)](https://arxiv.org/abs/2212.12249) | :heavy_minus_sign: |
| Evaluation and Improvement of Interpretability for Self-Explainable Part-Prototype Networks | [![GitHub](https://img.shields.io/github/stars/hqhQAQ/EvalProtoPNet?style=flat)](https://github.com/hqhQAQ/EvalProtoPNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Evaluation_and_Improvement_of_Interpretability_for_Self-Explainable_Part-Prototype_Networks_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.05946-b31b1b.svg)](https://arxiv.org/abs/2212.05946) | :heavy_minus_sign: |
| MoreauGrad: Sparse and Robust Interpretation of Neural Networks via Moreau Envelope | [![GitHub](https://img.shields.io/github/stars/buyeah1109/MoreauGrad?style=flat)](https://github.com/buyeah1109/MoreauGrad) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_MoreauGrad_Sparse_and_Robust_Interpretation_of_Neural_Networks_via_Moreau_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.05294-b31b1b.svg)](https://arxiv.org/abs/2302.05294) | :heavy_minus_sign: |
| Towards Understanding the Generalization of Deepfake Detectors from a Game-Theoretical View | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Towards_Understanding_the_Generalization_of_Deepfake_Detectors_from_a_Game-Theoretical_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Counterfactual-based Saliency Map: Towards Visual Contrastive Explanations for Neural Networks | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Counterfactual-based_Saliency_Map_Towards_Visual_Contrastive_Explanations_for_Neural_Networks_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Beyond Single Path Integrated Gradients for Reliable Input Attribution via Randomized Path Sampling | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Jeon_Beyond_Single_Path_Integrated_Gradients_for_Reliable_Input_Attribution_via_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Learning Support and Trivial Prototypes for Interpretable Image Classification | [![GitHub](https://img.shields.io/github/stars/cwangrun/ST-ProtoPNet?style=flat)](https://github.com/cwangrun/ST-ProtoPNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Support_and_Trivial_Prototypes_for_Interpretable_Image_Classification_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.04011-b31b1b.svg)](https://arxiv.org/abs/2301.04011) | :heavy_minus_sign: |
| Visual Explanations via Iterated Integrated Attributions | [![GitHub](https://img.shields.io/github/stars/iia-iccv23/iia?style=flat)](https://github.com/iia-iccv23/iia) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Barkan_Visual_Explanations_via_Iterated_Integrated_Attributions_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.18585-b31b1b.svg)](https://arxiv.org/abs/2310.18585) | :heavy_minus_sign: |
