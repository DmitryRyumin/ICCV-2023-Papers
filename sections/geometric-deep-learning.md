# ICCV-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/image-and-video-forensics.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/sections/vision-applications-and-systems.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Geometric Deep Learning

![Section Papers](https://img.shields.io/badge/Section%20Papers-8-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-7-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-4-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Get the Best of Both Worlds: Improving Accuracy and Transferability by Grassmann Class Representation | [![GitHub](https://img.shields.io/github/stars/innerlee/GCR?style=flat)](https://github.com/innerlee/GCR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Get_the_Best_of_Both_Worlds_Improving_Accuracy_and_Transferability_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.01547-b31b1b.svg)](https://arxiv.org/abs/2308.01547) | :heavy_minus_sign: |
| 4D Panoptic Segmentation as Invariant and Equivariant Field Prediction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://eq-4d-panoptic.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/minghanz/EQ-4D-StOP?style=flat)](https://github.com/minghanz/EQ-4D-StOP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_4D_Panoptic_Segmentation_as_Invariant_and_Equivariant_Field_Prediction_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15651-b31b1b.svg)](https://arxiv.org/abs/2303.15651) | :heavy_minus_sign: |
| SiLK: Simple Learned Keypoints | [![GitHub](https://img.shields.io/github/stars/facebookresearch/silk?style=flat)](https://github.com/facebookresearch/silk) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Gleize_SiLK_Simple_Learned_Keypoints_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06194-b31b1b.svg)](https://arxiv.org/abs/2304.06194) | :heavy_minus_sign: |
| SC3K: Self-Supervised and Coherent 3D Keypoints Estimation from Rotated, Noisy, and Decimated Point Cloud Data | [![GitHub](https://img.shields.io/github/stars/IIT-PAVIS/SC3K?style=flat)](https://github.com/IIT-PAVIS/SC3K) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zohaib_SC3K_Self-supervised_and_Coherent_3D_Keypoints_Estimation_from_Rotated_Noisy_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.05410-b31b1b.svg)](https://arxiv.org/abs/2308.05410) | :heavy_minus_sign: |
| Geometric Viewpoint Learning with Hyper-Rays and Harmonics Encoding | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Min_Geometric_Viewpoint_Learning_with_Hyper-Rays_and_Harmonics_Encoding_ICCV_2023_paper.pdf) | :heavy_minus_sign: |
| Surface Extraction from Neural Unsigned Distance Fields | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Surface_Extraction_from_Neural_Unsigned_Distance_Fields_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.08878-b31b1b.svg)](https://arxiv.org/abs/2309.08878) | :heavy_minus_sign: |
| Learning Adaptive Neighborhoods for Graph Neural Networks | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Saha_Learning_Adaptive_Neighborhoods_for_Graph_Neural_Networks_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.09065-b31b1b.svg)](https://arxiv.org/abs/2307.09065) | :heavy_minus_sign: |
| Why do Networks have Inhibitory/Negative Connections? | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Why_do_networks_have_inhibitorynegative_connections_ICCV_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2208.03211-b31b1b.svg)](https://arxiv.org/abs/2208.03211) | :heavy_minus_sign: |
