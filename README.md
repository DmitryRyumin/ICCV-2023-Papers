# ICCV-2023-Papers

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
![Version](https://img.shields.io/badge/version-v0.0.0-rc0)
![GitHub repo size](https://img.shields.io/github/repo-size/DmitryRyumin/ICCV-2023-Papers)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/LICENSE)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/README.md)
![GitHub contributors](https://img.shields.io/github/contributors/dmitryryumin/ICCV-2023-Papers)
![GitHub commit activity (branch)](https://img.shields.io/github/commit-activity/t/dmitryryumin/ICCV-2023-Papers)
![GitHub closed issues](https://img.shields.io/github/issues-closed/DmitryRyumin/ICCV-2023-Papers)
![GitHub issues](https://img.shields.io/github/issues/DmitryRyumin/ICCV-2023-Papers)
![GitHub closed pull requests](https://img.shields.io/github/issues-pr-closed/DmitryRyumin/ICCV-2023-Papers)
![GitHub pull requests](https://img.shields.io/github/issues-pr/dmitryryumin/ICCV-2023-Papers)
![GitHub last commit](https://img.shields.io/github/last-commit/DmitryRyumin/ICCV-2023-Papers)
![GitHub watchers](https://img.shields.io/github/watchers/dmitryryumin/ICCV-2023-Papers)
![GitHub forks](https://img.shields.io/github/forks/dmitryryumin/ICCV-2023-Papers)
![GitHub Repo stars](https://img.shields.io/github/stars/dmitryryumin/ICCV-2023-Papers)
![Visitors](https://api.visitorbadge.io/api/combined?path=https%3A%2F%2Fgithub.com%2FDmitryRyumin%2FICCV-2023-Papers&label=Visitors&countColor=%23263759&style=flat)

> Completed: ![Progress](https://geps.dev/progress/17?successColor=006600)

---

ICCV 2023 Papers: Explore a comprehensive collection of cutting-edge research papers presented at [*ICCV 2023*](https://iccv2023.thecvf.com/), the premier computer vision conference. Keep up to date with the latest advances in computer vision and deep learning. Code implementations included. :star: the repository for the development of visual intelligence!

<p align="center">
    <a href="https://iccv2023.thecvf.com/" target="_blank">
        <img width="600" src="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/images/ICCV2023-banner.jpg" alt="ICCV 2023">
    </a>
<p>

---

[*The online version of the ICCV 2023 Conference Programme*](https://iccv2023.thecvf.com/main.conference.program-107.php), comprises a list of all accepted full papers, their presentation order, as well as the designated presentation times.

---

<a href="https://github.com/DmitryRyumin/NewEraAI-Papers" style="float:left;">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arrow_click_cursor_pointer.png" width="25" />
  Other collections of the best AI conferences
</a>

<br />
<br />

> :exclamation: Conference table will be up to date all the time.

<table>
    <tr>
        <td><strong>Conference</strong></td>
        <td colspan="1" align="center"><strong>Year</strong></td>
    </tr>
    <tr>
      <td colspan="2" align="center"><i>Computer Vision (CV)</i></td>
    </tr>
    <tr>
        <td>CVPR</td>
        <td><a href="https://github.com/DmitryRyumin/CVPR-2023-Papers" target="_blank">2023</a></td>
    </tr>
    <tr>
      <td colspan="2" align="center"><i>Speech (SP)</i></td>
    </tr>
    <tr>
        <td>ICASSP</td>
        <td><a href="https://github.com/DmitryRyumin/ICASSP-2023-Papers" target="_blank">2023</a></td>
    </tr>
    <tr>
        <td>INTERSPEECH</td>
        <td><a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers" target="_blank">2023</a></td>
    </tr>
</table>

---

## Contributors

<a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/graphs/contributors">
  <img src="http://contributors.nn.ci/api?repo=DmitryRyumin/ICCV-2023-Papers" />
</a>

<br />
<br />

Contributions to improve the completeness of this list are greatly appreciated. If you come across any overlooked papers, please **feel free to [*create pull requests*](https://github.com/DmitryRyumin/ICCV-2023-Papers/pulls), [*open issues*](https://github.com/DmitryRyumin/ICCV-2023-Papers/issues) or contact me via [*email*](mailto:neweraairesearch@gmail.com)**. Your participation is crucial to making this repository even better.

---

## [Papers](https://iccv2023.thecvf.com/main.conference.program-107.php)

> :exclamation: Final paper links will be added post-conference.

<details open>
<summary>List of sections<a id="sections"></a></summary>

- [3D from Multi-View and Sensors](#3d-from-multi-view-and-sensors)
- [Adversarial Attack and Defense](#adversarial-attack-and-defense)
- [Vision and Robotics](#vision-and-robotics)
- [Vision and Graphics](#vision-and-graphics)
- [Segmentation, Grouping and Shape Analysis](#segmentation-grouping-and-shape-analysis)
- [Recognition: Categorization](#recognition-categorization)
- [Explainable AI for CV](#explainable-ai-for-cv)
- [Neural Generative Models](#neural-generative-models)
- [Vision and Language](#vision-and-language)
- [Vision, Graphics, and Robotics](#vision-graphics-and-robotics)
- [Privacy, Security, Fairness, and Explainability](#privacy-security-fairness-and-explainability)
- [Fairness, Privacy, Ethics, Social-good, Transparency, Accountability in Vision](#fairness-privacy-ethics-social-good-transparency-accountability-in-vision)
- [First Person (Egocentric) Vision](#first-person-egocentric-vision)
- [Deep Learning Architectures](#deep-learning-architectures)
- [Recognition: Detection](#recognition-detection)
- [Image and Video Synthesis](#image-and-video-synthesis)
- [Vision and Audio](#vision-and-audio)
- [Recognition, Segmentation, and Shape Analysis](#recognition-segmentation-and-shape-analysis)
- [Generative AI](#generative-ai)
- [Humans, 3D Modeling, and Driving](#humans-3d-modeling-and-driving)
- [Low-Level Vision and Theory](#low-level-vision-and-theory)
- [Navigation and Autonomous Driving](#navigation-and-autonomous-driving)
- [3D from a Single Image and Shape-from-X](#3d-from-a-single-image-and-shape-from-x)
- [Motion Estimation, Matching and Tracking](#motion-estimation-matching-and-tracking)
- [Action and Event Understanding](#action-and-event-understanding)
- [Computational Imaging](#computational-imaging)
- [Embodied Vision: Active Agents; Simulation](#embodied-vision-active-agents-simulation)
- [Recognition: Retrieval](#recognition-retrieval)
- [Transfer, Low-Shot, Continual, Long-Tail Learning](#transfer-low-shot-continual-long-tail-learning)
- [Low-Level and Physics-based Vision](#low-level-and-physics-based-vision)
- [Computer Vision Theory](#computer-vision-theory)
- [Video Analysis and Understanding](#video-analysis-and-understanding)
- [Object Pose Estimation and Tracking](#object-pose-estimation-and-tracking)
- [3D Shape Modeling and Processing](#3d-shape-modeling-and-processing)
- [Human Pose/Shape Estimation](#human-poseshape-estimation)
- [Transfer, Low-Shot, and Continual Learning](#transfer-low-shot-and-continual-learning)
- [Self-, Semi-, and Unsupervised Learning](#self--semi--and-unsupervised-learning)
- [Self-, Semi-, Meta-, Unsupervised Learning](#self--semi--meta--unsupervised-learning)
- [Photogrammetry and Remote Sensing](#photogrammetry-and-remote-sensing)
- [Efficient and Scalable Vision](#efficient-and-scalable-vision)
- [Machine Learning (other than Deep Learning)](#machine-learning-other-than-deep-learning)
- [Document Analysis and Understanding](#document-analysis-and-understanding)
- [Biometrics](#biometrics)
- [Datasets and Evaluation](#datasets-and-evaluation)
- [Faces and Gestures](#faces-and-gestures)
- [Medical and Biological Vision; Cell Microscopy](#medical-and-biological-vision-cell-microscopy)
- [Scene Analysis and Understanding](#scene-analysis-and-understanding)
- [Multimodal Learning](#multimodal-learning)
- [Human-in-the-Loop Computer Vision](#human-in-the-loop-computer-vision)
- [Image and Video Forensics](#image-and-video-forensics)
- [Geometric Deep Learning](#geometric-deep-learning)
- [Vision Applications and Systems](#vision-applications-and-systems)
- [Machine Learning and Dataset](#machine-learning-and-dataset)

</details>

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### 3D from Multi-View and Sensors

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Multi-Modal Neural Radiance Field for Monocular Dense SLAM with a Light-Weight ToF Sensor | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.14383-b31b1b.svg)](https://arxiv.org/abs/2308.14383) | :heavy_minus_sign: |
| ScanNet++: A High-Fidelity Dataset of 3D Indoor Scenes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://cy94.github.io/scannetpp/) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11417-b31b1b.svg)](https://arxiv.org/abs/2308.11417) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=E6P9e2r6M8I) |
| Translating Images to Road Network: A Non-Autoregressive Sequence-to-Sequence Approach | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Doppelgangers: Learning to Disambiguate Images of Similar Structures | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://doppelgangers-3d.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/RuojinCai/Doppelgangers)](https://github.com/RuojinCai/Doppelgangers) | :heavy_minus_sign: | :heavy_minus_sign: |
| EgoLoc: Revisiting 3D Object Localization from Egocentric Videos with Visual Queries | [![GitHub](https://img.shields.io/github/stars/Wayne-Mai/EgoLoc)](https://github.com/Wayne-Mai/EgoLoc) | [![arXiv](https://img.shields.io/badge/arXiv-2212.06969-b31b1b.svg)](https://arxiv.org/abs/2212.06969) | :heavy_minus_sign: |
| ClothPose: A Real-world Benchmark for Visual Analysis of Garment Pose via an Indirect Recording Solution | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| EMR-MSF: Self-Supervised Recurrent Monocular Scene Flow Exploiting Ego-Motion Rigidity | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| ENVIDR: Implicit Differentiable Renderer with Neural Environment Lighting | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://nexuslrf.github.io/ENVIDR/) <br /> [![GitHub](https://img.shields.io/github/stars/nexuslrf/ENVIDR)](https://github.com/nexuslrf/ENVIDR) | [![arXiv](https://img.shields.io/badge/arXiv-2303.13022-b31b1b.svg)](https://arxiv.org/abs/2303.13022) | [![Google Drive](https://img.shields.io/badge/Google%20Drive-4285F4?style=for-the-badge&logo=googledrive&logoColor=white)](https://drive.google.com/file/d/18kU-IWVxboCG8SCGgrBA5JHC0JIgPCS8/view?t=17s) |
| Learning a more Continuous Zero Level Set in Unsigned Distance Fields through Level Set Projection | [![GitHub](https://img.shields.io/github/stars/junshengzhou/LevelSetUDF)](https://github.com/junshengzhou/LevelSetUDF) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11441-b31b1b.svg)](https://arxiv.org/abs/2308.11441) | :heavy_minus_sign: |
| GNT-MOVE: Generalizable NeRF Transformer with Mixture-of-View-Experts | [![GitHub](https://img.shields.io/github/stars/VITA-Group/GNT-MOVE)](https://github.com/VITA-Group/GNT-MOVE) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11793-b31b1b.svg)](https://arxiv.org/abs/2308.11793) | :heavy_minus_sign: |
| MatrixCity: A Large-Scale City Dataset for City-Scale Neural Rendering and Beyond | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://city-super.github.io/matrixcity/) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://city-super.github.io/matrixcity/img/matrixcity_camera_ready.pdf) | :heavy_minus_sign: |
| R3D3: Dense 3D Reconstruction of Dynamic Scenes from Multiple Cameras | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.vis.xyz/pub/r3d3/) <br /> [![GitHub](https://img.shields.io/github/stars/SysCV/r3d3)](https://github.com/SysCV/r3d3) | [![arXiv](https://img.shields.io/badge/arXiv-2308.14713-b31b1b.svg)](https://arxiv.org/abs/2308.14713) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=lkU0lDq9HHw) |
| ClimateNeRF: Extreme Weather Synthesis in Neural Radiance Field | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://climatenerf.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2211.13226-b31b1b.svg)](https://arxiv.org/abs/2211.13226) | :heavy_minus_sign: |
| Rendering Humans from Object-Occluded Monocular Videos | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://cs.stanford.edu/~xtiange/projects/occnerf/) <br /> [![GitHub](https://img.shields.io/github/stars/tiangexiang/OccNeRF)](https://github.com/tiangexiang/OccNeRF) | [![arXiv](https://img.shields.io/badge/arXiv-2308.04622-b31b1b.svg)](https://arxiv.org/abs/2308.04622) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-LHyNdWGqTM) |
| AssetField: Assets Mining and Reconfiguration in Ground Feature Plane Representation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://city-super.github.io/assetfield/) | [![arXiv](https://img.shields.io/badge/arXiv-2303.13953-b31b1b.svg)](https://arxiv.org/abs/2303.13953) | :heavy_minus_sign: |
| PETRv2: A Unified Framework for 3D Perception from Multi-Camera Images | [![GitHub](https://img.shields.io/github/stars/megvii-research/PETR)](https://github.com/megvii-research/PETR) | [![arXiv](https://img.shields.io/badge/arXiv-2206.01256-b31b1b.svg)](https://arxiv.org/abs/2206.01256) | :heavy_minus_sign: |
| MIMO-NeRF: Fast Neural Rendering with Multi-Input Multi-Output Neural Radiance Fields | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Adaptive Positional Encoding for Bundle-Adjusting Neural Radiance Fields | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| NeuS2: Fast Learning of Neural Implicit Surfaces for Multi-View Reconstruction | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://vcai.mpi-inf.mpg.de/projects/NeuS2/) <br /> [![GitHub](https://img.shields.io/github/stars/19reborn/NeuS2)](https://github.com/19reborn/NeuS2) | [![arXiv](https://img.shields.io/badge/arXiv-2212.05231-b31b1b.svg)](https://arxiv.org/abs/2212.05231) | :heavy_minus_sign: |
| Learning from Semantic Alignment between Unpaired Multiviews for Egocentric Video Recognition | [![GitHub](https://img.shields.io/github/stars/wqtwjt1996/SUM-L)](https://github.com/wqtwjt1996/SUM-L) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11489-b31b1b.svg)](https://arxiv.org/abs/2308.11489) | :heavy_minus_sign: |
| Uncertainty Guided Adaptive Warping for Robust and Efficient Stereo Matching | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.14071-b31b1b.svg)](https://arxiv.org/abs/2307.14071) | :heavy_minus_sign: |
| Compatibility of Fundamental Matrices for Complete Viewing Graphs |  | [![arXiv](https://img.shields.io/badge/arXiv-2303.10658-b31b1b.svg)](https://arxiv.org/abs/2303.10658) | :heavy_minus_sign: |
| ProtoTransfer: Cross-Modal Prototype Transfer for Point Cloud Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| SA-BEV: Generating Semantic-Aware Bird's-Eye-View Feature for Multi-View 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/mengtan00/SA-BEV)](https://github.com/mengtan00/SA-BEV) | [![arXiv](https://img.shields.io/badge/arXiv-2307.11477-b31b1b.svg)](https://arxiv.org/abs/2307.11477) | :heavy_minus_sign: |
| GraphAlign: Enhancing Accurate Feature Alignment by Graph matching for Multi-Modal 3D Object Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Tangent Sampson Error: Fast Approximate Two-View Reprojection Error for Central Camera Models | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Using a Waffle Iron for Automotive Point Cloud Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/valeoai/WaffleIron)](https://github.com/valeoai/WaffleIron) | [![arXiv](https://img.shields.io/badge/arXiv-2301.10100-b31b1b.svg)](https://arxiv.org/abs/2301.10100) | :heavy_minus_sign: |
| Fast Globally Optimal Surface Normal Estimation from an Affine Correspondence | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| HeadsUp: A Data-Driven Volumetric Prior for Few-Shot Synthesis of Ultra High-Resolution Human Heads | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| TILTED: Robust Neural Fields via Latent Registration | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Center-based Decoupled Point-Cloud Registration for 6D Object Pose Estimation | [![GitHub](https://img.shields.io/github/stars/Jiang-HB/CenterReg)](https://github.com/Jiang-HB/CenterReg) | :heavy_minus_sign: | :heavy_minus_sign: |
| Deep Geometry-Aware Camera Self-Calibration from Video | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| V-FUSE: Volumetric Depth Map Fusion with Long-Range Constraints | [![GitHub](https://img.shields.io/github/stars/nburgdorfer/V-FUSE)](https://github.com/nburgdorfer/V-FUSE) | [![arXiv](https://img.shields.io/badge/arXiv-2308.08715-b31b1b.svg)](https://arxiv.org/abs/2308.08715) | :heavy_minus_sign: |
| Consistent Depth Prediction for Transparent Object Reconstruction from RGB-D Camera | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| FaceCLIPNeRF: Text-Driven 3D Face Manipulation using Deformable Neural Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://faceclipnerf.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2307.11418-b31b1b.svg)](https://arxiv.org/abs/2307.11418) | :heavy_minus_sign: |
| HollowNeRF: Pruning Hashgrid-based NeRFs with Trainable Collision Mitigation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.10122-b31b1b.svg)](https://arxiv.org/abs/2308.10122) | :heavy_minus_sign: |
| ICE-NeRF: Interactive Color Editing of NeRFs via Decomposition-Aware Weight Optimization | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| FULLER: Unified Multi-Modality Multi-Task 3D Perception via Multi-Level Gradient Calibration |  | [![arXiv](https://img.shields.io/badge/arXiv-2307.16617-b31b1b.svg)](https://arxiv.org/abs/2307.16617) | :heavy_minus_sign: |
| Neural Fields for Structured Lighting | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| CO-Net: Learning Multiple Point Cloud Tasks at Once with a Cohesive Network | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Pose-Free Neural Radiance Fields via Implicit Pose Regularization | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.15049-b31b1b.svg)](https://arxiv.org/abs/2308.15049) | :heavy_minus_sign: |
| TransHuman: A Transformer-based Human Representation for Generalizable Neural Human Rendering | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://pansanity666.github.io/TransHuman/) <br /> [![GitHub](https://img.shields.io/github/stars/pansanity666/TransHuman)](https://github.com/pansanity666/TransHuman) | [![arXiv](https://img.shields.io/badge/arXiv-2307.12291-b31b1b.svg)](https://arxiv.org/abs/2307.12291) | :heavy_minus_sign: |
| S-VolSDF: Sparse Multi-View Stereo Regularization of Neural Implicit Surfaces | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://hao-yu-wu.github.io/s-volsdf/) | [![arXiv](https://img.shields.io/badge/arXiv-2303.17712-b31b1b.svg)](https://arxiv.org/abs/2303.17712) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=3_4PeVHWliY) |
| DPS-Net: Deep Polarimetric Stereo Depth Estimation | [![GitHub](https://img.shields.io/github/stars/Ethereal-Tian/DPS-Net)](https://github.com/Ethereal-Tian/DPS-Net) | :heavy_minus_sign: | :heavy_minus_sign: |
| 3DPPE: 3D Point Positional Encoding for Transformer-based Multi-Camera 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/drilistbox/3DPPE)](https://github.com/drilistbox/3DPPE) | [![arXiv](https://img.shields.io/badge/arXiv-2211.14710-b31b1b.svg)](https://arxiv.org/abs/2211.14710) | :heavy_minus_sign: |
| Deformable Neural Radiance Fields using RGB and Event Cameras | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Inter-Reflectable Light Fields for Geometry and Material Estimation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yoyo000.github.io/NeILF_pp/) <br /> [![GitHub](https://img.shields.io/github/stars/apple/ml-neilfpp)](https://github.com/apple/ml-neilfpp) | [![arXiv](https://img.shields.io/badge/arXiv-2303.17147-b31b1b.svg)](https://arxiv.org/abs/2303.17147) | :heavy_minus_sign: |
| Hierarchical Prior Mining for Non-Local Multi-View Stereo | [![GitHub](https://img.shields.io/github/stars/CLinvx/HPM-MVS)](https://github.com/CLinvx/HPM-MVS) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09758-b31b1b.svg)](https://arxiv.org/abs/2303.09758) | :heavy_minus_sign: |
| Exploring Object-Centric Temporal Modeling for Efficient Multi-View 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/exiawsh/StreamPETR)](https://github.com/exiawsh/StreamPETR) | [![arXiv](https://img.shields.io/badge/arXiv-2303.11926-b31b1b.svg)](https://arxiv.org/abs/2303.11926) | :heavy_minus_sign: |
| Re-ReND: Real-Time Rendering of NeRFs Across Devices | [![GitHub](https://img.shields.io/github/stars/sararoma95/Re-ReND)](https://github.com/sararoma95/Re-ReND) | [![arXiv](https://img.shields.io/badge/arXiv-2303.08717-b31b1b.svg)](https://arxiv.org/abs/2303.08717) | :heavy_minus_sign: |
| Learning Shape Primitives via Implicit Convexity Regularization | [![GitHub](https://img.shields.io/github/stars/seanywang0408/ICR)](https://github.com/seanywang0408/ICR) | :heavy_minus_sign: | :heavy_minus_sign: |
| Geometry-Guided Feature Learning and Fusion for Indoor Scene Reconstruction | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| LiDAR-Camera Panoptic Segmentation via Geometry-Consistent and Semantic-Aware Alignment | [![GitHub](https://img.shields.io/github/stars/zhangzw12319/lcps)](https://github.com/zhangzw12319/lcps) | [![arXiv](https://img.shields.io/badge/arXiv-2308.01686-b31b1b.svg)](https://arxiv.org/abs/2308.01686) | :heavy_minus_sign: |
| PivotNet: End-to-End Learning for Vectorized HD Map Construction | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.16477-b31b1b.svg)](https://arxiv.org/abs/2308.16477) | :heavy_minus_sign: |
| Sat2Density: Faithful Density Learning from Satellite-Ground Image Pairs | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sat2density.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/qianmingduowan/Sat2Density)](https://github.com/qianmingduowan/Sat2Density) | [![arXiv](https://img.shields.io/badge/arXiv-2303.14672-b31b1b.svg)](https://arxiv.org/abs/2303.14672) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mf00PRXUpTU) |
| Mask-Attention-Free Transformer for 3D Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/dvlab-research/Mask-Attention-Free-Transformer)](https://github.com/dvlab-research/Mask-Attention-Free-Transformer) | [![arXiv](https://img.shields.io/badge/arXiv-2309.01692-b31b1b.svg)](https://arxiv.org/abs/2309.01692) | :heavy_minus_sign: |
| Scene-Aware Feature Matching | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.09949-b31b1b.svg)](https://arxiv.org/abs/2308.09949) | :heavy_minus_sign: |
| Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-Balanced Pseudo-Labeling | [![GitHub](https://img.shields.io/github/stars/zhuoxiao-chen/ReDB-DA-3Ddet)](https://github.com/zhuoxiao-chen/ReDB-DA-3Ddet) | [![arXiv](https://img.shields.io/badge/arXiv-2307.07944-b31b1b.svg)](https://arxiv.org/abs/2307.07944) | :heavy_minus_sign: |
| GO-SLAM: Global Optimization for Consistent 3D Instant Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://youmi-zym.github.io/projects/GO-SLAM/) <br /> [![GitHub](https://img.shields.io/github/stars/youmi-zym/GO-SLAM)](https://github.com/youmi-zym/GO-SLAM) | [![arXiv](https://img.shields.io/badge/arXiv-2309.02436-b31b1b.svg)](https://arxiv.org/abs/2309.02436) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=MbGn94Y4l8Y) |
| BANSAC: A Dynamic BAyesian Network for SAmple Consensus | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://pmiraldo.github.io/projects/bansac/bansac.html) | :heavy_minus_sign: | :heavy_minus_sign: |
| Theoretical and Numerical Analysis of 3D Reconstruction using Point and Line Incidences |  | [![arXiv](https://img.shields.io/badge/arXiv-2303.13593-b31b1b.svg)](https://arxiv.org/abs/2303.13593) | :heavy_minus_sign: |
| RealGraph: A Multiview Dataset for 4D Real-World Context Graph Generation | [![GitHub](https://img.shields.io/github/stars/THU-luvision/RealGraph)](https://github.com/THU-luvision/RealGraph) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://rqhuang88.github.io/html/RealGraph.html) | :heavy_minus_sign: |
| CL-MVSNet: Unsupervised Multi-View Stereo with Dual-Level Contrastive Learning | [![GitHub](https://img.shields.io/github/stars/KaiqiangXiong/CL-MVSNet)](https://github.com/KaiqiangXiong/CL-MVSNet) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://jianbojiao.com/pdfs/iccv23_clmvs.pdf) | :heavy_minus_sign: |
| Temporal Enhanced Training of Multi-View 3D Object Detector via Historical Object Prediction | [![GitHub](https://img.shields.io/github/stars/Sense-X/HoP)](https://github.com/Sense-X/HoP) | [![arXiv](https://img.shields.io/badge/arXiv-2304.00967-b31b1b.svg)](https://arxiv.org/abs/2304.00967) | :heavy_minus_sign: |
| Object as Query: Lifting any 2D Object Detector to 3D Detection | [![GitHub](https://img.shields.io/github/stars/tusen-ai/MV2D)](https://github.com/tusen-ai/MV2D) | [![arXiv](https://img.shields.io/badge/arXiv-2301.02364-b31b1b.svg)](https://arxiv.org/abs/2301.02364) | :heavy_minus_sign: |
| PARTNER: Level up the Polar Representation for LiDAR 3D Object Detection | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.03982-b31b1b.svg)](https://arxiv.org/abs/2308.03982) | :heavy_minus_sign: |
| Not Every Side is Equal: Localization Uncertainty Estimation for Semi-Supervised 3D Object Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Adversarial Attack and Defense

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Robust Mixture-of-Expert Training for Convolutional Neural Networks | [![GitHub](https://img.shields.io/github/stars/OPTML-Group/Robust-MoE-CNN)](https://github.com/OPTML-Group/Robust-MoE-CNN) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10110-b31b1b.svg)](https://arxiv.org/abs/2308.10110) | :heavy_minus_sign: |
| Set-Level Guidance Attack: Boosting Adversarial Transferability of Vision-Language Pre-Training Models | [![GitHub](https://img.shields.io/github/stars/Zoky-2020/SGA)](https://github.com/Zoky-2020/SGA) | [![arXiv](https://img.shields.io/badge/arXiv-2307.14061-b31b1b.svg)](https://arxiv.org/abs/2307.14061) | :heavy_minus_sign: |
| CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive Learning | [![GitHub](https://img.shields.io/github/stars/nishadsinghi/CleanCLIP)](https://github.com/nishadsinghi/CleanCLIP) | [![arXiv](https://img.shields.io/badge/arXiv-2303.03323-b31b1b.svg)](https://arxiv.org/abs/2303.03323) | :heavy_minus_sign: |
| CGBA: Curvature-Aware Geometric Black-Box Attack | [![GitHub](https://img.shields.io/github/stars/Farhamdur/CGBA)](https://github.com/Farhamdur/CGBA) | [![arXiv](https://img.shields.io/badge/arXiv-2308.03163-b31b1b.svg)](https://arxiv.org/abs/2308.03163) | :heavy_minus_sign: |
| Robust Evaluation of Diffusion-based Adversarial Purification | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.09051-b31b1b.svg)](https://arxiv.org/abs/2303.09051) | :heavy_minus_sign: |
| Advancing Example Exploitation can Alleviate Critical Challenges in Adversarial Training | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| The Victim and the Beneficiary: Exploiting a Poisoned Model to Train a Clean Model on Poisoned Data | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| TIJO: Trigger Inversion with Joint Optimization for Defending Multimodal Backdoored Models | [![GitHub](https://img.shields.io/github/stars/SRI-CSL/TIJO)](https://github.com/SRI-CSL/TIJO) | [![arXiv](https://img.shields.io/badge/arXiv-2308.03906-b31b1b.svg)](https://arxiv.org/abs/2308.03906) | :heavy_minus_sign: |
| SAGA: Spectral Adversarial Geometric Attack on 3D Meshes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://stoliktomer.github.io/SAGA/) <br /> [![GitHub](https://img.shields.io/github/stars/StolikTomer/SAGA)](https://github.com/StolikTomer/SAGA) | [![arXiv](https://img.shields.io/badge/arXiv-2211.13775-b31b1b.svg)](https://arxiv.org/abs/2211.13775) | :heavy_minus_sign: |
| Benchmarking and Analyzing Robust Point Cloud Recognition: Bag of Tricks for Defending Adversarial Examples | [![GitHub](https://img.shields.io/github/stars/qiufan319/benchmark_pc_attack)](https://github.com/qiufan319/benchmark_pc_attack) | [![arXiv](https://img.shields.io/badge/arXiv-2307.16361-b31b1b.svg)](https://arxiv.org/abs/2307.16361) | :heavy_minus_sign: |
| ACTIVE: Towards Highly Transferable 3D Physical Camouflage for Universal and Robust Vehicle Evasion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://islab-ai.github.io/active-iccv2023/) | [![arXiv](https://img.shields.io/badge/arXiv-2308.07009-b31b1b.svg)](https://arxiv.org/abs/2308.07009) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=m6m90kX0O3w) |
| Frequency-Aware GAN for Adversarial Manipulation Generation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Breaking Temporal Consistency: Generating Video Universal Adversarial Perturbations using Image Models | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Tracing the Origin of Adversarial Attack for Forensic Investigation and Deterrence | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2301.01218-b31b1b.svg)](https://arxiv.org/abs/2301.01218) | :heavy_minus_sign: |
| Downstream-Agnostic Adversarial Examples | [![GitHub](https://img.shields.io/github/stars/CGCL-codes/AdvEncoder)](https://github.com/CGCL-codes/AdvEncoder) | [![arXiv](https://img.shields.io/badge/arXiv-2307.12280-b31b1b.svg)](https://arxiv.org/abs/2307.12280) | :heavy_minus_sign: |
| Hiding Visual Information via Obfuscating Adversarial Perturbations | [![GitHub](https://img.shields.io/github/stars/suzhigangssz/AVIH)](https://github.com/suzhigangssz/AVIH) | [![arXiv](https://img.shields.io/badge/arXiv-2209.15304-b31b1b.svg)](https://arxiv.org/abs/2209.15304) | :heavy_minus_sign: |
| An Embarrassingly Simple Self-Supervised Trojan Attack | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Efficient Decision-based Black-Box Patch Attacks on Video Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.11917-b31b1b.svg)](https://arxiv.org/abs/2303.11917) | :heavy_minus_sign: |
| Adversarial Finetuning with Latent Representation Constraint to Mitigate Accuracy-Robustness Tradeoff | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.16454-b31b1b.svg)](https://arxiv.org/abs/2308.16454) | :heavy_minus_sign: |
| Towards Building more Robust Models with Frequency Bias | [![GitHub](https://img.shields.io/github/stars/retsuh-bqw/ICCV23-Towards-Building-More-Robust-Models-with-Frequency-Bias)](https://github.com/retsuh-bqw/ICCV23-Towards-Building-More-Robust-Models-with-Frequency-Bias) | [![arXiv](https://img.shields.io/badge/arXiv-2307.09763-b31b1b.svg)](https://arxiv.org/abs/2307.09763) | :heavy_minus_sign: |
| System-Driven Adversarial Object Evasion Attack in Autonomous Driving | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://sites.google.com/view/cav-sec/sysadv) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11894-b31b1b.svg)](https://arxiv.org/abs/2308.11894) | :heavy_minus_sign: |
| Improving Generalization of Adversarial Training via Robust Critical Fine-Tuning | [![GitHub](https://img.shields.io/github/stars/microsoft/robustlearn)](https://github.com/microsoft/robustlearn) | [![arXiv](https://img.shields.io/badge/arXiv-2308.02533-b31b1b.svg)](https://arxiv.org/abs/2308.02533) | :heavy_minus_sign: |
| Enhancing Generalization of Universal Adversarial Perturbation through Gradient Aggregation | [![GitHub](https://img.shields.io/github/stars/liuxuannan/Stochastic-Gradient-Aggregation)](https://github.com/liuxuannan/Stochastic-Gradient-Aggregation) | [![arXiv](https://img.shields.io/badge/arXiv-2308.06015-b31b1b.svg)](https://arxiv.org/abs/2308.06015) | :heavy_minus_sign: |
| Unified Adversarial Patch for Cross-Modal Attacks in the Physical World | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.07859-b31b1b.svg)](https://arxiv.org/abs/2307.07859) | :heavy_minus_sign: |
| RFLA: A Stealthy Reflected Light Adversarial Attack in the Physical World | [![GitHub](https://img.shields.io/github/stars/winterwindwang/RFLA)](https://github.com/winterwindwang/RFLA) | [![arXiv](https://img.shields.io/badge/arXiv-2307.07653-b31b1b.svg)](https://arxiv.org/abs/2307.07653) | :heavy_minus_sign: |
| Enhancing Fine-Tuning based Backdoor Defense with Sharpness-Aware Minimization | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2304.11823-b31b1b.svg)](https://arxiv.org/abs/2304.11823) | :heavy_minus_sign: |
| Conditional 360-Degree Image Synthesis for Immersive Indoor Scene Decoration | [![GitHub](https://img.shields.io/github/stars/kcshum/neural_360_decoration)](https://github.com/kcshum/neural_360_decoration) | [![arXiv](https://img.shields.io/badge/arXiv-2307.09621-b31b1b.svg)](https://arxiv.org/abs/2307.09621) | :heavy_minus_sign: |
| An Adaptive Model Ensemble Adversarial Attack for Boosting Adversarial Transferability | [![GitHub](https://img.shields.io/github/stars/CHENBIN99/AdaEA)](https://github.com/CHENBIN99/AdaEA) | [![arXiv](https://img.shields.io/badge/arXiv-2308.02897-b31b1b.svg)](https://arxiv.org/abs/2308.02897) | :heavy_minus_sign: |
| Mitigating Adversarial Vulnerability through Causal Parameter Estimation by Adversarial Double Machine Learning | [![GitHub](https://img.shields.io/github/stars/ByungKwanLee/Double-Debiased-Adversary)](https://github.com/ByungKwanLee/Double-Debiased-Adversary) | [![arXiv](https://img.shields.io/badge/arXiv-2307.07250-b31b1b.svg)](https://arxiv.org/abs/2307.07250) | :heavy_minus_sign: |
| LEA2: A Lightweight Ensemble Adversarial Attack via Non-Overlapping Vulnerable Frequency Regions | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Explaining Adversarial Robustness of Neural Networks from Clustering Effect Perspective | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| VertexSerum: Poisoning Graph Neural Networks for Link Inference | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.01469-b31b1b.svg)](https://arxiv.org/abs/2308.01469) | :heavy_minus_sign: |
| How to Choose Your Best Allies for a Transferable Attack? | [![GitHub](https://img.shields.io/github/stars/t-maho/transferability_measure_fit)](https://github.com/t-maho/transferability_measure_fit) | [![arXiv](https://img.shields.io/badge/arXiv-2304.02312-b31b1b.svg)](https://arxiv.org/abs/2304.02312) | :heavy_minus_sign: |
| Enhancing Adversarial Robustness in Semi-Supervised Learning via Adaptively Weighted Regularization and Knowledge Distillation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.04061-b31b1b.svg)](https://arxiv.org/abs/2308.04061) | :heavy_minus_sign: |
| AdvDiffuser: Natural Adversarial Example Synthesis with Diffusion Models | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| FnF Attack Adversarial Attack against Multiple Object Trackers by Inducing False Negatives and False Positives | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Rickrolling the Artist: Injecting Backdoors into Text Encoders for Text-to-Image Synthesis | [![GitHub](https://img.shields.io/github/stars/LukasStruppek/Rickrolling-the-Artist)](https://github.com/LukasStruppek/Rickrolling-the-Artist) | [![arXiv](https://img.shields.io/badge/arXiv-2211.02408-b31b1b.svg)](https://arxiv.org/abs/2211.02408) | :heavy_minus_sign: |
| Hard No-Box Adversarial Attack on Skeleton-based Human Action Recognition with Skeleton-Motion-Informed Gradient | [![GitHub](https://img.shields.io/github/stars/luyg45/HardNoBoxAttack)](https://github.com/luyg45/HardNoBoxAttack) | [![arXiv](https://img.shields.io/badge/arXiv-2308.05681-b31b1b.svg)](https://arxiv.org/abs/2308.05681) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=hvniybZIiqA) |
| Structure Invariant Transformation for Better Adversarial Transferability | [![GitHub](https://img.shields.io/github/stars/xiaosen-wang/SIT)](https://github.com/xiaosen-wang/SIT) | :heavy_minus_sign: | :heavy_minus_sign: |
| Beating Backdoor Attack at its Own Game | [![GitHub](https://img.shields.io/github/stars/damianliumin/non-adversarial_backdoor)](https://github.com/damianliumin/non-adversarial_backdoor) | [![arXiv](https://img.shields.io/badge/arXiv-2307.15539-b31b1b.svg)](https://arxiv.org/abs/2307.15539) | :heavy_minus_sign: |
| Transferable Adversarial Attack for Both Vision Transformers and Convolutional Networks via Momentum Integrated Gradients | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| REAP: A Large-Scale Realistic Adversarial Patch Benchmark | [![GitHub](https://img.shields.io/github/stars/wagner-group/reap-benchmark)](https://github.com/wagner-group/reap-benchmark) | [![arXiv](https://img.shields.io/badge/arXiv-2212.05680-b31b1b.svg)](https://arxiv.org/abs/2212.05680) | :heavy_minus_sign: |
| Multi-Metrics Adaptively Identifies Backdoors in Federated Learning | [![GitHub](https://img.shields.io/github/stars/siquanhuang/Multi-metrics_against_backdoors_in_FL)](https://github.com/siquanhuang/Multi-metrics_against_backdoors_in_FL) | [![arXiv](https://img.shields.io/badge/arXiv-2303.06601-b31b1b.svg)](https://arxiv.org/abs/2303.06601) | :heavy_minus_sign: |
| Backpropagation Path Search on Adversarial Transferability | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.07625-b31b1b.svg)](https://arxiv.org/abs/2308.07625) | :heavy_minus_sign: |
| Fast Adaptation of Neural Networks using Test-Time Feedback | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| One-Bit Flip is All You Need: When Bit-Flip Attack Meets Model Training | [![GitHub](https://img.shields.io/github/stars/jianshuod/TBA)](https://github.com/jianshuod/TBA) | [![arXiv](https://img.shields.io/badge/arXiv-2308.07934-b31b1b.svg)](https://arxiv.org/abs/2308.07934) | :heavy_minus_sign: |
| PolicyCleanse: Backdoor Detection and Mitigation for Competitive Reinforcement Learning | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2202.03609-b31b1b.svg)](https://arxiv.org/abs/2202.03609) | :heavy_minus_sign: |
| Towards Viewpoint-Invariant Visual Recognition via Adversarial Training | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.10235-b31b1b.svg)](https://arxiv.org/abs/2307.10235) | :heavy_minus_sign: |
| Fast Adversarial Training with Smooth Convergence | [![GitHub](https://img.shields.io/github/stars/FAT-CS/ConvergeSmooth)](https://github.com/FAT-CS/ConvergeSmooth) | [![arXiv](https://img.shields.io/badge/arXiv-2308.12857-b31b1b.svg)](https://arxiv.org/abs/2308.12857) | :heavy_minus_sign: |
| The Perils of Learning from Unlabeled Data: Backdoor Attacks on Semi-Supervised Learning | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2211.00453-b31b1b.svg)](https://arxiv.org/abs/2211.00453) | :heavy_minus_sign: |
| Boosting Adversarial Transferability via Gradient Relevance Attack | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Towards Robust Model Watermark via Reducing Parametric Vulnerability | [![GitHub](https://img.shields.io/github/stars/GuanhaoGan/robust-model-watermarking)](https://github.com/GuanhaoGan/robust-model-watermarking) | [![arXiv](https://img.shields.io/badge/arXiv-2309.04777-b31b1b.svg)](https://arxiv.org/abs/2309.04777) | :heavy_minus_sign: |
| TRM-UAP: Enhancing the Transferability of Data-Free Universal Adversarial Perturbation via Truncated Ratio Maximization | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Vision and Robotics

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Simoun: Synergizing Interactive Motion-Appearance Understanding for Vision-based Reinforcement Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Among Us: Adversarially Robust Collaborative Perception by Consensus | [![GitHub](https://img.shields.io/github/stars/coperception/ROBOSAC)](https://github.com/coperception/ROBOSAC) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09495-b31b1b.svg)](https://arxiv.org/abs/2303.09495) | :heavy_minus_sign: |
| Walking Your LiDOG: A Journey Through Multiple Domains for LiDAR Semantic Segmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://saltoricristiano.github.io/lidog/) <br /> [![GitHub](https://img.shields.io/github/stars/saltoricristiano/LiDOG)](https://github.com/saltoricristiano/LiDOG) | [![arXiv](https://img.shields.io/badge/arXiv-2304.11705-b31b1b.svg)](https://arxiv.org/abs/2304.11705) | :heavy_minus_sign: |
| Stabilizing Visual Reinforcement Learning via Asymmetric Interactive Cooperation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MAAL: Multimodality-Aware Autoencoder-based Affordance Learning for 3D Articulated Objects | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Rethinking Range View Representation for LiDAR Segmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.05367-b31b1b.svg)](https://arxiv.org/abs/2303.05367) | :heavy_minus_sign: |
| PourIt!: Weakly-Supervised Liquid Perception from a Single Image for Visual Closed-Loop Robotic Pouring | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://hetolin.github.io/PourIt/) <br /> [![GitHub](https://img.shields.io/github/stars/hetolin/PourIt)](https://github.com/hetolin/PourIt) | [![arXiv](https://img.shields.io/badge/arXiv-2307.11299-b31b1b.svg)](https://arxiv.org/abs/2307.11299) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=R5SpiV0658Q) |
| CROSSFIRE: Camera Relocalization On Self-Supervised Features from an Implicit Representation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.04869-b31b1b.svg)](https://arxiv.org/abs/2303.04869) | :heavy_minus_sign: |
| Environment Agnostic Representation for Visual Reinforcement Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Test-Time Personalizable Forecasting of 3D Human Poses | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| HM-ViT: Hetero-Modal Vehicle-to-Vehicle Cooperative Perception with Vision Transformer | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2304.10628-b31b1b.svg)](https://arxiv.org/abs/2304.10628) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Vision and Graphics

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Efficient Neural Supersampling on a Novel Gaming Dataset | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.01483-b31b1b.svg)](https://arxiv.org/abs/2308.01483) | :heavy_minus_sign: |
| Locally Stylized Neural Radiance Fields | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| NEMTO: Neural Environment Matting for Novel View and Relighting Synthesis of Transparent Objects | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.11963-b31b1b.svg)](https://arxiv.org/abs/2303.11963) | :heavy_minus_sign: |
| DDColor: Towards Photo-Realistic and Semantic-Aware Image Colorization via Dual Decoders | [![GitHub](https://img.shields.io/github/stars/piddnad/DDColor)](https://github.com/piddnad/DDColor) <br /> [![ModelScope](https://img.shields.io/badge/ModelScope-DDColor-614BFF.svg)](https://www.modelscope.cn/models/damo/cv_ddcolor_image-colorization/summary) | [![arXiv](https://img.shields.io/badge/arXiv-2212.11613-b31b1b.svg)](https://arxiv.org/abs/2212.11613) | :heavy_minus_sign: |
| IntrinsicNeRF: Learning Intrinsic Neural Radiance Fields for Editable Novel View Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zju3dv.github.io/intrinsic_nerf/) <br /> [![GitHub](https://img.shields.io/github/stars/zju3dv/IntrinsicNeRF)](https://github.com/zju3dv/IntrinsicNeRF) | [![arXiv](https://img.shields.io/badge/arXiv-2210.00647-b31b1b.svg)](https://arxiv.org/abs/2210.00647) | :heavy_minus_sign: |
| PARIS: Part-Level Reconstruction and Motion Analysis for Articulated Objects | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://3dlg-hcvc.github.io/paris/) <br /> [![GitHub](https://img.shields.io/github/stars/3dlg-hcvc/paris)](https://github.com/3dlg-hcvc/paris) | [![arXiv](https://img.shields.io/badge/arXiv-2308.07391-b31b1b.svg)](https://arxiv.org/abs/2308.07391) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=tDSrROPCgUc) |
| ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://mingyuan-zhang.github.io/projects/ReMoDiffuse.html) <br /> [![GitHub](https://img.shields.io/github/stars/mingyuan-zhang/ReMoDiffuse)](https://github.com/mingyuan-zhang/ReMoDiffuse) | [![arXiv](https://img.shields.io/badge/arXiv-2304.01116-b31b1b.svg)](https://arxiv.org/abs/2304.01116) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=wSddrIA_2p8) |
| DS-Fusion: Artistic Typography via Discriminated and Stylized Diffusion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ds-fusion.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/tmaham/DS-Fusion)](https://github.com/tmaham/DS-Fusion) <br /> [![Hugging Face](https://img.shields.io/badge/ðŸ¤—-tmaham-FFD21F.svg)](https://huggingface.co/spaces/tmaham/DS-Fusion-Express) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09604-b31b1b.svg)](https://arxiv.org/abs/2303.09604) | :heavy_minus_sign: |
| Dynamic Mesh-Aware Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://mesh-aware-rf.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/YilingQiao/DMRF)](https://github.com/YilingQiao/DMRF) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://drive.google.com/file/d/1uXg76v0CNVxgrQfBHPR5SbxIMXyPLFfQ/view) | :heavy_minus_sign: |
| Neural Reconstruction of Relightable Human Model from Monocular Video | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Neural Microfacet Fields for Inverse Rendering | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://half-potato.gitlab.io/posts/nmf/) <br /> [![GitHub](https://img.shields.io/github/stars/half-potato/nmf)](https://github.com/half-potato/nmf) | [![arXiv](https://img.shields.io/badge/arXiv-2303.17806-b31b1b.svg)](https://arxiv.org/abs/2303.17806) | :heavy_minus_sign: |
| A Theory of Topological Derivatives for Inverse Rendering of Geometry | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ishit.github.io/td/) | [![arXiv](https://img.shields.io/badge/arXiv-2308.09865-b31b1b.svg)](https://arxiv.org/abs/2308.09865) | :heavy_minus_sign: |
| Vox-E: Text-Guided Voxel Editing of 3D Objects | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://tau-vailab.github.io/Vox-E/) <br /> [![GitHub](https://img.shields.io/github/stars/TAU-VAILab/Vox-E)](https://github.com/TAU-VAILab/Vox-E) | [![arXiv](https://img.shields.io/badge/arXiv-2303.12048-b31b1b.svg)](https://arxiv.org/abs/2303.12048) | :heavy_minus_sign: |
| StegaNeRF: Embedding Invisible Information within Neural Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://xggnet.github.io/StegaNeRF/) <br /> [![GitHub](https://img.shields.io/github/stars/XGGNet/StegaNeRF)](https://github.com/XGGNet/StegaNeRF) | [![arXiv](https://img.shields.io/badge/arXiv-2212.01602-b31b1b.svg)](https://arxiv.org/abs/2212.01602) | :heavy_minus_sign: |
| GlobalMapper: Arbitrary-Shaped Urban Layout Generation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.09693-b31b1b.svg)](https://arxiv.org/abs/2307.09693) | :heavy_minus_sign: |
| Urban Radiance Field Representation with Deformable Neural Mesh Primitives | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dnmp.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/DNMP/DNMP)](https://github.com/DNMP/DNMP) | [![arXiv](https://img.shields.io/badge/arXiv-2307.10776-b31b1b.svg)](https://arxiv.org/abs/2307.10776) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JABhlaVq4VA) |
| End2End Multi-View Feature Matching with Differentiable Pose Optimization | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://barbararoessle.github.io/e2e_multi_view_matching/) | [![arXiv](https://img.shields.io/badge/arXiv-2205.01694-b31b1b.svg)](https://arxiv.org/abs/2205.01694) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5bFIIDOHRZY) |
| Tree-Structured Shading Decomposition | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chen-geng.com/inv-shade-trees/index.html) <br /> [![GitHub](https://img.shields.io/github/stars/gcgeng/inv-shade-trees)](https://github.com/gcgeng/inv-shade-trees) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://chen-geng.com/files/inv-shade-trees.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=L7zD9zM_zcg) |
| Lens Parameter Estimation for Realistic Depth of Field Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lvsn.github.io/inversedof/) | :heavy_minus_sign: | :heavy_minus_sign: |
| AttT2M: Text-Driven Human Motion Generation with Multi-Perspective Attention Mechanism | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Cross-Modal Latent Space Alignment for Image to Avatar Translation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Computationally Efficient Neural Image Compression with Shallow Decoders | [![GitHub](https://img.shields.io/github/stars/mandt-lab/shallow-ntc)](https://github.com/mandt-lab/shallow-ntc) | [![arXiv](https://img.shields.io/badge/arXiv-2304.06244-b31b1b.svg)](https://arxiv.org/abs/2304.06244) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Segmentation, Grouping and Shape Analysis

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Enhancing Spatial and Semantic Supervision for Hybrid-based 3D Instance Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Learning Neural Eigenfunctions for Unsupervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/thudzj/NeuralEigenfunctionSegmentor)](https://github.com/thudzj/NeuralEigenfunctionSegmentor) | [![arXiv](https://img.shields.io/badge/arXiv-2304.02841-b31b1b.svg)](https://arxiv.org/abs/2304.02841) | :heavy_minus_sign: |
| Divide and Conquer: 3D Point Cloud Instance Segmentation with Point-Wise Binarization | [![GitHub](https://img.shields.io/github/stars/weiguangzhao/PBNet)](https://github.com/weiguangzhao/PBNet) | [![arXiv](https://img.shields.io/badge/arXiv-2207.11209-b31b1b.svg)](https://arxiv.org/abs/2207.11209) | :heavy_minus_sign: |
| Point2Mask: Point-Supervised Panoptic Segmentation via Optimal Transport | [![GitHub](https://img.shields.io/github/stars/LiWentomng/Point2Mask)](https://github.com/LiWentomng/Point2Mask) | [![arXiv](https://img.shields.io/badge/arXiv-2308.01779-b31b1b.svg)](https://arxiv.org/abs/2308.01779) | :heavy_minus_sign: |
| Handwritten and Printed Text Segmentation: A Signature Case Study | [![SignaTR6K](https://img.shields.io/badge/SignaTR6K-dataset-20BEFF.svg)](https://forms.office.com/r/2a5RDg7cAY) | [![arXiv](https://img.shields.io/badge/arXiv-2307.07887-b31b1b.svg)](https://arxiv.org/abs/2307.07887) | :heavy_minus_sign: |
| Semantic-Aware Template Learning via Part Deformation Consistency | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.11916-b31b1b.svg)](https://arxiv.org/abs/2308.11916) | :heavy_minus_sign: |
| LeaF: Learning Frames for 4D Point Cloud Sequence Understanding | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MARS: Model-Agnostic Biased Object Removal without Additional Supervision for Weakly-Supervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/shjo-april/MARS)](https://github.com/shjo-april/MARS) | [![arXiv](https://img.shields.io/badge/arXiv-2304.09913-b31b1b.svg)](https://arxiv.org/abs/2304.09913) | :heavy_minus_sign: |
| USAGE: A Unified Seed Area Generation Paradigm for Weakly Supervised Semantic Segmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.07806-b31b1b.svg)](https://arxiv.org/abs/2303.07806) | :heavy_minus_sign: |
| Production-Level Video Segmentation from Few Annotated Frames | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://max810.github.io/xmem2-project-page/) <br /> [![GitHub](https://img.shields.io/github/stars/max810/XMem2)](https://github.com/max810/XMem2) | [![arXiv](https://img.shields.io/badge/arXiv-2307.15958-b31b1b.svg)](https://arxiv.org/abs/2307.15958) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=3X3TUP4vKcc) |
| Î£IGMA: Scale-Invariant Global Sparse Shape Matching | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.08393-b31b1b.svg)](https://arxiv.org/abs/2308.08393) | :heavy_minus_sign: |
| Self-Calibrated Cross Attention Network for Few-Shot Segmentation | [![GitHub](https://img.shields.io/github/stars/Sam1224/SCCAN)](https://github.com/Sam1224/SCCAN) | [![arXiv](https://img.shields.io/badge/arXiv-2308.09294-b31b1b.svg)](https://arxiv.org/abs/2308.09294) | :heavy_minus_sign: |
| Multi-Granularity Interaction Simulation for Unsupervised Interactive Segmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.13399-b31b1b.svg)](https://arxiv.org/abs/2303.13399) | :heavy_minus_sign: |
| Texture Learning Domain Randomization for Domain Generalized Segmentation | [![GitHub](https://img.shields.io/github/stars/ssssshwan/TLDR)](https://github.com/ssssshwan/TLDR) | [![arXiv](https://img.shields.io/badge/arXiv-2303.11546-b31b1b.svg)](https://arxiv.org/abs/2303.11546) | :heavy_minus_sign: |
| Unsupervised Video Object Segmentation with Online Adversarial Self-Tuning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Exploring Open-Vocabulary Semantic Segmentation without Human Labels | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.00450-b31b1b.svg)](https://arxiv.org/abs/2306.00450) | :heavy_minus_sign: |
| RbA: Segmenting Unknown Regions Rejected by All | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://kuis-ai.github.io/RbA/) <br /> [![GitHub](https://img.shields.io/github/stars/NazirNayal8/RbA)](https://github.com/NazirNayal8/RbA) | [![arXiv](https://img.shields.io/badge/arXiv-2211.14293-b31b1b.svg)](https://arxiv.org/abs/2211.14293) | :heavy_minus_sign: |
| SEMPART: Self-Supervised Multi-Resolution Partitioning of Image Semantics | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Multi-Object Discovery by Low-Dimensional Object Motion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://kuis-ai.github.io/multi-object-segmentation/) <br /> [![GitHub](https://img.shields.io/github/stars/sadrasafa/multi-object-segmentation)](https://github.com/sadrasafa/multi-object-segmentation) | [![arXiv](https://img.shields.io/badge/arXiv-2307.08027-b31b1b.svg)](https://arxiv.org/abs/2307.08027) | :heavy_minus_sign: |
| MemorySeg: Online LiDAR Semantic Segmentation with a Latent Memory | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Treating Pseudo-Labels Generation as Image Matting for Weakly Supervised Semantic Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| BoxSnake: Polygonal Instance Segmentation with Box Supervision | [![GitHub](https://img.shields.io/github/stars/Yangr116/BoxSnake)](https://github.com/Yangr116/BoxSnake) | [![arXiv](https://img.shields.io/badge/arXiv-2303.11630-b31b1b.svg)](https://arxiv.org/abs/2303.11630) | :heavy_minus_sign: |
| Dynamic Token Pruning in Plain Vision Transformers for Semantic Segmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.01045-b31b1b.svg)](https://arxiv.org/abs/2308.01045) | :heavy_minus_sign: |
| Instance Neural Radiance Field | [![GitHub](https://img.shields.io/github/stars/lyclyc52/Instance_NeRF)](https://github.com/lyclyc52/Instance_NeRF) | [![arXiv](https://img.shields.io/badge/arXiv-2304.04395-b31b1b.svg)](https://arxiv.org/abs/2304.04395) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=wW9Bme73coI) |
| Global Knowledge Calibration for Fast Open-Vocabulary Segmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.09181-b31b1b.svg)](https://arxiv.org/abs/2303.09181) | :heavy_minus_sign: |
| Diffusion-based Image Translation with Label Guidance for Domain Adaptive Semantic Segmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.12350-b31b1b.svg)](https://arxiv.org/abs/2308.12350) | :heavy_minus_sign: |
| Boosting Semantic Segmentation from an Explicit Class Embedding's Perspective | [![gitee](https://gitee-badge.vercel.app/svg/stars/mindspore/models)](https://gitee.com/mindspore/models) | [![arXiv](https://img.shields.io/badge/arXiv-2308.12894-b31b1b.svg)](https://arxiv.org/abs/2308.12894) | :heavy_minus_sign: |
| The Making and Breaking of Camouflage | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| CoinSeg: Contrast Inter- and Intra- Class Representations for Incremental Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Few-Shot Physically-Aware Articulated Mesh Generation via Hierarchical Deformation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://meowuu7.github.io/few-arti-obj-gen/) <br /> [![GitHub](https://img.shields.io/github/stars/Meowuu7/few-arti-gen)](https://github.com/Meowuu7/few-arti-gen) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10898-b31b1b.svg)](https://arxiv.org/abs/2308.10898) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=p8x3GN3VSPE) |
| HAL3D: Hierarchical Active Learning for Fine-Grained 3D Part Labeling | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2301.10460-b31b1b.svg)](https://arxiv.org/abs/2301.10460) | :heavy_minus_sign: |
| FreeCOS: Self-Supervised Learning from Fractals and Unlabeled Images for Curvilinear Object Segmentation | [![GitHub](https://img.shields.io/github/stars/TY-Shi/FreeCOS)](https://github.com/TY-Shi/FreeCOS) | [![arXiv](https://img.shields.io/badge/arXiv-2307.07245-b31b1b.svg)](https://arxiv.org/abs/2307.07245) | :heavy_minus_sign: |
| MasQCLIP for Open-Vocabulary Universal Image Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| CTVIS: Consistent Training for Online Video Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/KainingYing/CTVIS)](https://github.com/KainingYing/CTVIS) | [![arXiv](https://img.shields.io/badge/arXiv-2307.12616-b31b1b.svg)](https://arxiv.org/abs/2307.12616) | :heavy_minus_sign: |
| A Simple Framework for Panoptic Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Spectrum-Guided Multi-Granularity Referring Video Object Segmentation | [![GitHub](https://img.shields.io/github/stars/bo-miao/SgMg)](https://github.com/bo-miao/SgMg) | [![arXiv](https://img.shields.io/badge/arXiv-2307.13537-b31b1b.svg)](https://arxiv.org/abs/2307.13537) | :heavy_minus_sign: |
| Space Engage: Collaborative Space Supervision for Contrastive-based Semi-Supervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/WangChangqi98/CSS)](https://github.com/WangChangqi98/CSS) | [![arXiv](https://img.shields.io/badge/arXiv-2307.09755-b31b1b.svg)](https://arxiv.org/abs/2307.09755) | :heavy_minus_sign: |
| Adaptive Superpixel for Active Learning in Semantic Segmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.16817-b31b1b.svg)](https://arxiv.org/abs/2303.16817) | :heavy_minus_sign: |
| Multimodal Variational Auto-Encoder based Audio-Visual Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Isomer: Isomerous Transformer for Zero-Shot Video Object Segmentation | [![GitHub](https://img.shields.io/github/stars/DLUT-yyc/Isomer)](https://github.com/DLUT-yyc/Isomer) | [![arXiv](https://img.shields.io/badge/arXiv-2308.06693-b31b1b.svg)](https://arxiv.org/abs/2308.06693) | :heavy_minus_sign: |
| 2D-3D Interlaced Transformer for Point Cloud Segmentation with Scene-Level Supervision | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jimmy15923.github.io/mit_web/) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](http://vllab.cs.nctu.edu.tw/images/paper/iccv-yang23.pdf) | :heavy_minus_sign: |
| Foreground-Background Separation through Concept Distillation from Generative Image Foundation Models | [![GitHub](https://img.shields.io/github/stars/MischaD/fobadiffusion)](https://github.com/MischaD/fobadiffusion) | [![arXiv](https://img.shields.io/badge/arXiv-2212.14306-b31b1b.svg)](https://arxiv.org/abs/2212.14306) | :heavy_minus_sign: |
| SegPrompt: Boosting Open-World Segmentation via Category-Level Prompt Learning | [![GitHub](https://img.shields.io/github/stars/aim-uofa/SegPrompt)](https://github.com/aim-uofa/SegPrompt) | [![arXiv](https://img.shields.io/badge/arXiv-2308.06531-b31b1b.svg)](https://arxiv.org/abs/2308.06531) | :heavy_minus_sign: |
| Monte Carlo Linear Clustering with Single-Point Supervision is Enough for Infrared Small Target Detection | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yeren123455.github.io/SIRST-Single-Point-Supervision/) <br /> [![GitHub](https://img.shields.io/github/stars/YeRen123455/SIRST-Single-Point-Supervision)](https://github.com/YeRen123455/SIRST-Single-Point-Supervision) | [![arXiv](https://img.shields.io/badge/arXiv-2304.04442-b31b1b.svg)](https://arxiv.org/abs/2304.04442) | :heavy_minus_sign: |
| A Simple Framework for Open-Vocabulary Segmentation and Detection | [![GitHub](https://img.shields.io/github/stars/IDEA-Research/OpenSeeD)](https://github.com/IDEA-Research/OpenSeeD) | [![arXiv](https://img.shields.io/badge/arXiv-2303.08131-b31b1b.svg)](https://arxiv.org/abs/2303.08131) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=z4gsQw2n7iM) |
| Source-Free Depth for Object Pop-Out | [![GitHub](https://img.shields.io/github/stars/Zongwei97/PopNet)](https://github.com/Zongwei97/PopNet) | [![arXiv](https://img.shields.io/badge/arXiv-2212.05370-b31b1b.svg)](https://arxiv.org/abs/2212.05370) | :heavy_minus_sign: |
| DynaMITe: Dynamic Query Bootstrapping for Multi-Object Interactive Segmentation Transformer | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://amitrana001.github.io/DynaMITe/) <br /> [![GitHub](https://img.shields.io/github/stars/amitrana001/DynaMITe)](https://github.com/amitrana001/DynaMITe) | [![arXiv](https://img.shields.io/badge/arXiv-2304.06668-b31b1b.svg)](https://arxiv.org/abs/2304.06668) | :heavy_minus_sign: |
| Atmospheric Transmission and Thermal Inertia Induced Blind Road Segmentation with a Large-Scale Dataset TBRSD | [![GitHub](https://img.shields.io/github/stars/chenjzBUAA/TBRSD)](https://github.com/chenjzBUAA/TBRSD) | :heavy_minus_sign: | :heavy_minus_sign: |
| Informative Data Mining for One-Shot Cross-Domain Semantic Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Homography Guided Temporal Fusion for Road Line and Marking Segmentation | [![GitHub](https://img.shields.io/github/stars/ShanWang-Shan/HomoFusion)](https://github.com/ShanWang-Shan/HomoFusion) | :heavy_minus_sign: | :heavy_minus_sign: |
| Zero-Shot Semantic Segmentation with Decoupled One-Shot Network | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| TCOVIS: Temporally Consistent Online Video Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/jun-long-li/TCOVIS)](https://github.com/jun-long-li/TCOVIS) | :heavy_minus_sign: | :heavy_minus_sign: |
| FPR: False Positive Rectification for Weakly Supervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/mt-cly/FPR)](https://github.com/mt-cly/FPR) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](http://www4.comp.polyu.edu.hk/~cslzhang/paper/ICCV23-FPR.pdf) | :heavy_minus_sign: |
| Stochastic Segmentation with Conditional Categorical Diffusion Models | [![GitHub](https://img.shields.io/github/stars/LarsDoorenbos/ccdm-stochastic-segmentation)](https://github.com/LarsDoorenbos/ccdm-stochastic-segmentation) | [![arXiv](https://img.shields.io/badge/arXiv-2303.08888-b31b1b.svg)](https://arxiv.org/abs/2303.08888) | :heavy_minus_sign: |
| SegGPT: Segmenting Everything in Context | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://github.com/baaivision/Painter/tree/main/SegGPT) <br /> [![GitHub](https://img.shields.io/github/stars/baaivision/Painter)](https://github.com/baaivision/Painter) <br /> [![Hugging Face](https://img.shields.io/badge/ðŸ¤—-SegGPT-FFD21F.svg)](https://huggingface.co/spaces/BAAI/SegGPT) | [![arXiv](https://img.shields.io/badge/arXiv-2304.03284-b31b1b.svg)](https://arxiv.org/abs/2304.03284) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zxwH0dUBKis) |
| Open-Vocabulary Panoptic Segmentation with Embedding Modulation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.11324-b31b1b.svg)](https://arxiv.org/abs/2303.11324) | :heavy_minus_sign: |
| Residual Pattern Learning for Pixel-Wise Out-of-Distribution Detection in Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/yyliu01/RPL)](https://github.com/yyliu01/RPL) | [![arXiv](https://img.shields.io/badge/arXiv-2211.14512-b31b1b.svg)](https://arxiv.org/abs/2211.14512) | :heavy_minus_sign: |
| Zero-Guidance Segmentation using Zero Segment Labels | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zero-guide-seg.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2303.13396-b31b1b.svg)](https://arxiv.org/abs/2303.13396) | :heavy_minus_sign: |
| Model Calibration in Dense Classification with Adaptive Label Perturbation | [![GitHub](https://img.shields.io/github/stars/Carlisle-Liu/ASLP)](https://github.com/Carlisle-Liu/ASLP) | [![arXiv](https://img.shields.io/badge/arXiv-2307.13539-b31b1b.svg)](https://arxiv.org/abs/2307.13539) | :heavy_minus_sign: |
| Enhanced Soft Label for Semi-Supervised Semantic Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MixReorg: Cross-Modal Mixed Patch Reorganization is a Good Mask Learner for Open-World Semantic Segmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.04829-b31b1b.svg)](https://arxiv.org/abs/2308.04829) | :heavy_minus_sign: |
| DiffuMask: Synthesizing Images with Pixel-Level Annotations for Semantic Segmentation using Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://weijiawu.github.io/DiffusionMask/) <br /> [![GitHub](https://img.shields.io/github/stars/weijiawu/DiffuMask)](https://github.com/weijiawu/DiffuMask) | [![arXiv](https://img.shields.io/badge/arXiv-2303.11681-b31b1b.svg)](https://arxiv.org/abs/2303.11681) | :heavy_minus_sign: |
| Alignment Before Aggregation: Trajectory Memory Retrieval Network for Video Object Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Semi-Supervised Semantic Segmentation under Label Noise via Diverse Learning Groups | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| SUMMIT: Source-Free Adaptation of Uni-Modal Models to Multi-Modal Targets | [![GitHub](https://img.shields.io/github/stars/csimo005/SUMMIT)](https://github.com/csimo005/SUMMIT) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11880-b31b1b.svg)](https://arxiv.org/abs/2308.11880) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LDlLq9IdoAw) |
| Class-Incremental Continual Learning for Instance Segmentation with Image-Level Weak Supervision | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Coarse-to-Fine Amodal Segmentation with Shape Prior | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jianxgao.github.io/C2F-Seg/) <br /> [![GitHub](https://img.shields.io/github/stars/JianxGao/C2F-Seg)](https://github.com/JianxGao/C2F-Seg) | [![arXiv](https://img.shields.io/badge/arXiv-2308.16825-b31b1b.svg)](https://arxiv.org/abs/2308.16825) | :heavy_minus_sign: |
| Rethinking Amodal Video Segmentation from Learning Supervised Signals with Object-Centric Representation | [![GitHub](https://img.shields.io/github/stars/kfan21/EoRaS)](https://github.com/kfan21/EoRaS) | :heavy_minus_sign: | :heavy_minus_sign: |
| DVIS: Decoupled Video Instance Segmentation Framework | [![GitHub](https://img.shields.io/github/stars/zhang-tao-whu/DVIS)](https://github.com/zhang-tao-whu/DVIS) | [![arXiv](https://img.shields.io/badge/arXiv-2306.03413-b31b1b.svg)](https://arxiv.org/abs/2306.03413) | :heavy_minus_sign: |
| 3D Segmentation of Humans in Point Clouds with Synthetic Data | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://human-3d.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2212.00786-b31b1b.svg)](https://arxiv.org/abs/2212.00786) | :heavy_minus_sign: |
| WaterMask: Instance Segmentation for Underwater Imagery | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Decoupled or End-to-End Trained Video Segmentation if Target Data is Scarce? | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Recognition: Categorization

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Cross Contrasting Feature Perturbation for Domain Generalization | [![GitHub](https://img.shields.io/github/stars/hackmebroo/CCFP)](https://github.com/hackmebroo/CCFP) | [![arXiv](https://img.shields.io/badge/arXiv-2307.12502-b31b1b.svg)](https://arxiv.org/abs/2307.12502) | :heavy_minus_sign: |
| Flexible Visual Recognition by Evidential Modeling of Confusion and Ignorance | :heavy_minus_sign: | :heavy_minus_sign:  | :heavy_minus_sign: |
| CDUL: CLIP-Driven Unsupervised Learning for Multi-Label Image Classification | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.16634-b31b1b.svg)](https://arxiv.org/abs/2307.16634) | :heavy_minus_sign: |
| RankMixup: Ranking-based Mixup Training for Network Calibration | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://cvlab.yonsei.ac.kr/projects/RankMixup/) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11990-b31b1b.svg)](https://arxiv.org/abs/2308.11990) | :heavy_minus_sign: |
| Label-Noise Learning with Intrinsically Long-Tailed Data | [![GitHub](https://img.shields.io/github/stars/Wakings/TABASCO)](https://github.com/Wakings/TABASCO) | [![arXiv](https://img.shields.io/badge/arXiv-2208.09833-b31b1b.svg)](https://arxiv.org/abs/2208.09833) | :heavy_minus_sign: |
| Parallel Attention Interaction Network for Few-Shot Skeleton-based Action Recognition | [![GitHub](https://img.shields.io/github/stars/starrycos/PAINet)](https://github.com/starrycos/PAINet) | :heavy_minus_sign: | :heavy_minus_sign: |
| Rethinking Mobile Block for Efficient Attention-based Models | [![GitHub](https://img.shields.io/github/stars/zhangzjn/EMO)](https://github.com/zhangzjn/EMO) | [![arXiv](https://img.shields.io/badge/arXiv-2301.01146-b31b1b.svg)](https://arxiv.org/abs/2301.01146) | :heavy_minus_sign: |
| Read-Only Prompt Optimization for Vision-Language Few-Shot Learning | [![GitHub](https://img.shields.io/github/stars/mlvlab/RPO)](https://github.com/mlvlab/RPO) | [![arXiv](https://img.shields.io/badge/arXiv-2308.14960-b31b1b.svg)](https://arxiv.org/abs/2308.14960) | :heavy_minus_sign: |
| Understanding Self-Attention Mechanism via Dynamical System Perspective | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.09939-b31b1b.svg)](https://arxiv.org/abs/2308.09939) | :heavy_minus_sign: |
| Learning in Imperfect Environment: Multi-Label Classification with Long-Tailed Distribution and Partial Labels | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2304.10539-b31b1b.svg)](https://arxiv.org/abs/2304.10539) | :heavy_minus_sign: |
| What do Neural Networks Learn in Image Classification? A Frequency Shortcut Perspective | [![GitHub](https://img.shields.io/github/stars/nis-research/nn-frequency-shortcuts)](https://github.com/nis-research/nn-frequency-shortcuts) | [![arXiv](https://img.shields.io/badge/arXiv-2307.09829-b31b1b.svg)](https://arxiv.org/abs/2307.09829) | :heavy_minus_sign: |
| Inducing Neural Collapse to a Fixed Hierarchy-Aware Frame for Reducing Mistake Severity | [![GitHub](https://img.shields.io/github/stars/ltong1130ztr/HAFrame)](https://github.com/ltong1130ztr/HAFrame) | [![arXiv](https://img.shields.io/badge/arXiv-2303.05689-b31b1b.svg)](https://arxiv.org/abs/2303.05689) | :heavy_minus_sign: |
| Unified Out-of-Distribution Detection: A Model-Specific Perspective | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2304.06813-b31b1b.svg)](https://arxiv.org/abs/2304.06813) | :heavy_minus_sign: |
| A Unified Framework for Robustness on Diverse Sampling Errors | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Scene-Aware Label Graph Learning for Multi-Label Image Classification | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Holistic Label Correction for Noisy Multi-Label Classification | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Strip-MLP: Efficient Token Interaction for Vision MLP | [![GitHub](https://img.shields.io/github/stars/Med-Process/Strip_MLP)](https://github.com/Med-Process/Strip_MLP) | [![arXiv](https://img.shields.io/badge/arXiv-2307.11458-b31b1b.svg)](https://arxiv.org/abs/2307.11458) | :heavy_minus_sign: |
| EQ-Net: Elastic Quantization Neural Networks | [![GitHub](https://img.shields.io/github/stars/xuke225/EQ-Net)](https://github.com/xuke225/EQ-Net) | [![arXiv](https://img.shields.io/badge/arXiv-2308.07650-b31b1b.svg)](https://arxiv.org/abs/2308.07650) | :heavy_minus_sign: |
| Data-Free Knowledge Distillation for Fine-Grained Vision Categorization | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Shift from Texture-Bias to Shape-Bias: edge Deformation-based Augmentation for Robust Object Recognition | [![GitHub](https://img.shields.io/github/stars/C0notSilly/-ICCV-23-Edge-Deformation-based-Online-Augmentation)](https://github.com/C0notSilly/-ICCV-23-Edge-Deformation-based-Online-Augmentation) | :heavy_minus_sign: | :heavy_minus_sign: |
| Latent-OFER: Detect, Mask, and Reconstruct with Latent Vectors for Occluded Facial Expression Recognition | [![GitHub](https://img.shields.io/github/stars/leeisack/Latent-OFER)](https://github.com/leeisack/Latent-OFER) | [![arXiv](https://img.shields.io/badge/arXiv-2307.11404-b31b1b.svg)](https://arxiv.org/abs/2307.11404) | :heavy_minus_sign: |
| DR-Tune: Improving Fine-Tuning of Pretrained Visual Models by Distribution Regularization with Semantic Calibration | [![GitHub](https://img.shields.io/github/stars/weeknan/DR-Tune)](https://github.com/weeknan/DR-Tune) | [![arXiv](https://img.shields.io/badge/arXiv-2308.12058-b31b1b.svg)](https://arxiv.org/abs/2308.12058) | :heavy_minus_sign: |
| Understanding the Feature Norm for Out-of-Distribution Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Multi-View Active Fine-Grained Visual Recognition | [![GitHub](https://img.shields.io/github/stars/PRIS-CV/AFGR)](https://github.com/PRIS-CV/AFGR) | [![arXiv](https://img.shields.io/badge/arXiv-2206.01153-b31b1b.svg)](https://arxiv.org/abs/2206.01153) | :heavy_minus_sign: |
| DiffGuard: Semantic Mismatch-Guided Out-of-Distribution Detection using Pre-Trained Diffusion Models | [![GitHub](https://img.shields.io/github/stars/cure-lab/DiffGuard)](https://github.com/cure-lab/DiffGuard) | [![arXiv](https://img.shields.io/badge/arXiv-2308.07687-b31b1b.svg)](https://arxiv.org/abs/2308.07687) | :heavy_minus_sign: |
| Task-Aware Adaptive Learning for Cross-Domain Few-Shot Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Improving Adversarial Robustness of Masked Autoencoders via Test-Time Frequency-Domain Prompting | [![GitHub](https://img.shields.io/github/stars/shikiw/RobustMAE)](https://github.com/shikiw/RobustMAE) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10315-b31b1b.svg)](https://arxiv.org/abs/2308.10315) | :heavy_minus_sign: |
| Saliency Regularization for Self-Training with Partial Annotations | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Learning Gabor Texture Features for Fine-Grained Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.05396-b31b1b.svg)](https://arxiv.org/abs/2308.05396) | :heavy_minus_sign: |
| UniFormerV2: Unlocking the Potential of Image ViTs for Video Understanding | [![GitHub](https://img.shields.io/github/stars/OpenGVLab/UniFormerV2)](https://github.com/OpenGVLab/UniFormerV2) | [![arXiv](https://img.shields.io/badge/arXiv-2211.09552-b31b1b.svg)](https://arxiv.org/abs/2211.09552) | :heavy_minus_sign: |
| RankMatch: Fostering Confidence and Consistency in Learning with Noisy Labels | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MetaGCD: Learning to Continually Learn in Generalized Category Discovery | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.11063-b31b1b.svg)](https://arxiv.org/abs/2308.11063) | :heavy_minus_sign: |
| FerKD: Surgical Label Adaptation for Efficient Distillation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Point-Query Quadtree for Crowd Counting, Localization, and more | [![GitHub](https://img.shields.io/github/stars/cxliu0/PET)](https://github.com/cxliu0/PET) | [![arXiv](https://img.shields.io/badge/arXiv-2308.13814-b31b1b.svg)](https://arxiv.org/abs/2308.13814) | :heavy_minus_sign: |
| Nearest Neighbor Guidance for Out-of-Distribution Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Bayesian Optimization Meets Self-Distillation | [![GitHub](https://img.shields.io/github/stars/sooperset/boss)](https://github.com/sooperset/boss) | [![arXiv](https://img.shields.io/badge/arXiv-2304.12666-b31b1b.svg)](https://arxiv.org/abs/2304.12666) | :heavy_minus_sign: |
| When Prompt-based Incremental Learning does not Meet Strong Pretraining | [![GitHub](https://img.shields.io/github/stars/TOM-tym/APG)](https://github.com/TOM-tym/APG) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10445-b31b1b.svg)](https://arxiv.org/abs/2308.10445) | :heavy_minus_sign: |
| When to Learn what: Model-Adaptive Data Augmentation Curriculum | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Parametric Information Maximization for Generalized Category Discovery | [![GitHub](https://img.shields.io/github/stars/ThalesGroup/pim-generalized-category-discovery)](https://github.com/ThalesGroup/pim-generalized-category-discovery) | [![arXiv](https://img.shields.io/badge/arXiv-2212.00334-b31b1b.svg)](https://arxiv.org/abs/2212.00334) | :heavy_minus_sign: |
| Boosting Few-Shot Action Recognition with Graph-Guided Hybrid Matching | [![GitHub](https://img.shields.io/github/stars/jiazheng-xing/GgHM)](https://github.com/jiazheng-xing/GgHM) | [![arXiv](https://img.shields.io/badge/arXiv-2308.09346-b31b1b.svg)](https://arxiv.org/abs/2308.09346) | :heavy_minus_sign: |
| Domain Generalization via Rationale Invariance | [![GitHub](https://img.shields.io/github/stars/liangchen527/RIDG)](https://github.com/liangchen527/RIDG) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11158-b31b1b.svg)](https://arxiv.org/abs/2308.11158) | :heavy_minus_sign: |
| Masked Spiking Transformer | [![GitHub](https://img.shields.io/github/stars/bic-L/Masked-Spiking-Transformer)](https://github.com/bic-L/Masked-Spiking-Transformer) | [![arXiv](https://img.shields.io/badge/arXiv-2210.01208-b31b1b.svg)](https://arxiv.org/abs/2210.01208) | :heavy_minus_sign: |
| Prototype Reminiscence and Augmented Asymmetric Knowledge Aggregation for Non-Exemplar Class-Incremental Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Distilled Reverse Attention Network for Open-World Compositional Zero-Shot Learning | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.00404-b31b1b.svg)](https://arxiv.org/abs/2303.00404) | :heavy_minus_sign: |
| Candidate-Aware Selective Disambiguation based on Normalized Entropy for Instance-Dependent Partial-Label Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| CLIPN for Zero-Shot OOD Detection: Teaching CLIP to Say No | [![GitHub](https://img.shields.io/github/stars/xmed-lab/CLIPN)](https://github.com/xmed-lab/CLIPN) | [![arXiv](https://img.shields.io/badge/arXiv-2308.12213-b31b1b.svg)](https://arxiv.org/abs/2308.12213) | :heavy_minus_sign: |
| Self-Similarity Driven Scale-Invariant Learning for Weakly Supervised Person Search | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2302.12986-b31b1b.svg)](https://arxiv.org/abs/2302.12986) | :heavy_minus_sign: |
| Sample-Wise Label Confidence Incorporation for Learning with Noisy Labels | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Combating Noisy Labels with Sample Selection by Mining High-Discrepancy Examples | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Spatial-Aware Token for Weakly Supervised Object Localization | [![GitHub](https://img.shields.io/github/stars/wpy1999/SAT)](https://github.com/wpy1999/SAT) | [![arXiv](https://img.shields.io/badge/arXiv-2303.10438-b31b1b.svg)](https://arxiv.org/abs/2303.10438) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Explainable AI for CV

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Towards Improved Input Masking for Convolutional Neural Networks | [![GitHub](https://img.shields.io/github/stars/SriramB-98/layer_masking)](https://github.com/SriramB-98/layer_masking) | [![arXiv](https://img.shields.io/badge/arXiv-2211.14646-b31b1b.svg)](https://arxiv.org/abs/2211.14646) | :heavy_minus_sign: |
| PDiscoNet: Semantically Consistent Part Discovery for Fine-Grained Recognition | [![GitHub](https://img.shields.io/github/stars/robertdvdk/part_detection)](https://github.com/robertdvdk/part_detection) | [![HAL Science](https://img.shields.io/badge/hal-science-040060.svg)](https://hal.inrae.fr/hal-04183747) | :heavy_minus_sign: |
| Corrupting Neuron Explanations of Deep Visual Features | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| ICICLE: Interpretable Class Incremental Continual Learning | [![GitHub](https://img.shields.io/github/stars/gmum/ICICLE)](https://github.com/gmum/ICICLE) | [![arXiv](https://img.shields.io/badge/arXiv-2303.07811-b31b1b.svg)](https://arxiv.org/abs/2303.07811) | :heavy_minus_sign: |
| ProbVLM: Probabilistic Adapter for Frozen Vison-Language Models | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.eml-unitue.de/publication/ProbVLM) <br /> [![GitHub](https://img.shields.io/github/stars/ExplainableML/ProbVLM)](https://github.com/ExplainableML/ProbVLM) | [![arXiv](https://img.shields.io/badge/arXiv-2307.00398-b31b1b.svg)](https://arxiv.org/abs/2307.00398) | :heavy_minus_sign: |
| Out-of-Distribution Detection for Monocular Depth Estimation | [![GitHub](https://img.shields.io/github/stars/jhornauer/mde_ood)](https://github.com/jhornauer/mde_ood) | [![arXiv](https://img.shields.io/badge/arXiv-2308.06072-b31b1b.svg)](https://arxiv.org/abs/2308.06072) | :heavy_minus_sign: |
| Using Explanations to Guide Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.11932-b31b1b.svg)](https://arxiv.org/abs/2303.11932) | :heavy_minus_sign: |
| Rosetta Neurons: Mining the Common Units in a Model Zoo | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yossigandelsman.github.io/rosetta_neurons/) <br /> [![GitHub](https://img.shields.io/github/stars/yossigandelsman/rosetta_neurons)](https://github.com/yossigandelsman/rosetta_neurons) | [![arXiv](https://img.shields.io/badge/arXiv-2306.09346-b31b1b.svg)](https://arxiv.org/abs/2306.09346) | :heavy_minus_sign: |
| Prototype-based Dataset Comparison | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://nanne.github.io/ProtoSim/) <br /> [![GitHub](https://img.shields.io/github/stars/Nanne/ProtoSim)](https://github.com/Nanne/ProtoSim) | [![arXiv](https://img.shields.io/badge/arXiv-2309.02401-b31b1b.svg)](https://arxiv.org/abs/2309.02401) | :heavy_minus_sign: |
| Learning to Identify Critical States for Reinforcement Learning from Videos | [![GitHub](https://img.shields.io/github/stars/AI-Initiative-KAUST/VideoRLCS)](https://github.com/AI-Initiative-KAUST/VideoRLCS) | [![arXiv](https://img.shields.io/badge/arXiv-2308.07795-b31b1b.svg)](https://arxiv.org/abs/2308.07795) | :heavy_minus_sign: |
| Leaping Into Memories: Space-Time Deep Feature Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://alexandrosstergiou.github.io/project_pages/LEAPS/index.html) <br /> [![GitHub](https://img.shields.io/github/stars/alexandrosstergiou/Leaping-Into-Memories)](https://github.com/alexandrosstergiou/Leaping-Into-Memories) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09941-b31b1b.svg)](https://arxiv.org/abs/2303.09941) | :heavy_minus_sign: |
| MAGI: Multi-Annotated Explanation-Guided Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| SAFARI: Versatile and Efficient Evaluations for Robustness of Interpretability | [![GitHub](https://img.shields.io/github/stars/havelhuang/Eval_XAI_Robustness)](https://github.com/havelhuang/Eval_XAI_Robustness) | [![arXiv](https://img.shields.io/badge/arXiv-2208.09418-b31b1b.svg)](https://arxiv.org/abs/2208.09418) | :heavy_minus_sign: |
| Do BLIP and Stable Diffusion Understand Each Other? | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dalleflamingo.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2212.12249-b31b1b.svg)](https://arxiv.org/abs/2212.12249) | :heavy_minus_sign: |
| Evaluation and Improvement of Interpretability for Self-Explainable Part-Prototype Networks | [![GitHub](https://img.shields.io/github/stars/hqhQAQ/EvalProtoPNet)](https://github.com/hqhQAQ/EvalProtoPNet) | [![arXiv](https://img.shields.io/badge/arXiv-2212.05946-b31b1b.svg)](https://arxiv.org/abs/2212.05946) | :heavy_minus_sign: |
| MoreauGrad: Sparse and Robust Interpretation of Neural Networks via Moreau Envelope | [![GitHub](https://img.shields.io/github/stars/buyeah1109/MoreauGrad)](https://github.com/buyeah1109/MoreauGrad) | [![arXiv](https://img.shields.io/badge/arXiv-2302.05294-b31b1b.svg)](https://arxiv.org/abs/2302.05294) | :heavy_minus_sign: |
| Towards Understanding the Generalization of Deepfake Detectors from a Game-Theoretical View | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Counterfactual-based Saliency Map: Towards Visual Contrastive Explanations for Neural Networks | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Beyond Single Path Integrated Gradients for Reliable Input Attribution via Randomized Path Sampling | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Learning Support and Trivial Prototypes for Interpretable Image Classification | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2301.04011-b31b1b.svg)](https://arxiv.org/abs/2301.04011) | :heavy_minus_sign: |
| Visual Explanations via Iterated Integrated Gradients | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Neural Generative Models

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Unsupervised Compositional Concepts Discovery with Text-to-Image Generative Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://energy-based-model.github.io/unsupervised-concept-discovery/) <br /> [![GitHub](https://img.shields.io/github/stars/nanlliu/Unsupervised-Compositional-Concepts-Discovery)](https://github.com/nanlliu/Unsupervised-Compositional-Concepts-Discovery) | [![arXiv](https://img.shields.io/badge/arXiv-2306.05357-b31b1b.svg)](https://arxiv.org/abs/2306.05357) | :heavy_minus_sign: |
| Better Aligning Text-to-Image Models with Human Preference | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://tgxs002.github.io/align_sd_web/) <br /> [![GitHub](https://img.shields.io/github/stars/tgxs002/align_sd)](https://github.com/tgxs002/align_sd) | [![arXiv](https://img.shields.io/badge/arXiv-2303.14420-b31b1b.svg)](https://arxiv.org/abs/2303.14420) | :heavy_minus_sign: |
| DLT: Conditioned Layout Generation with Joint Discrete-Continuous Diffusion Layout Transformer | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://wix-incubator.github.io/DLT/) <br /> [![GitHub](https://img.shields.io/github/stars/wix-incubator/DLT)](https://github.com/wix-incubator/DLT) | [![arXiv](https://img.shields.io/badge/arXiv-2303.03755-b31b1b.svg)](https://arxiv.org/abs/2303.03755) | :heavy_minus_sign: |
| Anti-DreamBooth: Protecting users from Personalized Text-to-Image Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://anti-dreambooth.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/VinAIResearch/Anti-DreamBooth)](https://github.com/VinAIResearch/Anti-DreamBooth) | [![arXiv](https://img.shields.io/badge/arXiv-2303.15433-b31b1b.svg)](https://arxiv.org/abs/2303.15433) | :heavy_minus_sign: |
| GECCO: Geometrically-Conditioned Point Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jatentaki.github.io/publication/10-03-2023) | [![arXiv](https://img.shields.io/badge/arXiv-2303.05916-b31b1b.svg)](https://arxiv.org/abs/2303.05916) | :heavy_minus_sign: |
| DiffDreamer: Towards Consistent Unsupervised Single-View Scene Extrapolation with Conditional Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://primecai.github.io/diffdreamer) <br /> [![GitHub](https://img.shields.io/github/stars/primecai/DiffDreamer)](https://github.com/primecai/DiffDreamer) | [![arXiv](https://img.shields.io/badge/arXiv-2211.12131-b31b1b.svg)](https://arxiv.org/abs/2211.12131) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=UukyiAqlwcw) |
| Controllable Human Motion Synthesis via Guided Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://korrawe.github.io/gmd-project/) <br /> [![GitHub](https://img.shields.io/github/stars/korrawe/guided-motion-diffusion)](https://github.com/korrawe/guided-motion-diffusion) | [![arXiv](https://img.shields.io/badge/arXiv-2305.12577-b31b1b.svg)](https://arxiv.org/abs/2305.12577) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=giw0pLIKdsA) |
| COOP: Decoupling and Coupling of Whole-Body Grasping Pose Generation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Zero-Shot Spatial Layout Conditioning for Text-to-Image Diffusion Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.13754-b31b1b.svg)](https://arxiv.org/abs/2306.13754) | :heavy_minus_sign: |
| StyleDomain: Efficient and Lightweight Parameterizations of StyleGAN for One-Shot and Few-Shot Domain Adaptation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2212.10229-b31b1b.svg)](https://arxiv.org/abs/2212.10229) | :heavy_minus_sign: |
| GRAM-HD: 3D-Consistent Image Generation at High Resolution with Generative Radiance Manifolds | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jeffreyxiang.github.io/GRAM-HD/) | [![arXiv](https://img.shields.io/badge/arXiv-2206.07255-b31b1b.svg)](https://arxiv.org/abs/2206.07255) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Uqzs4uN6v8M) |
| Your Diffusion Model is Secretly a Zero-Shot Classifier | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://diffusion-classifier.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/diffusion-classifier/diffusion-classifier)](https://github.com/diffusion-classifier/diffusion-classifier) | [![arXiv](https://img.shields.io/badge/arXiv-2303.16203-b31b1b.svg)](https://arxiv.org/abs/2303.16203) | :heavy_minus_sign: |
| Learning Hierarchical Features with Joint Latent Space Energy-based Prior | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| ActFormer: A GAN-based Transformer towards General Action-Conditioned 3D Human Motion Generation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2203.07706-b31b1b.svg)](https://arxiv.org/abs/2203.07706) | :heavy_minus_sign: |
| Landscape Learning for Neural Network Inversion | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2206.09027-b31b1b.svg)](https://arxiv.org/abs/2206.09027) | :heavy_minus_sign: |
| Diffusion in Style | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Diffusion-SDF: Conditional Generative Modeling of Signed Distance Functions | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://light.princeton.edu/publication/diffusion-sdf/) <br /> [![GitHub](https://img.shields.io/github/stars/princeton-computational-imaging/Diffusion-SDF)](https://github.com/princeton-computational-imaging/Diffusion-SDF) | [![arXiv](https://img.shields.io/badge/arXiv-2211.13757-b31b1b.svg)](https://arxiv.org/abs/2211.13757) | :heavy_minus_sign: |
| GETAvatar: Generative Textured Meshes for Animatable Human Avatars | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| A-STAR: Test-Time <i>A</i>ttention <i>S</i>egrega<i>t</i>ion and <i>R</i>etention for Text-to-Image Synthesis | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.14544-b31b1b.svg)](https://arxiv.org/abs/2306.14544) | :heavy_minus_sign: |
| TF-ICON: Diffusion-based Training-Free Cross-Domain Image Composition | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://shilin-lu.github.io/tf-icon.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/Shilin-LU/TF-ICON)](https://github.com/Shilin-LU/TF-ICON) | [![arXiv](https://img.shields.io/badge/arXiv-2307.12493-b31b1b.svg)](https://arxiv.org/abs/2307.12493) | :heavy_minus_sign: |
| Breaking The Limits of Text-Conditioned 3D Motion Synthesis with Elaborative Descriptions | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| BeLFusion: Latent Diffusion for Behavior-Driven Human Motion Prediction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://barquerogerman.github.io/BeLFusion/) <br /> [![GitHub](https://img.shields.io/github/stars/BarqueroGerman/BeLFusion)](https://github.com/BarqueroGerman/BeLFusion) | [![arXiv](https://img.shields.io/badge/arXiv-2211.14304-b31b1b.svg)](https://arxiv.org/abs/2211.14304) | :heavy_minus_sign: |
| Delta Denoising Score | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://delta-denoising-score.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2304.07090-b31b1b.svg)](https://arxiv.org/abs/2304.07090) | :heavy_minus_sign: |
| Mimic3D: Thriving 3D-Aware GANs via 3D-to-2D Imitation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://seanchenxy.github.io/Mimic3DWeb/) <br /> [![GitHub](https://img.shields.io/github/stars/SeanChenxy/Mimic3D)](https://github.com/SeanChenxy/Mimic3D) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09036-b31b1b.svg)](https://arxiv.org/abs/2303.09036) | :heavy_minus_sign: |
| DreamBooth3D: Subject-Driven Text-to-3D Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dreambooth3d.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2303.13508-b31b1b.svg)](https://arxiv.org/abs/2303.13508) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kKVDrbfvOoA) |
| Feature Proliferation the Cancer in StyleGAN and its Treatments | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Unsupervised Facial Performance Editing via Vector-Quantized StyleGAN Representations | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| 3D-Aware Image Generation using 2D Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jeffreyxiang.github.io/ivid/) <br /> [![GitHub](https://img.shields.io/github/stars/JeffreyXiang/ivid)](https://github.com/JeffreyXiang/ivid) | [![arXiv](https://img.shields.io/badge/arXiv-2303.17905-b31b1b.svg)](https://arxiv.org/abs/2303.17905) | :heavy_minus_sign: |
| Neural Collage Transfer: Artistic Reconstruction via Material Manipulation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption | [![GitHub](https://img.shields.io/github/stars/sjtuplayer/few-shot-diffusion)](https://github.com/sjtuplayer/few-shot-diffusion) | [![arXiv](https://img.shields.io/badge/arXiv-2309.03729-b31b1b.svg)](https://arxiv.org/abs/2309.03729) | :heavy_minus_sign: |
| Single-Stage Diffusion NeRF: A Unified Approach to 3D Generation and Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lakonik.github.io/ssdnerf/) <br /> [![GitHub](https://img.shields.io/github/stars/Lakonik/SSDNeRF)](https://github.com/Lakonik/SSDNeRF) | [![arXiv](https://img.shields.io/badge/arXiv-2304.06714-b31b1b.svg)](https://arxiv.org/abs/2304.06714) | :heavy_minus_sign: |
| Erasing Concepts from Diffusion Models | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://erasing.baulab.info/) <br /> [![GitHub](https://img.shields.io/github/stars/rohitgandikota/erasing)](https://github.com/rohitgandikota/erasing) | [![arXiv](https://img.shields.io/badge/arXiv-2303.07345-b31b1b.svg)](https://arxiv.org/abs/2303.07345) | :heavy_minus_sign: |
| Make Encoder Great Again in 3D GAN Inversion through Geometry and Occlusion-Aware Encoding | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://eg3d-goae.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/jiangyzy/GOAE)](https://github.com/jiangyzy/GOAE) | [![arXiv](https://img.shields.io/badge/arXiv-2303.12326-b31b1b.svg)](https://arxiv.org/abs/2303.12326) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CptQDMqM9Pc) |
| HairNeRF: Geometry-Aware Hair Swapped Image Synthesis | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Vision and Language

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| SMAUG: Sparse Masked Autoencoder for Efficient Video-Language Pre-Training | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2211.11446-b31b1b.svg)](https://arxiv.org/abs/2211.11446) | :heavy_minus_sign: |
| DiffusionRet: Generative Text-Video Retrieval with Diffusion Model | [![GitHub](https://img.shields.io/github/stars/jpthu17/DiffusionRet)](https://github.com/jpthu17/DiffusionRet) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09867-b31b1b.svg)](https://arxiv.org/abs/2303.09867) | :heavy_minus_sign: |
| Explore and Tell: Embodied Visual Captioning in 3D Environments | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://aim3-ruc.github.io/ExploreAndTell/) <br /> [![GitHub](https://img.shields.io/github/stars/HAWLYQ/ET-Cap)](https://github.com/HAWLYQ/ET-Cap) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10447-b31b1b.svg)](https://arxiv.org/abs/2308.10447) | :heavy_minus_sign: |
| Distilling Large Vision-Language Model with Out-of-Distribution Generalizability | [![GitHub](https://img.shields.io/github/stars/xuanlinli17/large_vlm_distillation_ood)](https://github.com/xuanlinli17/large_vlm_distillation_ood) | [![arXiv](https://img.shields.io/badge/arXiv-2307.03135-b31b1b.svg)](https://arxiv.org/abs/2307.03135) | :heavy_minus_sign: |
| Learning Trajectory-Word Alignments for Video-Language Tasks | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2301.01953-b31b1b.svg)](https://arxiv.org/abs/2301.01953) | :heavy_minus_sign: |
| Variational Causal Inference Network for Explanatory Visual Question Answering | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| TextManiA: Enriching Visual Feature by Text-Driven Manifold Augmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://textmania.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/postech-ami/TextManiA)](https://github.com/postech-ami/TextManiA) | [![arXiv](https://img.shields.io/badge/arXiv-2307.14611-b31b1b.svg)](https://arxiv.org/abs/2307.14611) | :heavy_minus_sign: |
| UniRef: A Unified Model for Reference-based Object Segmentation Tasks | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Gradient-Regulated Meta-Prompt Learning for Generalizable Vision-Language Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.06571-b31b1b.svg)](https://arxiv.org/abs/2303.06571) | :heavy_minus_sign: |
| Misalign, Contrast then Distill: Rethinking Misalignments in Language-Image Pre-Training | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Toward Multi-Granularity Decision-Making: Explicit Visual Reasoning with Hierarchical Knowledge | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| VL-Match: Enhancing Vision-Language Pretraining with Token-Level and Instance-Level Matching | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Moment Detection in Long Tutorial Videos | [![GitHub](https://img.shields.io/github/stars/ioanacroi/longmoment-detr)](https://github.com/ioanacroi/longmoment-detr) | :heavy_minus_sign: | :heavy_minus_sign: |
| Not All Features Matter: Enhancing Few-Shot CLIP with Adaptive Prior Refinement | [![GitHub](https://img.shields.io/github/stars/yangyangyang127/APE)](https://github.com/yangyangyang127/APE) | [![arXiv](https://img.shields.io/badge/arXiv-2304.01195-b31b1b.svg)](https://arxiv.org/abs/2304.01195) | :heavy_minus_sign: |
| Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of Synthetic and Compositional Images | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://whoops-benchmark.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2303.07274-b31b1b.svg)](https://arxiv.org/abs/2303.07274) | :heavy_minus_sign: |
| Advancing Referring Expression Segmentation Beyond Single Image | [![GitHub](https://img.shields.io/github/stars/yixuan730/group-res)](https://github.com/yixuan730/group-res) | [![arXiv](https://img.shields.io/badge/arXiv-2305.12452-b31b1b.svg)](https://arxiv.org/abs/2305.12452) | :heavy_minus_sign: |
| CLIPoint: Adapting CLIP for Powerful 3D Open-World Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Unsupervised Prompt Tuning for Text-Driven Object Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Distilling Coarse-to-Fine Semantic Matching Knowledge for Weakly Supervised 3D Visual Grounding | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.09267-b31b1b.svg)](https://arxiv.org/abs/2307.09267) | :heavy_minus_sign: |
| I can't Believe there's no Images! Learning Visual Tasks using Only Language Data | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://prior.allenai.org/projects/close) <br /> [![GitHub](https://img.shields.io/github/stars/allenai/close)](https://github.com/allenai/close) | [![arXiv](https://img.shields.io/badge/arXiv-2211.09778-b31b1b.svg)](https://arxiv.org/abs/2211.09778) | :heavy_minus_sign: |
| Learning Cross-Modal Affinity for Referring Video Object Segmentation Targeting Limited Samples | [![GitHub](https://img.shields.io/github/stars/hengliusky/Few_shot_RVOS)](https://github.com/hengliusky/Few_shot_RVOS) | [![arXiv](https://img.shields.io/badge/arXiv-2309.02041-b31b1b.svg)](https://arxiv.org/abs/2309.02041) | :heavy_minus_sign: |
| MeViS: A Large-Scale Benchmark for Video Segmentation with Motion Expressions | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://henghuiding.github.io/MeViS/) <br /> [![GitHub](https://img.shields.io/github/stars/henghuiding/MeViS)](https://github.com/henghuiding/MeViS) | [![arXiv](https://img.shields.io/badge/arXiv-2308.08544-b31b1b.svg)](https://arxiv.org/abs/2308.08544) | :heavy_minus_sign: |
| Diverse Data Augmentation with Diffusions for Effective Test-Time Prompt Tuning | [![GitHub](https://img.shields.io/github/stars/chunmeifeng/DiffTPT)](https://github.com/chunmeifeng/DiffTPT) | [![arXiv](https://img.shields.io/badge/arXiv-2308.06038-b31b1b.svg)](https://arxiv.org/abs/2308.06038) | :heavy_minus_sign: |
| ShapeScaffolder: Structure-Aware 3D Shape Generation from Text | :heavy_minus_sign: | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://www.yongliangyang.net/docs/shapescaffolder_iccv23.pdf) | :heavy_minus_sign: |
| SuS-X: Training-Free Name-Only Transfer of Vision-Language Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://vishaal27.github.io/SuS-X-webpage/) <br /> [![GitHub](https://img.shields.io/github/stars/vishaal27/SuS-X)](https://github.com/vishaal27/SuS-X) | [![arXiv](https://img.shields.io/badge/arXiv-2211.16198-b31b1b.svg)](https://arxiv.org/abs/2211.16198) | :heavy_minus_sign: |
| BEVBert: Multimodal Map Pre-Training for Language-Guided Navigation | [![GitHub](https://img.shields.io/github/stars/MarSaKi/VLN-BEVBert)](https://github.com/MarSaKi/VLN-BEVBert) | [![arXiv](https://img.shields.io/badge/arXiv-2212.04385-b31b1b.svg)](https://arxiv.org/abs/2212.04385) | :heavy_minus_sign: |
| X-Mesh: Towards Fast and Accurate Text-Driven 3D Stylization via Dynamic Textual Guidance | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://xmu-xiaoma666.github.io/Projects/X-Mesh/) <br /> [![GitHub](https://img.shields.io/github/stars/xmu-xiaoma666/X-Mesh)](https://github.com/xmu-xiaoma666/X-Mesh) | [![arXiv](https://img.shields.io/badge/arXiv-2303.15764-b31b1b.svg)](https://arxiv.org/abs/2303.15764) | :heavy_minus_sign: |
| OnlineRefer: A Simple Online Baseline for Referring Video Object Segmentation | [![GitHub](https://img.shields.io/github/stars/wudongming97/OnlineRefer)](https://github.com/wudongming97/OnlineRefer) | [![arXiv](https://img.shields.io/badge/arXiv-2307.09356-b31b1b.svg)](https://arxiv.org/abs/2307.09356) | :heavy_minus_sign: |
| Attentive Mask CLIP | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2212.08653-b31b1b.svg)](https://arxiv.org/abs/2212.08653) | :heavy_minus_sign: |
| Knowledge Proxy Intervention for Deconfounded Video Question Answering | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| UniVTG: Towards Unified Video-Language Temporal Grounding | [![GitHub](https://img.shields.io/github/stars/showlab/UniVTG)](https://github.com/showlab/UniVTG) | [![arXiv](https://img.shields.io/badge/arXiv-2307.16715-b31b1b.svg)](https://arxiv.org/abs/2307.16715) | :heavy_minus_sign: |
| Self-Supervised Cross-View Representation Reconstruction for Change Captioning | [![GitHub](https://img.shields.io/github/stars/tuyunbin/SCORER)](https://github.com/tuyunbin/SCORER) | :heavy_minus_sign: | :heavy_minus_sign: |
| Unified Coarse-to-Fine Alignment for Video-Text Retrieval | [![GitHub](https://img.shields.io/github/stars/Ziyang412/UCoFiA)](https://github.com/Ziyang412/UCoFiA) | :heavy_minus_sign: | :heavy_minus_sign: |
| Confidence-Aware Pseudo-Label Learning for Weakly Supervised Visual Grounding | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| TextPSG: Panoptic Scene Graph Generation from Textual Descriptions | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MAtch, eXpand and Improve: Unsupervised Finetuning for Zero-Shot Action Recognition with Language Knowledge | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://wlin-at.github.io/maxi) <br /> [![GitHub](https://img.shields.io/github/stars/wlin-at/MAXI)](https://github.com/wlin-at/MAXI) | [![arXiv](https://img.shields.io/badge/arXiv-2303.08914-b31b1b.svg)](https://arxiv.org/abs/2303.08914) | :heavy_minus_sign: |
| Unify, Align and Refine: Multi-Level Semantic Alignment for Radiology Report Generation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.15932-b31b1b.svg)](https://arxiv.org/abs/2303.15932) | :heavy_minus_sign: |
| Transferring Visual Knowledge with Pre-Trained Models for Multimodal Machine Translation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://devaansh100.github.io/projects/cliptrans/) <br /> [![GitHub](https://img.shields.io/github/stars/devaansh100/CLIPTrans)](https://github.com/devaansh100/CLIPTrans) | [![arXiv](https://img.shields.io/badge/arXiv-2308.15226-b31b1b.svg)](https://arxiv.org/abs/2308.15226) | :heavy_minus_sign: |
| Learning Human-Human Interactions in Images from Weak Textual Supervision | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://tau-vailab.github.io/learning-interactions/) <br /> [![GitHub](https://img.shields.io/github/stars/TAU-VAILab/learning-interactions)](https://github.com/TAU-VAILab/learning-interactions) | [![arXiv](https://img.shields.io/badge/arXiv-2304.14104-b31b1b.svg)](https://arxiv.org/abs/2304.14104) | :heavy_minus_sign: |
| BUS: Efficient and Effective Vision-Language Pretraining with Bottom-Up Patch Summarization | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.08504-b31b1b.svg)](https://arxiv.org/abs/2307.08504) | :heavy_minus_sign: |
| 3D-VisTA: Pre-Trained Transformer for 3D Vision and Text Alignment | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://3d-vista.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/3d-vista/3D-VisTA)](https://github.com/3d-vista/3D-VisTA) | [![arXiv](https://img.shields.io/badge/arXiv-2308.04352-b31b1b.svg)](https://arxiv.org/abs/2308.04352) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=uUtMaoif8DQ&t=1s) |
| ALIP: Adaptive Language-Image Pre-Training with Synthetic Caption | [![GitHub](https://img.shields.io/github/stars/deepglint/ALIP)](https://github.com/deepglint/ALIP) | [![arXiv](https://img.shields.io/badge/arXiv-2308.08428-b31b1b.svg)](https://arxiv.org/abs/2308.08428) | :heavy_minus_sign: |
| LoGoPrompt: Synthetic Text Images can be Good Visual Prompts for Vision-Language Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chengshiest.github.io/logo/) | [![arXiv](https://img.shields.io/badge/arXiv-2309.01155-b31b1b.svg)](https://arxiv.org/abs/2309.01155) | :heavy_minus_sign: |
| Noise-Aware Learning from Web-Crawled Image-Text Data for Image Captioning | [![GitHub](https://img.shields.io/github/stars/kakaobrain/noc)](https://github.com/kakaobrain/noc) | [![arXiv](https://img.shields.io/badge/arXiv-2212.13563-b31b1b.svg)](https://arxiv.org/abs/2212.13563) | :heavy_minus_sign: |
| Decouple Before Interact: Multi-Modal Prompt Learning for Continual Visual Question Answering | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Prompt-Guided Image Captioning for VQA with GPT-3 | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yushi-hu.github.io/promptcap_demo/) <br /> [![GitHub](https://img.shields.io/github/stars/Yushi-Hu/PromptCap)](https://github.com/Yushi-Hu/PromptCap) | [![arXiv](https://img.shields.io/badge/arXiv-2211.09699-b31b1b.svg)](https://arxiv.org/abs/2211.09699) | :heavy_minus_sign: |
| Grounded Image Text Matching with Mismatched Relation Reasoning | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.01236-b31b1b.svg)](https://arxiv.org/abs/2308.01236) | :heavy_minus_sign: |
| GePSAn: Generative Procedure Step Anticipation in Cooking Videos | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dki-lab.github.io/LLM-Planner/) <br /> [![GitHub](https://img.shields.io/github/stars/OSU-NLP-Group/LLM-Planner)](https://github.com/OSU-NLP-Group/LLM-Planner) | [![arXiv](https://img.shields.io/badge/arXiv-2212.04088-b31b1b.svg)](https://arxiv.org/abs/2212.04088) | :heavy_minus_sign: |
| VL-PET: Vision-and-Language Parameter-Efficient Tuning via Granularity Control | [![GitHub](https://img.shields.io/github/stars/HenryHZY/VL-PET)](https://github.com/HenryHZY/VL-PET) | [![arXiv](https://img.shields.io/badge/arXiv-2308.09804-b31b1b.svg)](https://arxiv.org/abs/2308.09804) | :heavy_minus_sign: |
| With a Little Help from Your own Past: Prototypical Memory Networks for Image Captioning | [![GitHub](https://img.shields.io/github/stars/aimagelab/PMA-Net)](https://github.com/aimagelab/PMA-Net) | [![arXiv](https://img.shields.io/badge/arXiv-2308.12383-b31b1b.svg)](https://arxiv.org/abs/2308.12383) | :heavy_minus_sign: |
| Improving Zero-Shot Generalization for CLIP with Synthesized Prompts | [![GitHub](https://img.shields.io/github/stars/mrflogs/SHIP)](https://github.com/mrflogs/SHIP) | [![arXiv](https://img.shields.io/badge/arXiv-2307.07397-b31b1b.svg)](https://arxiv.org/abs/2307.07397) | :heavy_minus_sign: |
| DALL-Eval: Probing the Reasoning Skills and Social Biases of Text-to-Image Generation Models | [![GitHub](https://img.shields.io/github/stars/j-min/DallEval)](https://github.com/j-min/DallEval) | [![arXiv](https://img.shields.io/badge/arXiv-2202.04053-b31b1b.svg)](https://arxiv.org/abs/2202.04053) | :heavy_minus_sign: |
| Learning Navigational Visual Representations with Semantic Map Supervision | [![GitHub](https://img.shields.io/github/stars/YicongHong/Ego2Map-NaViT)](https://github.com/YicongHong/Ego2Map-NaViT) | [![arXiv](https://img.shields.io/badge/arXiv-2307.12335-b31b1b.svg)](https://arxiv.org/abs/2307.12335) | :heavy_minus_sign: |
| CoTDet: Affordance Knowledge Prompting for Task Driven Object Detection | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://toneyaya.github.io/cotdet/) | [![arXiv](https://img.shields.io/badge/arXiv-2309.01093-b31b1b.svg)](https://arxiv.org/abs/2309.01093) | :heavy_minus_sign: |
| Open Set Video HOI detection from Action-Centric Chain-of-Look Prompting | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Learning Concise and Descriptive Attributes for Visual Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.03685-b31b1b.svg)](https://arxiv.org/abs/2308.03685) | :heavy_minus_sign: |
| Open-Vocabulary Video Question Answering: A New Benchmark for Evaluating the Generalizability of Video Question Answering Models | [![GitHub](https://img.shields.io/github/stars/mlvlab/OVQA)](https://github.com/mlvlab/OVQA) | [![arXiv](https://img.shields.io/badge/arXiv-2308.09363-b31b1b.svg)](https://arxiv.org/abs/2308.09363) | :heavy_minus_sign: |
| Encyclopedic VQA: Visual Questions About Detailed Properties of Fine-Grained Categories | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://github.com/google-research/google-research/tree/master/encyclopedic_vqa) | [![arXiv](https://img.shields.io/badge/arXiv-2306.09224-b31b1b.svg)](https://arxiv.org/abs/2306.09224) | :heavy_minus_sign: |
| Story Visualization by Online Text Augmentation with Context Memory | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dcahn12.github.io/projects/CMOTA/) <br /> [![GitHub](https://img.shields.io/github/stars/yonseivnl/cmota)](https://github.com/yonseivnl/cmota) | [![arXiv](https://img.shields.io/badge/arXiv-2308.07575-b31b1b.svg)](https://arxiv.org/abs/2308.07575) | :heavy_minus_sign: |
| Transferable Decoding with Visual Entities for Zero-Shot Image Captioning | [![GitHub](https://img.shields.io/github/stars/FeiElysia/ViECap)](https://github.com/FeiElysia/ViECap) | [![arXiv](https://img.shields.io/badge/arXiv-2307.16525-b31b1b.svg)](https://arxiv.org/abs/2307.16525) | :heavy_minus_sign: |
| Too Large; Data Reduction for Vision-Language Pre-Training | [![GitHub](https://img.shields.io/github/stars/showlab/datacentric.vlp)](https://github.com/showlab/datacentric.vlp) | [![arXiv](https://img.shields.io/badge/arXiv-2305.20087-b31b1b.svg)](https://arxiv.org/abs/2305.20087) | :heavy_minus_sign: |
| ViLTA: Enhancing Vision-Language Pre-Training through Textual Augmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.16689-b31b1b.svg)](https://arxiv.org/abs/2308.16689) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Vision, Graphics, and Robotics

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Learning Conditional Control for Pretrained Text-to-Image Diffusion Models | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Factorized Inverse Path Tracing for Efficient and Accurate Material-Lighting Estimation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jerrypiglet.github.io/fipt-ucsd/) <br /> [![GitHub](https://img.shields.io/github/stars/lwwu2/fipt)](https://github.com/lwwu2/fipt) | [![arXiv](https://img.shields.io/badge/arXiv-2304.05669-b31b1b.svg)](https://arxiv.org/abs/2304.05669) |  |
| Manipulate by Seeing: Creating Manipulation Controllers from Pre-Trained Representations | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://agi-labs.github.io/manipulate-by-seeing/) <br /> [![GitHub](https://img.shields.io/github/stars/AGI-Labs/manipulate-by-seeing)](https://github.com/AGI-Labs/manipulate-by-seeing) | [![arXiv](https://img.shields.io/badge/arXiv-2303.08135-b31b1b.svg)](https://arxiv.org/abs/2303.08135) | :heavy_minus_sign: |
| 3D Implicit Transporter for Temporally Consistent Keypoint Discovery | [![GitHub](https://img.shields.io/github/stars/zhongcl-thu/3D-Implicit-Transporter)](https://github.com/zhongcl-thu/3D-Implicit-Transporter) | [![ResearchGate](https://img.shields.io/badge/Research-Gate-D7E7F5.svg)](https://www.researchgate.net/publication/373328882_3D_Implicit_Transporter_for_Temporally_Consistent_Keypoint_Discovery) | :heavy_minus_sign: |
| Chordal Averaging on Flag Manifolds and its Applications | [![GitHub](https://img.shields.io/github/stars/nmank/FlagAveraging)](https://github.com/nmank/FlagAveraging) | [![arXiv](https://img.shields.io/badge/arXiv-2303.13501-b31b1b.svg)](https://arxiv.org/abs/2303.13501) | :heavy_minus_sign: |
| UniDexGrasp++: Improving Universal Dexterous Grasping via Geometry-Aware Curriculum Learning and Iterative Generalist-Specialist Learning | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2304.00464-b31b1b.svg)](https://arxiv.org/abs/2304.00464) | :heavy_minus_sign: |
| GameFormer: Game-Theoretic Modeling and Learning of Transformer-based Interactive Prediction and Planning for Autonomous Driving | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://mczhi.github.io/GameFormer/) <br /> [![GitHub](https://img.shields.io/github/stars/MCZhi/GameFormer)](https://github.com/MCZhi/GameFormer) | [![arXiv](https://img.shields.io/badge/arXiv-2303.05760-b31b1b.svg)](https://arxiv.org/abs/2303.05760) | :heavy_minus_sign: |
| PPR: Physically Plausible Reconstruction from Monocular Videos | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://gengshan-y.github.io/ppr/) <br /> [![GitHub](https://img.shields.io/github/stars/gengshan-y/ppr)](https://github.com/gengshan-y/ppr) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://gengshan-y.github.io/ppr/PPR.pdf) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Privacy, Security, Fairness, and Explainability

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Zolly: Zoom Focal Length Correctly for Perspective-Distorted Human Mesh Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://wenjiawang0312.github.io/projects/zolly/) <br /> [![GitHub](https://img.shields.io/github/stars/WenjiaWang0312/Zolly)](https://github.com/WenjiaWang0312/Zolly) | [![arXiv](https://img.shields.io/badge/arXiv-2303.13796-b31b1b.svg)](https://arxiv.org/abs/2303.13796) | :heavy_minus_sign: |
| ACLS: Adaptive and Conditional Label Smoothing for Network Calibration | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://cvlab.yonsei.ac.kr/projects/ACLS/) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11911-b31b1b.svg)](https://arxiv.org/abs/2308.11911) | :heavy_minus_sign: |
| PGFed: Personalize Each Client's Global Objective for Federated Learning | [![GitHub](https://img.shields.io/github/stars/ljaiverson/pgfed)](https://github.com/ljaiverson/pgfed) | [![arXiv](https://img.shields.io/badge/arXiv-2212.01448-b31b1b.svg)](https://arxiv.org/abs/2212.01448) | :heavy_minus_sign: |
| Overcoming Bias in Pretrained Models by Manipulating the Finetuning Dataset | [![GitHub](https://img.shields.io/github/stars/princetonvisualai/overcoming-pretraining-bias)](https://github.com/princetonvisualai/overcoming-pretraining-bias) | [![arXiv](https://img.shields.io/badge/arXiv-2303.06167-b31b1b.svg)](https://arxiv.org/abs/2303.06167) <br /> [![ResearchGate](https://img.shields.io/badge/Research-Gate-D7E7F5.svg)](https://www.researchgate.net/publication/369199104_Overcoming_Bias_in_Pretrained_Models_by_Manipulating_the_Finetuning_Dataset) | :heavy_minus_sign: |
| ITI-GEN: Inclusive Text-to-Image Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://czhang0528.github.io/iti-gen) | [![arXiv](https://img.shields.io/badge/arXiv-2309.05569-b31b1b.svg)](https://arxiv.org/abs/2309.05569) | :heavy_minus_sign: |
| FunnyBirds: A Synthetic Vision Dataset for a Part-based Analysis of Explainable AI Methods | [![GitHub](https://img.shields.io/github/stars/visinf/funnybirds)](https://github.com/visinf/funnybirds) | [![arXiv](https://img.shields.io/badge/arXiv-2308.06248-b31b1b.svg)](https://arxiv.org/abs/2308.06248) | :heavy_minus_sign: |
| X-VoE: Measuring eXplanatory Violation of Expectation in Physical Events | [![GitHub](https://img.shields.io/github/stars/daibopku/X-VoE)](https://github.com/daibopku/X-VoE) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10441-b31b1b.svg)](https://arxiv.org/abs/2308.10441) | :heavy_minus_sign: |
| Adaptive Testing of Computer Vision Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2212.02774-b31b1b.svg)](https://arxiv.org/abs/2212.02774) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Fairness, Privacy, Ethics, Social-good, Transparency, Accountability in Vision

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### First Person (Egocentric) Vision

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Deep Learning Architectures

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Recognition: Detection

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Image and Video Synthesis

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Vision and Audio

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Recognition, Segmentation, and Shape Analysis

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Generative AI

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Humans, 3D Modeling, and Driving

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Low-Level Vision and Theory

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Navigation and Autonomous Driving

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### 3D from a Single Image and Shape-from-X

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Motion Estimation, Matching and Tracking

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Action and Event Understanding

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Computational Imaging

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Embodied Vision: Active Agents; Simulation

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Recognition: Retrieval

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Transfer, Low-Shot, Continual, Long-Tail Learning

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Low-Level and Physics-based Vision

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| High-Resolution Document Shadow Removal via a Large-Scale Real-World Dataset and a Frequency-Aware Shadow Erasing Net | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://cxh-research.github.io/DocShadow-SD7K/) <br /> [![GitHub](https://img.shields.io/github/stars/CXH-Research/DocShadow-SD7K)](https://github.com/CXH-Research/DocShadow-SD7K) | [![arXiv](https://img.shields.io/badge/arXiv-2308.14221-b31b1b.svg)](https://arxiv.org/abs/2308.14221) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Computer Vision Theory

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Video Analysis and Understanding

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Object Pose Estimation and Tracking

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### 3D Shape Modeling and Processing

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Human Pose/Shape Estimation

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Transfer, Low-Shot, and Continual Learning

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Self-, Semi-, and Unsupervised Learning

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Self-, Semi-, Meta-, Unsupervised Learning

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Photogrammetry and Remote Sensing

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Efficient and Scalable Vision

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Machine Learning (other than Deep Learning)

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Document Analysis and Understanding

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Biometrics

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Datasets and Evaluation

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Faces and Gestures

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Medical and Biological Vision; Cell Microscopy

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Scene Analysis and Understanding

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Multimodal Learning

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Human-in-the-Loop Computer Vision

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Image and Video Forensics

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Geometric Deep Learning

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Vision Applications and Systems

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Machine Learning and Dataset

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Unmasked Teacher: Towards Training-Efficient Video Foundation Models | [![GitHub](https://img.shields.io/github/stars/OpenGVLab/unmasked_teacher)](https://github.com/OpenGVLab/unmasked_teacher) | [![arXiv](https://img.shields.io/badge/arXiv-2303.16058-b31b1b.svg)](https://arxiv.org/abs/2303.16058) | :heavy_minus_sign: |

---

## Star History

<p align="center">
    <a href="https://star-history.com/#Dmitryryumin/ICCV-2023-Papers&Date" target="_blank">
        <img width="500" src="https://api.star-history.com/svg?repos=Dmitryryumin/ICCV-2023-Papers&type=Date" alt="Star History Chart">
    </a>
<p>
